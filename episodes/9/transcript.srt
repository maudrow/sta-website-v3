1
00:00:02,190 --> 00:00:04,230
Audrow Nash: This is a
conversation with Youssef

2
00:00:04,350 --> 00:00:09,810
Benmokhtar. Yousef is the CEO of
GelSight of Boston based company

3
00:00:09,840 --> 00:00:13,980
that makes high resolution touch
sensors. In this conversation,

4
00:00:13,980 --> 00:00:19,080
we talk about how GelSight's
touch sensors work, their new

5
00:00:19,080 --> 00:00:23,850
collaboration with Meta AI,
formerly Facebook AI, to make a

6
00:00:23,850 --> 00:00:27,900
new low cost sensor called
DIGIT, the digitization of

7
00:00:27,900 --> 00:00:33,060
touch, touch sensing and
robotic, how GelSight is

8
00:00:33,060 --> 00:00:37,200
investing in community and open
source software. And we talked

9
00:00:37,200 --> 00:00:41,850
about Youssef's professional
path in several industries. This

10
00:00:41,850 --> 00:00:44,760
is the Sense Think Act Podcast.
Thank you to our founding

11
00:00:44,760 --> 00:00:49,020
sponsor, Open Robotics. And now
here's my conversation with

12
00:00:49,050 --> 00:00:50,400
Youssef Benmokhtar.

13
00:00:52,140 --> 00:00:54,030
Youssef, would you introduce
yourself?

14
00:00:55,260 --> 00:00:57,390
Youssef Benmokhtar: Absolutely.
Youssef Benmokhtar, CEO of

15
00:00:57,420 --> 00:01:02,340
GelSight and a high tech
executive for the last 25 years,

16
00:01:02,850 --> 00:01:07,950
and excited about this interview
and sharing my thoughts with the

17
00:01:07,950 --> 00:01:08,460
audience.

18
00:01:10,430 --> 00:01:11,510
Audrow Nash: Tell me about
GelSight.

19
00:01:12,830 --> 00:01:16,040
Youssef Benmokhtar: So GelSight
is a MIT spin off, we have a

20
00:01:16,040 --> 00:01:20,030
very unique technology, we have
an imaging based digital tactile

21
00:01:20,030 --> 00:01:25,640
sensing technology, which
basically allows us and our

22
00:01:25,640 --> 00:01:32,000
customers to get a 3d
information of anything that

23
00:01:32,000 --> 00:01:35,870
sensors in contact with,
regardless of the material

24
00:01:35,870 --> 00:01:39,260
properties that is in contact
with, that's the essence and the

25
00:01:39,260 --> 00:01:40,310
core of our technology.

26
00:01:41,120 --> 00:01:43,880
Audrow Nash: Yeah, and so you
have several products that all

27
00:01:43,940 --> 00:01:47,270
kind of work this way. Can you
tell me at a high level, how

28
00:01:47,270 --> 00:01:50,240
they work? Like, how are you
looking at? How are you

29
00:01:50,270 --> 00:01:53,840
understanding the deformation of
the material and inferring touch

30
00:01:53,840 --> 00:01:54,500
information?

31
00:01:55,160 --> 00:01:59,030
Absolutely. So we have
a unique proprietary elasomeric

32
00:01:59,810 --> 00:02:04,400
material. That mean, so it
basically means it's a material

33
00:02:04,400 --> 00:02:08,630
that has kind of elastic
properties where it can conform

34
00:02:10,280 --> 00:02:14,390
easily to surfaces that is in
contact with, but still keeps

35
00:02:14,510 --> 00:02:21,590
some rigidity to it and has
optical properties to allow

36
00:02:21,620 --> 00:02:23,780
basically to be integrated into
an imaging system.

37
00:02:24,500 --> 00:02:27,440
Audrow Nash: I'm picturing like
a transparent silicon. Is that

38
00:02:27,470 --> 00:02:29,030
something like very similarly to

39
00:02:29,030 --> 00:02:30,680
Youssef Benmokhtar: that?
Absolutely, you're right, it's

40
00:02:30,680 --> 00:02:32,870
something very, so it's
basically a polymer like

41
00:02:32,870 --> 00:02:37,910
material that lets lights go
through it. So the essence of

42
00:02:37,910 --> 00:02:41,030
our technology is we have this
material, we we coat it with a

43
00:02:41,030 --> 00:02:46,640
reflective surface. And we
basically eliminated with RGB

44
00:02:46,640 --> 00:02:51,830
light, and place a camera behind
it. And now we have the ability

45
00:02:51,830 --> 00:02:58,430
to, to take scans with these
cameras, using a technique

46
00:02:58,430 --> 00:03:03,860
called photometric. 3d
reconstruction. And that's

47
00:03:03,860 --> 00:03:06,710
basically the essence of gel
sight technology.

48
00:03:08,090 --> 00:03:11,060
Audrow Nash: Okay, so let's see,
I've looked at some of the

49
00:03:11,060 --> 00:03:13,790
images, and they're quite cool
from this technology. So it

50
00:03:13,790 --> 00:03:16,970
looks like you have, so you'll
have the gel. And it looks like

51
00:03:16,970 --> 00:03:20,750
you have the light shining from
different sides of the gel so

52
00:03:20,750 --> 00:03:23,660
that it gives you different
shadows when the gel is pushed

53
00:03:23,690 --> 00:03:27,410
into by an object, is that
correct? Or how does that work?

54
00:03:27,410 --> 00:03:29,060
Like? How do you set up the
lights? Basically?

55
00:03:29,540 --> 00:03:32,330
Youssef Benmokhtar: Yes, I think
the lights is really more about

56
00:03:32,330 --> 00:03:37,940
getting the most uniform light
possible. at different

57
00:03:37,940 --> 00:03:43,730
wavelengths we use, we use red,
green, and blue. And making sure

58
00:03:43,730 --> 00:03:47,390
that the surface is uniformly
illuminated, what each one of

59
00:03:47,390 --> 00:03:53,960
these different LEDs. And then
we have a proprietary algorithm

60
00:03:53,990 --> 00:03:58,700
that's using the images captured
at each one of these wavelengths

61
00:03:59,660 --> 00:04:02,150
to reconstruct 3d from that.

62
00:04:02,990 --> 00:04:05,510
Audrow Nash: Why, what's the
significance of different

63
00:04:05,510 --> 00:04:07,850
wavelengths? why did why are
they necessary?

64
00:04:08,540 --> 00:04:12,290
Well, that's the
principle of photometric 3d.

65
00:04:13,790 --> 00:04:14,930
Audrow Nash: I guess, I don't
know very much.

66
00:04:15,830 --> 00:04:17,660
Youssef Benmokhtar: So that's
something that I'm not an expert

67
00:04:17,660 --> 00:04:20,390
on. I think that's something I
co founder could better explain,

68
00:04:20,390 --> 00:04:23,450
since he's the kind of the
inventor and the one who

69
00:04:23,450 --> 00:04:27,770
developed the algorithms, but
he's basically, you know, having

70
00:04:28,850 --> 00:04:33,170
three images done at different
wavelengths. And knowing what

71
00:04:33,170 --> 00:04:38,180
those wavelengths are basically,
being able to get those three

72
00:04:38,450 --> 00:04:43,100
different images, he's able to
build an algorithm that that

73
00:04:43,190 --> 00:04:45,080
builds 3d information from that.

74
00:04:45,440 --> 00:04:48,260
Audrow Nash: So I'm wondering,
like, maybe this is wrong, but

75
00:04:48,260 --> 00:04:52,580
this is how I'm thinking of it.
Perhaps having different colors

76
00:04:52,580 --> 00:04:56,390
lets you separate them in the
image space, so you can get more

77
00:04:56,420 --> 00:05:01,580
dimensions like you get
different views. So you get

78
00:05:01,580 --> 00:05:05,060
different views from each of the
lights. Because each of them

79
00:05:05,060 --> 00:05:08,960
casts a shadow. And so if you
have, say you do red, green and

80
00:05:08,960 --> 00:05:12,200
blue lights, now you can
separate it into red, green and

81
00:05:12,200 --> 00:05:15,740
blue in your image. And you can
kind of tease those apart. And

82
00:05:15,740 --> 00:05:19,550
that might be more useful for
analysis and inferring 3d

83
00:05:19,550 --> 00:05:22,820
structure. Does that make it
kinda like that? Yes,

84
00:05:22,850 --> 00:05:24,650
Youssef Benmokhtar: it's kind of
like that. Yeah, absolutely.

85
00:05:25,850 --> 00:05:30,050
Audrow Nash: Cool. And you
mentioned that the sensor is

86
00:05:30,050 --> 00:05:34,520
reflective. Is that just on the
side that's touching some

87
00:05:34,520 --> 00:05:36,230
object? Or? Yes, that's

88
00:05:36,230 --> 00:05:38,930
Youssef Benmokhtar: correct.
Yes. Because basically, you need

89
00:05:38,930 --> 00:05:42,410
that, that reflect that
reflection is what allows you to

90
00:05:43,160 --> 00:05:45,530
build that 3d scan, basically,

91
00:05:46,040 --> 00:05:49,250
Audrow Nash: is it reflective,
or just opaque for this guy is

92
00:05:49,250 --> 00:05:53,090
actually it is reflective? What,
why do you want it reflective?

93
00:05:54,350 --> 00:05:56,600
Youssef Benmokhtar: Because you
want to basically, you know,

94
00:05:56,600 --> 00:06:01,850
keep the light within within the
system, you know, again, in a

95
00:06:01,850 --> 00:06:05,810
very uniform way, so any kind of
light dissipation outside will

96
00:06:05,810 --> 00:06:10,370
make the computation of the 3d
very difficult. So Oh, so you

97
00:06:10,370 --> 00:06:13,940
want to have actually, you know,
I think opaque is actually

98
00:06:13,940 --> 00:06:16,700
another way to look at it, but
you need to think about it as

99
00:06:16,730 --> 00:06:19,910
it's very opaque, like light is
really not going through.

100
00:06:20,690 --> 00:06:22,640
Audrow Nash: Oh, so you mean,
you're keeping all of the light

101
00:06:22,640 --> 00:06:25,640
within the system, it probably
helps. You don't have to

102
00:06:25,640 --> 00:06:29,330
normalize it, or something,
because you know, how much light

103
00:06:29,330 --> 00:06:32,930
is in it. And thus, you can have
very accurate calibration, when

104
00:06:32,930 --> 00:06:33,770
it corrects

105
00:06:33,830 --> 00:06:36,500
Youssef Benmokhtar: graduate,
you avoid having to D noise and

106
00:06:36,500 --> 00:06:37,700
other things like that.

107
00:06:39,230 --> 00:06:43,760
Audrow Nash: Okay. So, what I'm
imagining that we have the

108
00:06:43,760 --> 00:06:48,110
lights behind a piece of gel,
the gel at the front of it, and

109
00:06:48,110 --> 00:06:50,540
the part that we'll touch
things, has some sort of

110
00:06:50,540 --> 00:06:53,600
reflective or opaque like thing
that doesn't let light through.

111
00:06:54,800 --> 00:06:58,280
And you push into the top of the
gel, the part with the

112
00:06:58,280 --> 00:07:03,560
reflective part, and it deforms
it. So that, and then the gel

113
00:07:03,560 --> 00:07:07,520
deforms, and you see kind of
like shadows or something within

114
00:07:07,520 --> 00:07:13,910
the gel that you use to infer
how the 3d how the gel is being

115
00:07:14,000 --> 00:07:16,280
deformed in 3d, correct?

116
00:07:16,790 --> 00:07:17,930
Youssef Benmokhtar: Yep, you got
it.

117
00:07:19,160 --> 00:07:23,750
Audrow Nash: Now, let's see what
So how long has this method been

118
00:07:23,750 --> 00:07:24,320
around?

119
00:07:25,700 --> 00:07:29,660
So the company was
founded in 2011, I believe the

120
00:07:29,660 --> 00:07:33,230
first papers describing the
concept were a few years before

121
00:07:33,230 --> 00:07:37,310
that. Yeah, so I want to say
maybe 2009 is the first time

122
00:07:37,310 --> 00:07:43,250
that this kind of idea was
described. And then our co

123
00:07:43,250 --> 00:07:47,930
founders, Ted Ellison, who is a
professor at MIT, and his

124
00:07:47,930 --> 00:07:53,990
student, Chemo Johnson, wrote
those papers, and got actually a

125
00:07:53,990 --> 00:07:57,020
lot of interest, not only from
academia, but also from

126
00:07:57,020 --> 00:07:59,930
industry. And that gave give
them an idea to say, Well, why

127
00:07:59,930 --> 00:08:04,310
don't we just, you know, found
his company and and, and try to

128
00:08:04,310 --> 00:08:08,120
do something with that. Just
respond to the, you know, what,

129
00:08:08,780 --> 00:08:11,270
what they felt was a strong
demand signal.

130
00:08:12,080 --> 00:08:20,180
Audrow Nash: Hmm. Why? I'm just
wondering, what makes like, I'm

131
00:08:20,180 --> 00:08:23,600
sure that, like, so I have a
little bit of experience in

132
00:08:23,600 --> 00:08:28,940
computer vision. And so thinking
about like, Okay, we want robots

133
00:08:28,970 --> 00:08:34,730
to touch things. Now using some
sort of gel and looking at how

134
00:08:34,730 --> 00:08:41,360
it deforms, to me, it seems like
a, like, kind of an AI solution

135
00:08:41,360 --> 00:08:44,990
a lot of people would come to,
in terms of how to understand

136
00:08:44,990 --> 00:08:49,850
touch. But I think that a lot of
companies have tried this kind

137
00:08:49,850 --> 00:08:54,770
of approach. And I'm sure
there's something hard about it,

138
00:08:54,920 --> 00:08:58,310
that has stopped a lot. Like the
fact that this technology is

139
00:08:58,310 --> 00:09:02,420
taking so long, or is like just
coming about now, what's been so

140
00:09:02,420 --> 00:09:03,830
hard about this technology.

141
00:09:05,270 --> 00:09:06,980
Youssef Benmokhtar: I think
what's been hard, you know, in,

142
00:09:07,040 --> 00:09:13,010
especially in the robotics, you
know, field is that, you know,

143
00:09:13,010 --> 00:09:19,580
sensors were bulky, expensive,
hard to calibrate, so hard to

144
00:09:19,580 --> 00:09:26,510
get actually repeatable
performance over time. And, you

145
00:09:26,510 --> 00:09:32,210
know, really just low
resolution. And when I mean low

146
00:09:32,210 --> 00:09:36,080
resolution, I mean, it's really
low resolution. So what we're

147
00:09:36,080 --> 00:09:41,810
hoping at GelSight is that we
are solving all of those issues,

148
00:09:41,840 --> 00:09:45,860
you know, with the, whether it's
the DIGIT which is now you know,

149
00:09:45,860 --> 00:09:49,520
something that is, you know,
completely, you know, mountable

150
00:09:49,520 --> 00:09:55,160
on a robotic hand, right. That's
what it was designed for. With a

151
00:09:55,160 --> 00:09:58,490
price point of $300. That's what
we announced with Facebook. It's

152
00:09:58,490 --> 00:09:59,720
available for $300

153
00:10:01,040 --> 00:10:02,150
Audrow Nash: or meta now?

154
00:10:04,100 --> 00:10:05,690
Youssef Benmokhtar: Yes,
absolutely, absolutely. Right.

155
00:10:06,710 --> 00:10:10,340
And also, we because we're
imaging based, right, the

156
00:10:10,340 --> 00:10:12,860
resolution of our sensor is
actually directly linked to the

157
00:10:12,860 --> 00:10:16,340
resolution of the sensor, the
cameras that we're using the

158
00:10:16,340 --> 00:10:20,690
image sensor we're using. So,
you know, in the case of the

159
00:10:20,690 --> 00:10:24,980
digit, I believe it's a, it's a,
you know, it's a VGA resolution

160
00:10:24,980 --> 00:10:27,200
sensor. So you getting, you
know,

161
00:10:27,230 --> 00:10:30,740
Audrow Nash: so for VGA, that's
like, that's one of the display

162
00:10:30,740 --> 00:10:35,720
ports. And so is that 640 by
480, or 20? By 480. Correct? No,

163
00:10:35,720 --> 00:10:36,560
why would know that? But

164
00:10:36,560 --> 00:10:38,960
Youssef Benmokhtar: okay, yeah,
yeah. So so, you know, suddenly,

165
00:10:38,960 --> 00:10:42,050
you know, you have, you know, a
million plus pixels to play with

166
00:10:42,290 --> 00:10:45,500
all the other technologies out
there will give you in the

167
00:10:45,500 --> 00:10:49,040
resolutions in the 10s, or
hundreds, you know, pixels for

168
00:10:49,040 --> 00:10:52,040
the same surface. And now,
suddenly, you have this

169
00:10:52,040 --> 00:10:57,200
amazingly high resolution
available to you at $300, in

170
00:10:57,200 --> 00:11:00,200
something that you can mount.
So, you know, now, when you

171
00:11:00,200 --> 00:11:03,800
starting to think about
applications, I think you have

172
00:11:03,800 --> 00:11:08,480
something that is actually even
better than the resolution of a

173
00:11:08,510 --> 00:11:13,370
of a human finger. So it puts
things in perspective, I think

174
00:11:13,850 --> 00:11:16,970
AI technology helps to, you
know, bridge that gap that

175
00:11:16,970 --> 00:11:21,200
existed before. That's why
That's why we believe it's

176
00:11:21,200 --> 00:11:27,530
exciting. And for gel sight. You
know, we had also this

177
00:11:27,530 --> 00:11:31,040
reputation of being extremely
expensive and big, you know, our

178
00:11:31,040 --> 00:11:36,200
standard products on the 20 or
$30,000 apiece. But hey, we are,

179
00:11:36,230 --> 00:11:40,370
you know, we are a company
that's able to do things, you

180
00:11:40,370 --> 00:11:44,990
know, for different
applications. And in this $300,

181
00:11:45,260 --> 00:11:47,750
you know, sensor shows that, you
know, we can do things at low

182
00:11:47,750 --> 00:11:48,200
cost.

183
00:11:48,830 --> 00:11:50,870
Audrow Nash: Yes, and I want to
talk about DIGIT quite a bit.

184
00:11:51,230 --> 00:11:53,690
But I want to still talk, I want
to make sure I understand

185
00:11:53,690 --> 00:11:59,420
everything pretty well, before
going into that. So one of the

186
00:11:59,420 --> 00:12:02,210
big things that was really hard
with getting this into robotics

187
00:12:02,210 --> 00:12:06,260
previously was probably that the
sensors were extremely bulky, as

188
00:12:06,260 --> 00:12:13,970
you were saying. And so how have
you guys made it smaller? Like,

189
00:12:13,970 --> 00:12:16,010
how, how have you reduced the
bolt?

190
00:12:17,210 --> 00:12:21,260
Youssef Benmokhtar: It's a great
question. You know, the, what

191
00:12:21,260 --> 00:12:24,740
Wally actually attracted me to
jail side is that at the core of

192
00:12:24,740 --> 00:12:27,020
the technology, which which I
described, and I think you have

193
00:12:27,020 --> 00:12:32,750
a good understanding of now, the
three pieces, you should think

194
00:12:32,750 --> 00:12:36,920
about them as a modular
approach, a design approach, so

195
00:12:37,160 --> 00:12:38,360
we can really be

196
00:12:38,360 --> 00:12:41,000
Audrow Nash: modular and that
they can each be improved

197
00:12:41,030 --> 00:12:41,990
independently,

198
00:12:42,170 --> 00:12:43,820
Youssef Benmokhtar: correct, and
then put back together as a

199
00:12:43,820 --> 00:12:46,070
system. So for example, into
your question about

200
00:12:46,070 --> 00:12:51,290
miniaturization, we can design a
gel material a polymer material

201
00:12:51,290 --> 00:12:54,410
that is specific to an
application like robotics,

202
00:12:54,470 --> 00:13:00,110
right? And actually make them in
any x, y, z dimension that you'd

203
00:13:00,110 --> 00:13:03,620
like, you know, it's almost, you
know, infinite from end to end

204
00:13:03,620 --> 00:13:10,460
design space. And until that we
can, you know, put in LED

205
00:13:10,460 --> 00:13:15,980
illumination, you know, in a
fairly easy way, these are not

206
00:13:16,010 --> 00:13:20,930
big, you know, type of
electronics. And, and then the

207
00:13:20,930 --> 00:13:25,760
challenge becomes more about the
image sensor that you use, and

208
00:13:25,760 --> 00:13:29,030
most importantly, the lens and
the field of view of the lens.

209
00:13:29,180 --> 00:13:34,130
And how close can you get it to,
you know, to this elastomeric

210
00:13:34,130 --> 00:13:37,370
materials that we have, but you
can play with that, depending on

211
00:13:37,370 --> 00:13:38,510
what the application isn't

212
00:13:38,510 --> 00:13:41,390
Audrow Nash: work one more time
really slowly. It's so Marek, or

213
00:13:41,390 --> 00:13:45,380
what is it? Elasto Merrick
sorry. Elasto Merrick. Yeah,

214
00:13:45,380 --> 00:13:45,800
okay.

215
00:13:46,820 --> 00:13:48,710
Youssef Benmokhtar: Yeah, I try
to avoid using it from now on,

216
00:13:48,710 --> 00:13:50,900
but that's yeah, I'm just
thinking they're so

217
00:13:51,980 --> 00:13:54,500
Audrow Nash: clear pop
deformable polymer, Paul, yeah,

218
00:13:54,800 --> 00:13:56,660
Youssef Benmokhtar: it's a gel.
You know, internally, honestly,

219
00:13:56,660 --> 00:14:02,120
we call it gel. The easy way
that we think about it. But But

220
00:14:02,270 --> 00:14:06,890
then it's to your question. So
what we did is that we basically

221
00:14:06,890 --> 00:14:12,350
found what is the right surface
contact surface that would be

222
00:14:12,350 --> 00:14:15,830
attractive to robotics
applications? And then how small

223
00:14:15,830 --> 00:14:21,590
how thin can you make that
sensor by playing around with

224
00:14:21,590 --> 00:14:24,920
the, with the camera module,
basically, and the field of view

225
00:14:24,920 --> 00:14:29,090
of that lens? And, and that's
how you get something like DIGIT

226
00:14:29,120 --> 00:14:33,620
in that kind of size. There are
ways actually, that we have

227
00:14:33,740 --> 00:14:38,300
developed a gel site to make it
even thinner. So it we DIGIT is

228
00:14:38,300 --> 00:14:40,880
not the limit of what how small
we can make things.

229
00:14:40,910 --> 00:14:44,780
Audrow Nash: Yeah. Okay, so we
keep mentioning digit. Let's,

230
00:14:45,230 --> 00:14:46,850
what is digit? Could you tell me
a bit.

231
00:14:47,840 --> 00:14:52,190
Youssef Benmokhtar: So DIGIT is
a basically a tactile sensor is

232
00:14:52,190 --> 00:14:57,410
a digital tactile sensor imaging
base. It's basically in a job

233
00:14:57,410 --> 00:15:02,750
site technology and in a meta
design. Facebook made a I should

234
00:15:02,750 --> 00:15:07,760
say, sorry, has, you know,
identify the need to really have

235
00:15:08,120 --> 00:15:12,740
this small, easy to integrate
into robotics hands and fingers

236
00:15:13,280 --> 00:15:18,440
sensor to be able to develop,
you know, AI algorithms for a

237
00:15:18,440 --> 00:15:22,730
bunch of different applications,
object manipulation, you know,

238
00:15:22,730 --> 00:15:29,600
pose estimation and things like
that. And basically, we are

239
00:15:29,810 --> 00:15:34,280
their commercial partners to
bring bring that sensor to the

240
00:15:34,280 --> 00:15:39,590
world, we share the same vision,
we believe that digital touch

241
00:15:39,590 --> 00:15:44,390
and feel is the next sensor to
be digitized. To do that, yeah,

242
00:15:44,450 --> 00:15:48,380
that's right. And to do that,
you actually just need to make

243
00:15:48,380 --> 00:15:51,830
it easy to use and affordable
and small. So that's, that's,

244
00:15:51,830 --> 00:15:52,850
that's what we're doing
together.

245
00:15:53,660 --> 00:15:59,480
Audrow Nash: Yeah, so DIGIT is
something that meta AI or

246
00:15:59,630 --> 00:16:05,690
formerly Facebook, AI, research,
I don't know, organization or

247
00:16:05,870 --> 00:16:08,150
part of Facebook that does
research and development for

248
00:16:08,150 --> 00:16:12,860
that. So they created DIGIT and
they open sourced it. Correct?

249
00:16:13,100 --> 00:16:17,990
Correct. So it's freely
available online. And then you

250
00:16:18,020 --> 00:16:24,170
guys now are taking this and
building it at scale for this so

251
00:16:24,170 --> 00:16:27,800
that you can buy it, and it's
out of kind of the research lab

252
00:16:27,800 --> 00:16:37,250
and into the world. What, so it
was a research paper with maybe

253
00:16:37,250 --> 00:16:42,770
like a demo and this kind of
thing. How long ago? How long

254
00:16:42,770 --> 00:16:49,940
ago did Facebook or meta
release? This? The DIGIT design?

255
00:16:50,960 --> 00:16:52,910
Youssef Benmokhtar: I believe
it's over a year ago? I don't

256
00:16:52,910 --> 00:16:58,910
know the exact date. Wow. But
over a year ago,

257
00:16:58,940 --> 00:17:02,450
Audrow Nash: yeah. And then how
did you guys? How did you begin

258
00:17:02,450 --> 00:17:09,500
a collaboration to work on this
and produce it at scale? Like,

259
00:17:09,500 --> 00:17:12,740
how did that how did it occur,
that they produce a paper and

260
00:17:12,740 --> 00:17:17,030
now you guys are actually
manufacturing lots of these?

261
00:17:18,470 --> 00:17:20,960
Well, I think the you
know, that's also a great

262
00:17:20,960 --> 00:17:25,100
question to ask Mehta, but my
understanding is that some of

263
00:17:25,100 --> 00:17:29,180
the researchers at MIT, I had
experience with GelSight during

264
00:17:29,210 --> 00:17:33,470
their academic research. And
this is where they've learned

265
00:17:33,470 --> 00:17:35,840
about tactile sensing, they've
learned about the GSI

266
00:17:35,840 --> 00:17:41,390
technology, and you know, kind
of, you know, use that, that

267
00:17:41,390 --> 00:17:47,240
knowledge and gain expertise in
academia, and wanted to actually

268
00:17:47,240 --> 00:17:52,160
focus on AI, I think more than,
than building hardware. But such

269
00:17:52,190 --> 00:17:57,260
a hardware does not did not
exist, and, and hence the need

270
00:17:57,260 --> 00:17:57,860
to design it.

271
00:17:58,760 --> 00:18:00,470
Audrow Nash: And you mean, it
didn't exist, because you guys

272
00:18:00,470 --> 00:18:04,100
have your product line, but it
didn't exist in a way that was

273
00:18:04,130 --> 00:18:10,040
affordable to like, put 10 of
them on to iRobot? Hands, one at

274
00:18:10,040 --> 00:18:12,440
each fingers end? Correct.

275
00:18:12,500 --> 00:18:15,290
Youssef Benmokhtar: And in the
right form factor as well, you

276
00:18:15,290 --> 00:18:17,810
know, we had was way too big,
correct?

277
00:18:19,490 --> 00:18:23,270
Audrow Nash: You know, so did
they come to you? And they were

278
00:18:23,270 --> 00:18:25,490
like, Hey, we think it'd be
really cool if you guys could

279
00:18:25,490 --> 00:18:29,090
work on this or, I mean, can I
know these details? Or can you

280
00:18:29,090 --> 00:18:31,100
disclose them? I'm curious.

281
00:18:31,580 --> 00:18:32,810
Youssef Benmokhtar: You know,
the way I would answer this

282
00:18:32,810 --> 00:18:38,750
question is, I would say, we
have a shared vision. And, you

283
00:18:38,750 --> 00:18:44,360
know, it was very easy to align
on this partnership because of

284
00:18:44,360 --> 00:18:48,740
that shared vision. Yeah, and I
think, you know, when two

285
00:18:48,740 --> 00:18:53,300
parties basically have the same
ultimate goal, which is, you

286
00:18:53,300 --> 00:18:59,330
know, let's bring tactile sensor
to the masses. And, you know,

287
00:18:59,330 --> 00:19:04,640
make it attractive for people to
want to research with it. Then,

288
00:19:04,700 --> 00:19:08,360
you know, the rest actually
became really easy to do on in a

289
00:19:08,360 --> 00:19:11,990
straight if part. And I believe,
you know, and I hope that this

290
00:19:11,990 --> 00:19:14,870
partnership actually is just at
its beginning, and more more

291
00:19:14,870 --> 00:19:15,500
will come from it.

292
00:19:16,370 --> 00:19:19,160
Audrow Nash: Yeah. So So what is
the nature of the partnership?

293
00:19:19,340 --> 00:19:20,120
Exactly.

294
00:19:20,990 --> 00:19:23,750
Youssef Benmokhtar: So at the
moment, it is really about

295
00:19:23,810 --> 00:19:28,040
GelSight, commercializing the
DIGIT design, and that's already

296
00:19:28,100 --> 00:19:31,430
available for for people to
purchase through our online

297
00:19:31,430 --> 00:19:38,990
portal. And it really, that's
the extent of, of what we have

298
00:19:39,020 --> 00:19:43,370
agreed to do at this point. You
know, as I said, you know, more

299
00:19:43,370 --> 00:19:45,650
is being talked about, I think
now, you know, that we've

300
00:19:45,680 --> 00:19:46,550
reached that one.

301
00:19:47,810 --> 00:19:52,100
Audrow Nash: Nice, what can you
hint at what additional steps

302
00:19:52,100 --> 00:19:53,900
will occur or what they might
look like?

303
00:19:54,440 --> 00:19:57,200
Youssef Benmokhtar: Well, I
think, you know, it's going to

304
00:19:57,350 --> 00:20:00,650
touch upon a few different
things, you know, One of them

305
00:20:00,650 --> 00:20:07,730
is, we believe at Dell side that
we can have a complimentary

306
00:20:07,730 --> 00:20:16,760
offering to the DIGIT sensor
that will be attractive to the

307
00:20:16,760 --> 00:20:23,690
robot robotics crowd but also to
the hobbyist market. And this is

308
00:20:23,720 --> 00:20:26,750
basically aligned with our
vision that again, that we want

309
00:20:26,780 --> 00:20:30,890
tactile sensing to be available
for any engineer, any

310
00:20:30,890 --> 00:20:37,850
technician, any hobbyist to use
in their creative moments, for

311
00:20:37,850 --> 00:20:40,490
anything, and I think, to do
that, you need to actually think

312
00:20:40,490 --> 00:20:47,450
beyond DIGIT and just offer a
more universal sensor. So you

313
00:20:47,450 --> 00:20:49,520
know, something that could be
mounted to robotic hand if you

314
00:20:49,520 --> 00:20:53,270
want to, but you can also use it
as a digital microscope and a

315
00:20:53,270 --> 00:20:57,680
high school class. You know,
something like that. Right? So

316
00:20:57,740 --> 00:20:59,810
Audrow Nash: is that is that the
kind of resolution you're

317
00:20:59,810 --> 00:21:02,060
getting with this approach? Or
Yeah,

318
00:21:02,060 --> 00:21:03,950
Youssef Benmokhtar: so what
we're planning to do is actually

319
00:21:03,950 --> 00:21:08,600
having a much higher resolution
sensor than digital. But a

320
00:21:08,600 --> 00:21:14,210
similar or even smaller form
factor. And our partnership with

321
00:21:14,240 --> 00:21:18,290
DIGIT would be with with meta
would be that we will probably

322
00:21:18,290 --> 00:21:21,770
want to leverage their open
source community, and make our

323
00:21:21,770 --> 00:21:25,280
sensor compatible with with
their Python community, you

324
00:21:25,280 --> 00:21:28,280
know, libraries and everything
else like that. So that we have

325
00:21:28,700 --> 00:21:31,310
a kickstart, you know, when
people want to use our sensor,

326
00:21:31,310 --> 00:21:34,580
they already have libraries
accessible to them right away.

327
00:21:35,570 --> 00:21:40,520
So that this is where I see the
next step being. So this is not

328
00:21:40,520 --> 00:21:44,090
something that is done today,
maybe it's you know, I'm going

329
00:21:44,090 --> 00:21:48,380
to be scolded by, by my metal
friends that I'm already talking

330
00:21:48,380 --> 00:21:51,650
about something like this. But,
you know, regardless of that,

331
00:21:51,650 --> 00:21:54,440
you know, this is the direction
we're taking. And this will

332
00:21:54,440 --> 00:21:57,020
happen, because it's a, it's
something that we are jealous I

333
00:21:57,020 --> 00:21:57,530
believe in.

334
00:21:58,310 --> 00:22:00,590
Audrow Nash: And I want to talk
a lot more about the different

335
00:22:00,590 --> 00:22:02,840
libraries or ways of
standardizing this. And it's

336
00:22:02,840 --> 00:22:07,340
quite cool if you make a sort of
universal sensor, or you may

337
00:22:07,370 --> 00:22:11,060
maybe like a universal way of
visualizing touch data and

338
00:22:11,060 --> 00:22:18,650
relating it. But going from
actually creating, alright, so

339
00:22:18,680 --> 00:22:23,180
you had DIGIT was released as a
paper, you guys agreed to start

340
00:22:23,180 --> 00:22:26,870
manufacturing them. I assume
that since it was coming

341
00:22:26,870 --> 00:22:30,800
directly from the research
community, that it wasn't built

342
00:22:30,800 --> 00:22:35,330
in a way that's exactly the
easiest for manufacturing, or

343
00:22:35,330 --> 00:22:39,230
the best way for manufacturing.
Can you tell me a bit about

344
00:22:39,230 --> 00:22:40,850
those challenges? Because I
assume you have to take

345
00:22:40,850 --> 00:22:44,510
basically what exists? And then
like, make it robust and make it

346
00:22:44,990 --> 00:22:49,310
reliable and make or whatever,
grow it up for?

347
00:22:49,520 --> 00:22:51,200
Youssef Benmokhtar: Correct?
Yeah, absolutely correct. You

348
00:22:51,200 --> 00:22:56,300
know, it's always it's always
over simplified, you know, how

349
00:22:56,330 --> 00:22:58,640
difficult it is to take
something that looks like you

350
00:22:58,640 --> 00:23:02,000
can make 10 of them in a lab.
And now suddenly, you need to be

351
00:23:02,000 --> 00:23:06,890
ready to make hundreds and 1000s
That's exactly why I think gel

352
00:23:06,890 --> 00:23:09,260
sites it wasn't the right, you
know, the right partner for

353
00:23:09,260 --> 00:23:13,160
meta, because we already know
how to make products like these,

354
00:23:13,190 --> 00:23:16,160
we have an existing business,
you know, we know how difficult

355
00:23:16,160 --> 00:23:20,420
it is to do in volume and the
repeatable way. So yes, we did

356
00:23:20,420 --> 00:23:26,390
have to learn on the spot,
really quickly about the meta

357
00:23:26,390 --> 00:23:31,580
design, and then how to improve,
you know, some of the

358
00:23:32,120 --> 00:23:36,200
manufacturability issues that we
encountered, as we were always

359
00:23:36,200 --> 00:23:38,780
rebuilding them, but that that
was something that was expected.

360
00:23:38,810 --> 00:23:44,510
But this is also where Joel site
expertise is, we, you know, we

361
00:23:44,540 --> 00:23:50,210
we had some quick cycles of
learning that we did in the

362
00:23:50,210 --> 00:23:54,050
early phases, when you build the
first ones, to make sure that we

363
00:23:54,050 --> 00:23:57,590
have a pretty high yield and
building this gel material for

364
00:23:57,590 --> 00:23:59,750
digit, which mean pretty

365
00:23:59,750 --> 00:24:02,480
Audrow Nash: high yield and
building this Gel it well, like,

366
00:24:03,110 --> 00:24:05,480
you have to manufacture gel, and
then you can cut it up and you

367
00:24:05,480 --> 00:24:09,530
want it to be I don't know, get
a lot of it at once or what. And

368
00:24:09,530 --> 00:24:11,300
some of it has quality issues or

369
00:24:11,780 --> 00:24:13,340
Youssef Benmokhtar: Well, you
know, like like anything like

370
00:24:13,340 --> 00:24:17,390
any any part of a product that
you that you make, you know,

371
00:24:17,390 --> 00:24:21,800
need to pass, you know, some
some specifications. And, you

372
00:24:21,800 --> 00:24:24,680
know, this gel material, which
is kind of the secret sauce, you

373
00:24:24,680 --> 00:24:27,410
know, that we have, and we build
it for different applications,

374
00:24:27,740 --> 00:24:31,070
you have to make sure that it
has the right optical density

375
00:24:31,310 --> 00:24:36,140
that you want that it's cut and,
you know, in the right shape,

376
00:24:36,170 --> 00:24:39,950
and that the coatings are, you
know, opaque, like we talked

377
00:24:39,950 --> 00:24:43,250
about before to make sure that
the light uniform uniformity is

378
00:24:43,250 --> 00:24:48,200
going to be good that you don't
have, you know, an unacceptable

379
00:24:48,200 --> 00:24:51,230
level of cosmetic defects that
will affect image quality, you

380
00:24:51,230 --> 00:24:53,930
know, those kind of things. So,
this is what we're, you know,

381
00:24:54,200 --> 00:25:00,020
experts in and it took, you
know, took us a few cycles

382
00:25:00,050 --> 00:25:03,560
Learning to get right so that we
can start making hundreds of

383
00:25:03,560 --> 00:25:04,940
these are 1000s of these.

384
00:25:07,850 --> 00:25:12,290
Audrow Nash: Okay, so it's
interesting. A would expect that

385
00:25:12,290 --> 00:25:14,810
that's the case with the
challenges of making a lot of

386
00:25:14,810 --> 00:25:17,930
them. Were there any particular
things that came up that, you

387
00:25:17,930 --> 00:25:22,490
know, you had to change? From
the DIGIT design?

388
00:25:23,060 --> 00:25:26,660
Youssef Benmokhtar: You know, I
it, candidly, the biggest

389
00:25:26,660 --> 00:25:32,480
problem we had were components
supply. You know, in these days,

390
00:25:32,510 --> 00:25:34,760
you know, like, I'm sure you've
been hurt hearing around

391
00:25:35,270 --> 00:25:39,590
shortages. And what was the
challenge, I think for both,

392
00:25:39,920 --> 00:25:43,400
both parties actually was to
find replacements compared to

393
00:25:43,400 --> 00:25:48,230
the digits original component
choices, just because of supply

394
00:25:48,230 --> 00:25:51,020
issues. So I would say the
biggest challenge we had was

395
00:25:51,050 --> 00:25:54,410
honestly, around that is
actually, you know, finding

396
00:25:55,010 --> 00:25:58,940
alternative chips and things
like that, qualifying them and

397
00:25:58,940 --> 00:26:01,610
getting our hands on it,
honestly, has been the biggest

398
00:26:01,610 --> 00:26:02,090
challenge.

399
00:26:03,830 --> 00:26:07,070
Audrow Nash: What an interesting
thing. So you had to like, find

400
00:26:07,250 --> 00:26:11,300
it called for a certain part and
you had to swap it in, use

401
00:26:11,300 --> 00:26:15,080
something else and validate that
it did the exact same thing,

402
00:26:15,080 --> 00:26:16,340
Youssef Benmokhtar: correct?
Correct, then, you know, and

403
00:26:16,340 --> 00:26:18,770
develop the firmware because,
you know, the original firmware

404
00:26:18,770 --> 00:26:20,540
was meant for another chip, so
you have to make some

405
00:26:20,540 --> 00:26:23,420
modifications and that kind of
stuff. That honestly was the

406
00:26:23,420 --> 00:26:26,660
biggest challenge. The rest of
us, okay.

407
00:26:28,520 --> 00:26:31,850
Audrow Nash: Okay, so, just and
I haven't I don't think we've

408
00:26:31,850 --> 00:26:36,590
said DIGIT is like, how large is
DIGIT? And what's it? What's its

409
00:26:36,590 --> 00:26:38,060
case? Basically?

410
00:26:40,070 --> 00:26:44,780
Youssef Benmokhtar: Oh, I think
it's about, say, three quarters.

411
00:26:44,780 --> 00:26:48,650
Yeah, it's a little over an inch
deep. I think it's 28

412
00:26:48,680 --> 00:26:52,760
millimeters, if I remember
correctly. Just over an inch.

413
00:26:52,850 --> 00:26:57,500
Yeah. And I think I wouldn't
need to get a specs on that. But

414
00:26:57,860 --> 00:27:02,270
I want to say it's maybe half an
inch, and little bit over maybe

415
00:27:02,270 --> 00:27:06,200
three quarters of an inch in
width. Anyways. Yeah. And then

416
00:27:06,200 --> 00:27:11,420
in height, or then it's probably
another inch in height. Yeah,

417
00:27:11,420 --> 00:27:13,550
slightly below that. Probably.
So it's

418
00:27:13,550 --> 00:27:15,740
Audrow Nash: kind of like an
extra thick human finger.

419
00:27:15,770 --> 00:27:20,990
Correct. In terms of size, and
it has a little pad on it. That

420
00:27:20,990 --> 00:27:22,220
has the gel.

421
00:27:24,320 --> 00:27:26,030
Youssef Benmokhtar: The Delta
data, yeah, the

422
00:27:26,030 --> 00:27:29,090
Audrow Nash: gel material and
the gel material. It's kind of

423
00:27:29,870 --> 00:27:35,150
it's like framed by the case
material. Correct. So you put

424
00:27:35,150 --> 00:27:40,970
something on the gel material.
And it will measure the

425
00:27:40,970 --> 00:27:44,360
deformation there. There's the
edges on the same side as the

426
00:27:44,360 --> 00:27:44,750
gel.

427
00:27:44,810 --> 00:27:46,580
Youssef Benmokhtar: Correct?
Yeah, there is a there is a

428
00:27:46,580 --> 00:27:49,340
bezel I think the bezel is like
one and a half or two

429
00:27:49,370 --> 00:27:55,490
millimeters. I know fairly thin.
Yeah. And the the gel itself is

430
00:27:55,940 --> 00:27:58,070
you know, I forgot what it is
like three to four millimeters

431
00:27:58,070 --> 00:28:05,570
probably high. It kind of a
slightly dome, like, you know

432
00:28:05,570 --> 00:28:09,290
shape just like your finger
would. Basically yeah, yeah.

433
00:28:10,670 --> 00:28:13,460
Audrow Nash: Yeah, like the tip
like the last DIGIT of your

434
00:28:13,460 --> 00:28:14,990
finger. Correct kind of thing.

435
00:28:16,280 --> 00:28:19,310
Youssef Benmokhtar: Yeah, you
know, what's another thing maybe

436
00:28:19,310 --> 00:28:22,790
that would be interesting to
you. The way I look at these

437
00:28:22,790 --> 00:28:26,960
tactile sensors like DIGIT is
almost thinking about having a

438
00:28:26,960 --> 00:28:30,590
camera inside your finger. So
imagine if you had a camera

439
00:28:30,590 --> 00:28:34,250
inside your finger and it would
actually be able to see anything

440
00:28:34,250 --> 00:28:37,940
that the forms your skin as
you're touching things. That's

441
00:28:37,940 --> 00:28:41,420
pretty much what DIGIT is. Yeah,
you know?

442
00:28:42,260 --> 00:28:44,570
Audrow Nash: Uh huh. So just so
I can picture the internals of

443
00:28:44,570 --> 00:28:50,180
it a little bit so you have the
gel surface? Yep. And if so,

444
00:28:50,180 --> 00:28:52,640
then we have the camera and the
camera could be so if the

445
00:28:52,670 --> 00:28:55,880
sensors facing down and the gel
is at the bottom, the camera is

446
00:28:55,880 --> 00:29:00,110
above looking at the gel
Correct? Do we have it does the

447
00:29:00,110 --> 00:29:04,670
camera touch the gel? Or is it
just like a sensor pad that

448
00:29:04,670 --> 00:29:07,640
touches the gel or how do we get
our

449
00:29:08,210 --> 00:29:11,450
Youssef Benmokhtar: know the
camera is is offset from the gel

450
00:29:11,450 --> 00:29:14,630
there's a the gel is mounted you
know think about it mounted on a

451
00:29:14,990 --> 00:29:19,010
like a plastic window if you'd
like okay and the camera is

452
00:29:19,010 --> 00:29:22,070
behind that I guess small
distance you need to have a

453
00:29:22,070 --> 00:29:24,650
minimal you know distance
between the camera and the

454
00:29:25,400 --> 00:29:28,730
Audrow Nash: yeah gel. I was
wondering if you could like use

455
00:29:28,730 --> 00:29:31,850
the gel as a lens or something
like this but I imagine because

456
00:29:31,850 --> 00:29:34,460
it's not like a pinhole camera
you would get a lot of light

457
00:29:34,940 --> 00:29:37,550
going and bouncing all over. So
be very it'd be like a very

458
00:29:37,550 --> 00:29:41,630
blurry image as opposed to a
crisp image kind of thing. So

459
00:29:41,630 --> 00:29:47,240
you need that separation as
opposed to not having a lens or

460
00:29:47,240 --> 00:29:50,090
having a sensor pad directly
into the gel.

461
00:29:50,270 --> 00:29:52,580
Youssef Benmokhtar: You need to
be able to image that area right

462
00:29:52,580 --> 00:29:55,790
so you need a little bit of
distance to be able to see that

463
00:29:55,790 --> 00:29:56,420
surface.

464
00:29:58,490 --> 00:30:02,240
Audrow Nash: Now for robotics
just like wondering, how do you

465
00:30:02,240 --> 00:30:06,320
connect to it? How does it? How
does it work as a sensor? What

466
00:30:06,320 --> 00:30:08,330
exists for libraries? Like all
these things?

467
00:30:09,680 --> 00:30:11,570
Youssef Benmokhtar: Yeah, so,
you know, so connect

468
00:30:11,600 --> 00:30:15,320
connectivity is done through a
USBC type, you know, of

469
00:30:15,320 --> 00:30:19,490
connectivity. And then, you
know, you basically have

470
00:30:19,970 --> 00:30:23,660
Audrow Nash: high data flow or
something through USB C, or was

471
00:30:23,660 --> 00:30:26,900
there any reason to choose it
other than it's a nice ports,

472
00:30:26,900 --> 00:30:26,990
the

473
00:30:26,990 --> 00:30:29,840
Youssef Benmokhtar: most common
port, and also, you know,

474
00:30:30,320 --> 00:30:35,600
robotics actually does care
about real time information. And

475
00:30:35,600 --> 00:30:38,150
so you can run it, you know,
easily at 30 frames a second,

476
00:30:38,480 --> 00:30:42,890
you know, you know, it has even
the capabilities, I think,

477
00:30:42,890 --> 00:30:45,860
should run a little bit faster
than that. But you want to have

478
00:30:45,860 --> 00:30:50,870
real time and USB was was, is
basically a good way to do that.

479
00:30:52,070 --> 00:30:55,640
And then you basically, you
know, you know, program, the

480
00:30:55,640 --> 00:31:00,290
sensor using all the firmware
that meta has made available on

481
00:31:00,290 --> 00:31:05,390
PI touch. So that's how
basically, you, you connect it

482
00:31:05,390 --> 00:31:08,780
to your your computer, have
access all the Python libraries,

483
00:31:09,230 --> 00:31:10,460
and you're ready to go.

484
00:31:11,660 --> 00:31:13,790
Audrow Nash: What, so I don't I
don't know too much about the

485
00:31:13,790 --> 00:31:20,150
available libraries for the what
do they let you do? Like, you

486
00:31:20,150 --> 00:31:23,690
assume you can get 3d
deformation, but is there like,

487
00:31:23,720 --> 00:31:26,510
I mean, there's for vision for
computer vision, there's like

488
00:31:26,540 --> 00:31:30,830
open CV, or open computer vision
library, I believe, started by

489
00:31:30,830 --> 00:31:34,400
Intel. And it's a big open
source library has been around

490
00:31:34,400 --> 00:31:38,030
for a long time. And so that
lets you do a lot of basic

491
00:31:38,060 --> 00:31:41,360
computer vision things. So if
you're working with a camera,

492
00:31:41,360 --> 00:31:43,820
like almost right out of the
box, after you figured out the

493
00:31:43,820 --> 00:31:50,000
install, you can like detect
faces, or do object tracking or

494
00:31:50,000 --> 00:31:54,200
something like this, is there
any such things that let you

495
00:31:54,920 --> 00:31:58,670
kind of identify what you're
touching or identify properties

496
00:31:58,670 --> 00:32:01,640
of what you're touching? Yet,
and these libraries,

497
00:32:01,790 --> 00:32:03,830
Youssef Benmokhtar: you know, I
think the meta team is, is kind

498
00:32:03,830 --> 00:32:06,710
of adding things on a regular
basis, but it's all the basic

499
00:32:06,710 --> 00:32:10,370
things you get are, for example,
you know, the ability to just,

500
00:32:10,400 --> 00:32:13,550
you know, see an image, you
know, so even even a 2d

501
00:32:13,550 --> 00:32:16,370
interpretation of the image or
3d representation of the image,

502
00:32:16,910 --> 00:32:21,230
see where the sensor has been
touched in. So if you look at

503
00:32:21,230 --> 00:32:26,810
the surface area of the sensor,
which area has been touched, you

504
00:32:26,810 --> 00:32:29,600
know, which is an interesting
information, you know, in

505
00:32:29,600 --> 00:32:33,260
robotic application, that they
typically called pose

506
00:32:33,260 --> 00:32:37,520
estimation. And from, that's the
kind of the very basic

507
00:32:37,520 --> 00:32:42,890
information that they give, you
know, the purpose of mirrors, as

508
00:32:42,890 --> 00:32:49,100
far as I understand it, is to
then in turn this into creating

509
00:32:49,520 --> 00:32:56,270
datasets of deformations of that
gel based on the type of objects

510
00:32:56,300 --> 00:33:01,520
that the robotics hand or
gripper is, is manipulating. So,

511
00:33:01,820 --> 00:33:05,780
you know, you kind of train
models to say, you know, let me

512
00:33:05,780 --> 00:33:09,860
grab this example, if you say,
this is, this is a cable, right?

513
00:33:10,130 --> 00:33:13,670
And you basically have your
robot kind of holding it in all

514
00:33:13,670 --> 00:33:17,960
kinds of different, you know,
orientations, and different

515
00:33:17,960 --> 00:33:21,800
forces and things like that, and
all that is captured in their,

516
00:33:22,700 --> 00:33:27,140
you know, in their datasets. And
it's used to basically, you

517
00:33:27,140 --> 00:33:30,530
know, create AI to basically
say, Well, this is how I

518
00:33:30,530 --> 00:33:33,800
recognize that this is a cable,
you know, touching the sensor?

519
00:33:34,070 --> 00:33:37,880
And then can you do things like
that, for example, like, you

520
00:33:37,880 --> 00:33:41,630
know, reorienting that cable and
space, because you want to move

521
00:33:41,630 --> 00:33:46,280
it from A to B, you know, those
kinds of things. So, I Yeah, you

522
00:33:46,280 --> 00:33:46,610
know,

523
00:33:46,940 --> 00:33:50,240
Audrow Nash: to me, I'm saying
it's similar to like, image

524
00:33:50,240 --> 00:33:53,870
segmentation, or something like
this. So we do all of the, when

525
00:33:53,870 --> 00:33:57,350
we had like image net, or some
sort of thing that has a bunch

526
00:33:57,350 --> 00:34:00,440
of labeled images. So we have
cameras, the cameras take

527
00:34:00,530 --> 00:34:02,870
pictures, and then we say, Okay,
that's a cat, that's a tree,

528
00:34:02,870 --> 00:34:06,680
that's what whatever. And then
you do that a lot of times, and

529
00:34:06,680 --> 00:34:10,820
then maybe one approach is you
can have a more complex image,

530
00:34:10,850 --> 00:34:14,090
and you can identify the
different parts that are in it.

531
00:34:14,480 --> 00:34:16,790
And I think now they do that
typically with like bounding

532
00:34:16,790 --> 00:34:20,540
boxes, that they just slide over
the image or something, to try

533
00:34:20,540 --> 00:34:22,700
to figure out where in the image
might be a cat, but they're

534
00:34:22,700 --> 00:34:24,320
getting more and more
sophisticated. And I'm

535
00:34:24,320 --> 00:34:28,340
definitely not aware of this,
but are aware of the like

536
00:34:28,340 --> 00:34:31,910
cutting edge of this research.
But it seems kind of like that,

537
00:34:31,940 --> 00:34:37,880
where the intention is to start
with very simple identifications

538
00:34:37,880 --> 00:34:40,160
of things. And then perhaps
eventually a robot can grab a

539
00:34:40,160 --> 00:34:44,120
chunk of stuff from a messy,
messy desk and identify that it

540
00:34:44,120 --> 00:34:47,990
might have a few cables and
whatever. So it could look for

541
00:34:47,990 --> 00:34:48,770
things or

542
00:34:48,860 --> 00:34:49,970
Youssef Benmokhtar: I think
you're right, I think, you know,

543
00:34:49,970 --> 00:34:54,470
the Holy Grail is actually to be
able to provide that kind of

544
00:34:54,470 --> 00:34:57,830
intelligence to robots the same
way that you've you've mentioned

545
00:34:57,830 --> 00:35:01,220
about image recognition, you
know, forecast And dogs and

546
00:35:01,220 --> 00:35:05,690
other things, right? It's kind
of the same idea is, you know,

547
00:35:05,690 --> 00:35:10,580
if I want to be able to do
complex object manipulation in a

548
00:35:10,580 --> 00:35:14,210
robotic application, or you
know, to do, you know, kidding,

549
00:35:14,240 --> 00:35:18,140
right, and other things like
that, what to do kidding, for

550
00:35:18,140 --> 00:35:21,560
example, if you want to, you
know, take, you know, you have a

551
00:35:21,560 --> 00:35:24,020
box of a whole bunch of
different objects, you don't

552
00:35:24,020 --> 00:35:26,690
really know what those objects
are, but you want to basically

553
00:35:26,690 --> 00:35:31,310
put a certain class of objects
and put them in another box, you

554
00:35:31,310 --> 00:35:35,090
know, but this time classified
by the type of objects. This is

555
00:35:35,090 --> 00:35:38,240
something that actually very
difficult to do. The word

556
00:35:38,240 --> 00:35:40,490
Kidding, kidding. Yes? Like a
kit?

557
00:35:40,520 --> 00:35:42,860
Audrow Nash: You No kidding. So
like you're assembling kits,

558
00:35:42,920 --> 00:35:47,540
correct thing? Correct. Okay.
I'm not heard that before. Yeah.

559
00:35:47,540 --> 00:35:50,810
So if you're, if you're grouping
objects by type or something,

560
00:35:50,960 --> 00:35:53,450
for example, I, yes, go ahead.

561
00:35:53,510 --> 00:35:55,400
Youssef Benmokhtar: You know,
the other thing could be if

562
00:35:55,400 --> 00:35:59,180
you're trying to just assemble
things that today, I really only

563
00:35:59,180 --> 00:36:02,870
done by humans, because humans
have the kind of dexterity you

564
00:36:02,870 --> 00:36:06,860
need to do those kinds of
assembly of complex assemblies,

565
00:36:07,790 --> 00:36:11,990
you know, handling, you know,
cables, or handling, you know,

566
00:36:12,230 --> 00:36:15,770
types of fibers and things like
that are just, you know, really

567
00:36:15,770 --> 00:36:19,940
hard to do for a robot, you need
to have that kind of sensitivity

568
00:36:20,180 --> 00:36:25,190
feel that humans have. So
providing this kind of

569
00:36:25,190 --> 00:36:29,720
perception capability to robots
may allow them to start doing

570
00:36:29,720 --> 00:36:31,460
some of these more complicated
tasks.

571
00:36:32,270 --> 00:36:34,940
Audrow Nash: Gotcha. And I
imagine that it's not terribly

572
00:36:34,940 --> 00:36:38,360
interesting to be like, Okay,
now we can grab this and

573
00:36:38,360 --> 00:36:43,430
identify it as much as it is
that you can use it in like a

574
00:36:43,430 --> 00:36:47,180
sensor fusion kind of context
where you say, I think that I'm

575
00:36:47,180 --> 00:36:50,450
grabbing this, and I grabbed
something. Does it agree with

576
00:36:50,450 --> 00:36:53,810
what I expect to feel given
this? I think that would lead to

577
00:36:53,810 --> 00:36:58,610
more interesting applications of
this kind of thing.

578
00:36:58,730 --> 00:37:00,200
Youssef Benmokhtar: You're
absolutely right. You know, one

579
00:37:00,200 --> 00:37:05,240
thing that's really interesting
is that machine vision, and

580
00:37:05,240 --> 00:37:10,130
computer vision is extensively
used in in robotics today. But

581
00:37:10,130 --> 00:37:12,470
one thing that happens is,
especially in a robotic hand,

582
00:37:12,470 --> 00:37:17,450
for example, is once the hand
grabs something, he can't see

583
00:37:17,450 --> 00:37:20,180
anything is occluded. It's no
idea what it is, right? So I

584
00:37:20,180 --> 00:37:24,470
think complementing vision, with
tactile information, is

585
00:37:24,470 --> 00:37:26,660
something that's going to be
extremely useful.

586
00:37:27,560 --> 00:37:31,220
Audrow Nash: Yeah. Now, so one
thing that I'm wondering as a

587
00:37:31,220 --> 00:37:36,410
roboticist with this is, so say,
I want to like screw in a screw

588
00:37:36,650 --> 00:37:39,800
with this. So I want to pick it
up with my fingers, and I want

589
00:37:39,800 --> 00:37:44,690
to screw it in. So maybe I can
pick it up and identify it. But

590
00:37:44,690 --> 00:37:49,700
I think that highly like I'm
imagining the gel is quite soft

591
00:37:50,000 --> 00:37:53,510
for this. And that deaf
formation might make it hard to

592
00:37:53,510 --> 00:38:00,050
control whatever you're picking
up. Are there? Is this kind of

593
00:38:00,080 --> 00:38:02,090
it? Would you think that this is
correct? And are there

594
00:38:02,090 --> 00:38:05,930
strategies for using these
sensors with tasks do you like,

595
00:38:05,960 --> 00:38:08,600
identify it, and then move a
little lower and then to factor

596
00:38:08,600 --> 00:38:12,020
or higher, so that you can
identify what it is and then

597
00:38:12,020 --> 00:38:16,400
pick it up with rigid grippers
that you kind of know what you

598
00:38:16,400 --> 00:38:20,300
have? Or is it is it more
complex and how you grip it.

599
00:38:20,540 --> 00:38:22,010
Youssef Benmokhtar: So, you
know, first of all, you know,

600
00:38:22,010 --> 00:38:26,150
the gel that we use in robotics
application today is actually

601
00:38:26,150 --> 00:38:30,920
not that soft, at least not to
the human touch is actually it

602
00:38:30,920 --> 00:38:34,850
would feel, you know, it will
have this kind of elasticity

603
00:38:34,850 --> 00:38:38,000
feel to it, but it's still
pretty hard to actually, you

604
00:38:38,000 --> 00:38:42,860
know, if you're grabbing a, you
know, a screw, for example, as

605
00:38:42,860 --> 00:38:49,010
you as you mentioned, you would
actually not really need to, you

606
00:38:49,010 --> 00:38:54,890
know, pass it on to another
robotic arm. To do something

607
00:38:54,890 --> 00:38:57,410
else, you actually will have a
very good understanding of what

608
00:38:57,410 --> 00:39:02,660
the screw is how you know, how
hard you actually grasp, it will

609
00:39:02,660 --> 00:39:05,720
actually give you more
information about it's about its

610
00:39:05,840 --> 00:39:10,100
shape, we actually have done
some experiments that you might

611
00:39:10,100 --> 00:39:14,660
find interesting to us are
actually tactile sensor as a

612
00:39:14,690 --> 00:39:19,610
hardness a relative measurement
of hardness, because same

613
00:39:19,640 --> 00:39:25,760
similar to, to human skin,
right? And human finger, if I'm

614
00:39:26,090 --> 00:39:30,650
pressing on something that is
really, you know, soft, you

615
00:39:30,650 --> 00:39:35,960
know, I really don't have a lot
of feedback on my, on my skin,

616
00:39:35,960 --> 00:39:38,090
it's actually very, very light.
But if it's really a hard

617
00:39:38,090 --> 00:39:42,260
material, I my my my skin will
get indented really fast. Well,

618
00:39:42,260 --> 00:39:44,840
it's the same thing that happens
to us with our sensor. So when

619
00:39:44,840 --> 00:39:48,530
you're holding an object and
actually pressing it, pressing

620
00:39:48,530 --> 00:39:52,010
it against another, it actually
also gives you gives you that

621
00:39:52,040 --> 00:39:54,560
that really interesting
information about the potential

622
00:39:54,560 --> 00:39:58,790
hardness or softness of the of
the object that is touching. So

623
00:39:58,790 --> 00:39:59,480
it's really look

624
00:39:59,480 --> 00:40:04,040
Audrow Nash: at the deformation
of both objects, the gel, and

625
00:40:04,070 --> 00:40:08,480
the objects are kind of infer
the hardness of the object is

626
00:40:08,480 --> 00:40:10,250
Youssef Benmokhtar: it the jail
by itself would tell you how

627
00:40:10,250 --> 00:40:13,820
hard the object is that that
whatever you're holding is in

628
00:40:13,820 --> 00:40:19,970
contact with, you know, just
just by, again, you know, just

629
00:40:19,970 --> 00:40:25,550
imagine we have a video, I
think, on our libraries of a

630
00:40:25,550 --> 00:40:30,620
gripper holding a fork. And then
we have hardness samples. And as

631
00:40:30,620 --> 00:40:34,580
you push the fork into the
harness sample, you see how the

632
00:40:34,670 --> 00:40:37,070
tactile sensor deforms,
depending on the hardness of

633
00:40:37,070 --> 00:40:40,910
that sample, and the hotter it
is and the more deforms, right?

634
00:40:40,910 --> 00:40:44,900
So this is actually how you get
a relative hardness measurement.

635
00:40:45,710 --> 00:40:48,620
Audrow Nash: does this require
that you have 3d knowledge of

636
00:40:48,620 --> 00:40:51,200
whatever the object is that
you're doing? Or at least you

637
00:40:51,200 --> 00:40:54,230
know, like, say the width of it,
or how far it is between the two

638
00:40:54,230 --> 00:40:57,950
sensors are? How much of it
should be pushed into the

639
00:40:58,460 --> 00:40:59,060
sensor?

640
00:41:00,200 --> 00:41:02,240
Youssef Benmokhtar: Um, I think
3d helps, but I don't think it's

641
00:41:02,240 --> 00:41:03,680
even necessary.

642
00:41:04,550 --> 00:41:07,730
Audrow Nash: Oh, it's, I think,
intuitively see how it works. So

643
00:41:08,120 --> 00:41:09,410
Youssef Benmokhtar: well,
because you know, all I really

644
00:41:09,410 --> 00:41:12,020
care about is, you know, for
example, is the depth of the

645
00:41:12,020 --> 00:41:15,800
indentation. But not necessarily
the exact shape of the object,

646
00:41:16,100 --> 00:41:19,910
you know, is how deep do you get
into the gel their formation,

647
00:41:19,910 --> 00:41:22,760
for example. But if you have the
shape, then you can also say,

648
00:41:22,760 --> 00:41:25,130
oh, now I'm starting to
recognize that that's the tip of

649
00:41:25,130 --> 00:41:29,780
a, of a fork, for example.
Because you can add that to

650
00:41:29,810 --> 00:41:31,520
object recognition.

651
00:41:33,050 --> 00:41:35,390
Audrow Nash: So you think if
we're picking up like a screw or

652
00:41:35,390 --> 00:41:40,070
something, and we have, say you
have the two digits, or whatever

653
00:41:40,070 --> 00:41:43,610
would be next after DIGIT with
higher resolution, and you have

654
00:41:43,610 --> 00:41:48,230
it between the two sensor pads,
between the gel on the both of

655
00:41:48,230 --> 00:41:54,020
the sensors. Now, you can kind
of see how it is pressed into

656
00:41:54,020 --> 00:41:58,190
both of the sensors. And you can
infer in 3d how the screw is

657
00:41:58,220 --> 00:42:01,550
oriented, correct with respect
to the sensor, and then from

658
00:42:01,550 --> 00:42:04,250
there, you can figure out how
it's oriented with respect to

659
00:42:04,250 --> 00:42:06,260
the rest of the robot, because
you know, how the fingers are

660
00:42:06,260 --> 00:42:09,980
positioned with respect to the
rest of the robot, this kind of

661
00:42:09,980 --> 00:42:10,220
thing?

662
00:42:10,250 --> 00:42:12,530
Youssef Benmokhtar: Absolutely,
that that is possible today, we

663
00:42:12,530 --> 00:42:17,570
actually have, we're doing that
at a job site, we, we build,

664
00:42:17,840 --> 00:42:24,470
basically, a 3d point cloud
model of an object that the that

665
00:42:24,470 --> 00:42:30,170
we want to our grippers to, to
manipulate. And based on just

666
00:42:30,170 --> 00:42:37,310
the contact area, we actually
able to infer the orientation in

667
00:42:37,310 --> 00:42:41,510
3d of the of the 3d Point Cloud,
which is, which is a really cool

668
00:42:41,510 --> 00:42:42,200
thing to do. Yeah.

669
00:42:43,100 --> 00:42:46,370
Audrow Nash: So when you say
point cloud, you mean, mesh,

670
00:42:46,550 --> 00:42:49,220
kind of thing. So it's not
you're using your sensor to get

671
00:42:49,220 --> 00:42:52,010
the 3d information. And it's
creating like a mesh

672
00:42:52,010 --> 00:42:55,130
representation of the object
that you see. And like a 3d

673
00:42:55,130 --> 00:42:59,030
graphics or not, I was thinking
LIDAR initially, which you get

674
00:42:59,030 --> 00:43:01,250
all the points, and then you can

675
00:43:01,310 --> 00:43:03,530
Youssef Benmokhtar: Yeah, it's
not Yeah, I think a mesh is a

676
00:43:03,530 --> 00:43:05,540
good, good explanation to it for
it.

677
00:43:06,260 --> 00:43:07,730
Audrow Nash: Gotcha. Just making
sure I understand.

678
00:43:08,990 --> 00:43:09,980
Youssef Benmokhtar: No problem.
Okay.

679
00:43:11,120 --> 00:43:16,880
Audrow Nash: Then, so, you know,
what, meta or formerly Facebook?

680
00:43:18,170 --> 00:43:22,040
Like, so I know, they had the
one robot that would turn and

681
00:43:22,040 --> 00:43:25,850
look at you. And it was used for
like video calls and things like

682
00:43:25,850 --> 00:43:29,360
this, like an echo with a neck
kind of thing. Amazon Echo with

683
00:43:29,360 --> 00:43:34,790
a neck? Do you know what their
interest is in tactile sensing

684
00:43:34,790 --> 00:43:38,390
and find manipulation? Are they
going to get more into robotics

685
00:43:38,390 --> 00:43:40,100
or any ideas here?

686
00:43:41,240 --> 00:43:45,380
Youssef Benmokhtar: I think it
will be a bit of a relation of

687
00:43:45,380 --> 00:43:48,200
mine. Well, it's definitely
started as research. But I think

688
00:43:48,200 --> 00:43:56,090
the the idea of providing this
intelligent perception tool to

689
00:43:56,090 --> 00:44:04,580
robots is what is compelling to
meta, as you imagine, you know,

690
00:44:04,580 --> 00:44:11,420
robots being able to do more and
more tasks. It became obvious to

691
00:44:11,420 --> 00:44:15,140
them that it needed to have
additional sensing capability.

692
00:44:15,590 --> 00:44:21,260
And that vision and sound was
just not enough for robots to be

693
00:44:21,260 --> 00:44:24,410
able to, to do the kind of
complex tasks that the human

694
00:44:24,410 --> 00:44:28,910
does. And, you know, I think,
you know, in their very grand

695
00:44:28,910 --> 00:44:32,330
vision, I believe that Robotics
has a place in their Metaverse

696
00:44:32,330 --> 00:44:38,150
story, in the sense that, you
know, you have to imagine a

697
00:44:38,150 --> 00:44:40,640
Audrow Nash: verse story, you
mean the kind of 3d world

698
00:44:40,670 --> 00:44:41,480
they're creating?

699
00:44:41,720 --> 00:44:43,940
Youssef Benmokhtar: Correct? I
think, you know, you know, I

700
00:44:43,940 --> 00:44:48,410
look I define, you know, I have
my own simple definition of

701
00:44:48,410 --> 00:44:51,290
Metaverse is really basically
the, you know, the the

702
00:44:51,290 --> 00:44:54,800
integration of the digital and
the physical space into one. And

703
00:44:54,800 --> 00:45:00,980
to do that, you know, you want
to have the ability to replicate

704
00:45:00,980 --> 00:45:03,980
or duplicate any task that
happens in the, in the physical

705
00:45:03,980 --> 00:45:06,830
world in another world. And
robotics is part of that other

706
00:45:06,830 --> 00:45:10,700
world, although it is a physical
object, or equipment, you know,

707
00:45:10,700 --> 00:45:15,200
you want it to be able to
replicate what humans do to

708
00:45:15,200 --> 00:45:19,700
provide, you know, services just
like a human would do. So if you

709
00:45:19,700 --> 00:45:22,610
if you imagine, for example,
doing remote collaboration

710
00:45:22,640 --> 00:45:26,810
through a robot, you know, or
somebody who's coming to your,

711
00:45:26,900 --> 00:45:30,830
you know, a robot coming to your
house to do house cleaning, or

712
00:45:30,830 --> 00:45:36,800
to, you know, be your, you know,
the person that's actually

713
00:45:37,190 --> 00:45:41,540
bringing you water, if you're in
cabinet incapacitated in bed or

714
00:45:41,540 --> 00:45:44,240
something, because you're sick
or something, well, if you don't

715
00:45:44,240 --> 00:45:46,760
have those capabilities, I don't
think you're going to be able to

716
00:45:46,880 --> 00:45:50,480
perform those kinds of tasks
like a human would. So and

717
00:45:50,480 --> 00:45:53,960
that's in that perspective, I
think this kind of research is

718
00:45:54,350 --> 00:45:57,200
probably very attractive to them
in the long run.

719
00:45:58,400 --> 00:46:00,500
Audrow Nash: Is there is there
work on kind of the other side

720
00:46:00,500 --> 00:46:04,700
of this where it's, so right now
your sensor allows you to get

721
00:46:04,700 --> 00:46:10,220
really accurate 3d deformation
information, so you can push an

722
00:46:10,220 --> 00:46:13,070
object into it, you can see the
surface I like the videos, or

723
00:46:13,070 --> 00:46:15,650
the pictures are amazing. Like,
where you see a fingerprint? Do

724
00:46:15,650 --> 00:46:20,000
you see the $1? I think I think
I saw that somewhere where you

725
00:46:20,000 --> 00:46:24,320
see like a $1? Or if you put it
on $100. Bill, yeah. And see the

726
00:46:24,320 --> 00:46:29,270
press throughout the like,
that's crazy. Yeah. But is there

727
00:46:29,270 --> 00:46:32,090
is there work in the other side
of this, where, okay, we have

728
00:46:32,090 --> 00:46:37,670
this detail 3d information, can
we display it elsewhere? This

729
00:46:37,670 --> 00:46:42,230
kind of thing. So like, if I
push into it, and I feel like

730
00:46:42,290 --> 00:46:45,110
like, say, my finger drags
across a larger one of these

731
00:46:45,110 --> 00:46:50,930
sensors, can that be replayed in
a 3d space some other way?

732
00:46:52,040 --> 00:46:55,040
Youssef Benmokhtar: So I think
you're, you know, it's

733
00:46:55,040 --> 00:46:56,840
Audrow Nash: outside of what
your company does with Joe?

734
00:46:57,560 --> 00:46:59,810
Youssef Benmokhtar: Not
completely, because I think what

735
00:46:59,810 --> 00:47:02,930
you just described is, I mean,
to me and tell me if I if I

736
00:47:02,930 --> 00:47:06,800
understood correctly, what your
question is, um, you know, I

737
00:47:06,800 --> 00:47:12,110
look at tactile sensing being
the, you know, the the input to

738
00:47:12,140 --> 00:47:16,730
another output, which is
haptics. Right? So what you just

739
00:47:16,730 --> 00:47:21,830
described to me is, okay, if I,
if I know how it feels right to

740
00:47:21,830 --> 00:47:25,880
touch it with my sensor, I give
you a digital signature of that

741
00:47:25,880 --> 00:47:29,930
texture of that feeling. Right.
So what do I do with that? And I

742
00:47:29,930 --> 00:47:32,180
think once you do with that, one
of the things you can do with

743
00:47:32,180 --> 00:47:36,200
that is actually that becomes
the input that you need to have

744
00:47:36,200 --> 00:47:39,530
true to life haptics
experiences, right? Because if,

745
00:47:39,560 --> 00:47:42,980
you know, eventually, one day
haptic technologies would be

746
00:47:42,980 --> 00:47:47,990
just as high resolution as our
sensor technology. And they've

747
00:47:47,990 --> 00:47:51,620
been in and they're gonna need
right to know, well, how do I?

748
00:47:51,650 --> 00:47:56,780
How does woodgrain feel? How
does cotton feel? How's that

749
00:47:56,810 --> 00:48:02,240
silk feel? How does glass feel.
And I don't see how you get that

750
00:48:02,240 --> 00:48:06,200
information. Without a sensor
like ours, which gives you

751
00:48:06,530 --> 00:48:09,800
millions of pixels of
information to derive a digital

752
00:48:09,800 --> 00:48:13,550
signature of any texture out
there. So when you think about

753
00:48:13,700 --> 00:48:17,360
the need one day, to have a
digital twin of all the surfaces

754
00:48:17,360 --> 00:48:21,170
in the world, all the feeling
the textures of materials in the

755
00:48:21,170 --> 00:48:24,980
world, you're going to need to
characterize them through a

756
00:48:24,980 --> 00:48:28,520
digital tactile sensor. And
that's going to be very useful

757
00:48:28,520 --> 00:48:30,950
to people working in haptics, in
my opinion,

758
00:48:32,330 --> 00:48:36,920
Audrow Nash: the combination of
those, so if you if you go from

759
00:48:37,070 --> 00:48:43,850
good texture sensing to haptics
that makes me that to me with

760
00:48:44,240 --> 00:48:48,290
meta, makes a lot of sense, it
would be kind of like, Ready

761
00:48:48,290 --> 00:48:51,620
Player One or something like
this, where you have like,

762
00:48:51,650 --> 00:48:53,060
sensations and stuff.

763
00:48:53,210 --> 00:48:54,860
Youssef Benmokhtar: Yeah, I
think, you know, we're, what

764
00:48:54,860 --> 00:48:57,530
kind of the microphone to the
speaker, you know, if I use the

765
00:48:57,530 --> 00:49:02,150
sound analogy, right, okay. And
I think in our world, you know,

766
00:49:02,180 --> 00:49:05,630
where the input to haptics and I
think that's, that's just a

767
00:49:05,690 --> 00:49:07,970
simple way to look at it, you
know, where, yeah, where the

768
00:49:07,970 --> 00:49:10,850
camera work with the camera to
the display. You know, that's,

769
00:49:10,850 --> 00:49:12,770
that's, that's how I look at our
company.

770
00:49:13,640 --> 00:49:16,700
Audrow Nash: Yep. And so now,
you mentioned at the beginning,

771
00:49:17,390 --> 00:49:21,590
how the digitization of touch,
can you tell me a bit about kind

772
00:49:21,590 --> 00:49:24,020
of what you believe are the
implications of this and how

773
00:49:24,020 --> 00:49:26,990
important it will be and how
technology will go that way?

774
00:49:28,430 --> 00:49:32,210
Youssef Benmokhtar: Well, I, we
believe it will say that

775
00:49:32,240 --> 00:49:35,690
honestly, that the next sense to
be digitized this touch, vision

776
00:49:35,690 --> 00:49:39,890
was first and we know what
happens once CMOS sensors

777
00:49:39,890 --> 00:49:43,610
became, you know, broadly
available, not only obviously,

778
00:49:43,880 --> 00:49:44,840
it helped to and

779
00:49:44,840 --> 00:49:46,640
Audrow Nash: that's what they're
made out of, what is it

780
00:49:46,640 --> 00:49:50,450
complementary metal oxide? I
don't remember. Yeah, I

781
00:49:52,220 --> 00:49:53,000
Youssef Benmokhtar: remember, I
think

782
00:49:53,330 --> 00:49:56,030
Audrow Nash: so. metal oxides,
so that's what those are made

783
00:49:56,030 --> 00:49:58,790
Youssef Benmokhtar: of. Yeah,
but those digits basically it

784
00:49:58,820 --> 00:50:03,560
translated photonic information
to electronic, you know, an

785
00:50:03,560 --> 00:50:09,410
electronic signal. And, you
know, and today it's used

786
00:50:09,560 --> 00:50:12,500
Audrow Nash: to get digital
images as opposed to like, the

787
00:50:12,500 --> 00:50:15,830
old, I don't know, film roll,
correct. Like,

788
00:50:15,860 --> 00:50:18,110
Youssef Benmokhtar: they're
really original, you know, you

789
00:50:18,110 --> 00:50:20,330
know, picture taking
technologies, you know, that

790
00:50:20,360 --> 00:50:26,270
that, you know, with with the,
you know, the silver oxide

791
00:50:26,270 --> 00:50:29,300
things and you know that Kodak
was, you know, famous for for a

792
00:50:29,300 --> 00:50:32,750
while. But so we digitize that,
digitize that, and then we

793
00:50:32,750 --> 00:50:35,690
basically make copies, yeah, you
can make. So first of all,

794
00:50:35,690 --> 00:50:39,230
you're able to miniaturize it,
make it, you know, widely and

795
00:50:39,230 --> 00:50:41,810
broadly available to everybody
be able to take pictures,

796
00:50:41,810 --> 00:50:44,540
videos, and so on. But most
importantly, it actually allowed

797
00:50:44,540 --> 00:50:47,960
computer vision to take off
because now you have access to

798
00:50:48,470 --> 00:50:51,050
the, you know, billions and
billions and billions of images

799
00:50:51,050 --> 00:50:54,470
to be able to derive, you know,
information from using machine

800
00:50:54,500 --> 00:50:57,800
learning and deep learning
techniques. You know, and then

801
00:50:57,800 --> 00:51:01,490
audio went through the same
revolution. You know, without

802
00:51:01,490 --> 00:51:05,150
digital audio, there would be no
speech recognition. And, you

803
00:51:05,150 --> 00:51:09,710
know, no, Alexa, no, Google now
No, Siri, you know, no music

804
00:51:09,710 --> 00:51:11,960
streaming, you know, like, no,
no, Spotify or anything like

805
00:51:11,960 --> 00:51:12,890
that. No Apple Music.

806
00:51:13,820 --> 00:51:15,530
Audrow Nash: We'd ever record
player and that'd be it.

807
00:51:15,560 --> 00:51:17,600
Youssef Benmokhtar: Yeah, which,
which I liked a lot to the

808
00:51:17,600 --> 00:51:20,810
handle. Exactly. It sounds
really good. But but none of

809
00:51:20,810 --> 00:51:23,090
these other things would have
happened, because now we have,

810
00:51:23,120 --> 00:51:27,530
again, you know, the, you know,
trillions of hours of sound and

811
00:51:27,560 --> 00:51:32,600
audio bits that can be used for
algorithms to train and respond

812
00:51:32,600 --> 00:51:34,190
to the next step

813
00:51:34,190 --> 00:51:39,500
Audrow Nash: rise. I'm surprised
that video or images came before

814
00:51:39,500 --> 00:51:44,270
sound. To me, it seems like
sound is simpler, because it's

815
00:51:44,270 --> 00:51:47,030
one dimensional, as opposed to
images. But, I mean, I guess

816
00:51:47,030 --> 00:51:48,770
we've been interested in cameras
for a long time,

817
00:51:48,770 --> 00:51:51,380
Youssef Benmokhtar: well, you
know, the human, the human

818
00:51:51,380 --> 00:51:56,720
brain, you know, 30% of our
brain activity is used by the

819
00:51:56,720 --> 00:51:59,990
visual cortex, right? So, I'm
not surprised that we were more

820
00:51:59,990 --> 00:52:06,860
attracted to sound to to audio
to video, sorry, then. But, but

821
00:52:06,860 --> 00:52:09,770
I, I think the next one is
really touch, we are

822
00:52:09,920 --> 00:52:14,150
multimodality creatures, that,
you know, for humans to really

823
00:52:14,150 --> 00:52:18,920
do what they do best they need
all of their senses. And, you

824
00:52:18,920 --> 00:52:23,390
know, the next one that that I
think is ripe for digitization

825
00:52:23,420 --> 00:52:28,910
is tactile, or touch, touch and
feel. And I think it's going to

826
00:52:28,910 --> 00:52:32,840
open up a brand new type of, of,
of applications, you know,

827
00:52:32,840 --> 00:52:35,870
starting with, you know, with
robotics, but also some of the

828
00:52:35,870 --> 00:52:38,540
other activities that we've been
doing a gel side and, you know,

829
00:52:38,870 --> 00:52:43,580
in understanding surfaces and
features of surfaces for years.

830
00:52:43,580 --> 00:52:43,940
Now,

831
00:52:44,870 --> 00:52:46,730
Audrow Nash: you want to mention
some of the other applications

832
00:52:46,730 --> 00:52:47,840
that use this technology.

833
00:52:47,870 --> 00:52:49,490
Youssef Benmokhtar: Sure, you
know, I think at a really high

834
00:52:49,490 --> 00:52:57,140
level, we have found that we are
really nice fit whenever we

835
00:52:58,670 --> 00:53:02,180
count an application that has
been using actually human touch.

836
00:53:02,450 --> 00:53:07,370
So believe it or not, in
aerospace, for example, there

837
00:53:07,370 --> 00:53:11,870
are still some companies that
are using the fingernail test

838
00:53:11,870 --> 00:53:18,230
test to decide if a scratch on a
part is a problem or not a

839
00:53:18,230 --> 00:53:20,750
problem basically, meaning that
it needs to be reworked or

840
00:53:20,750 --> 00:53:24,230
tossed. By basically just finger
meant notice, well, basically,

841
00:53:24,230 --> 00:53:26,000
you put your finger in the
scratch and you actually feel

842
00:53:26,000 --> 00:53:29,600
how deep it is, like you say,
Well, yeah, that one that think

843
00:53:29,600 --> 00:53:32,540
is too deep, we need to do
something about it. That's

844
00:53:32,540 --> 00:53:35,360
crazy, it is crazy, absolutely
crazy. But for us, you know,

845
00:53:35,360 --> 00:53:40,700
using our sensor, they able to
get now repeatable, accurate,

846
00:53:40,730 --> 00:53:44,600
fast measurement, quantitative,
not subjective, and you can make

847
00:53:44,600 --> 00:53:47,630
decisions right away that are
the right decisions every time.

848
00:53:49,250 --> 00:53:52,610
And our, our technology is the
only one that allows to do that,

849
00:53:52,610 --> 00:53:57,260
because vision is not very
effective on metallic surfaces

850
00:53:57,260 --> 00:54:00,080
that are, you know, hard to take
pictures of it's very highly

851
00:54:00,080 --> 00:54:04,670
reflective, and so on again, you
know, definitely yeah, but the

852
00:54:04,700 --> 00:54:07,160
the beauty of art technology,
because it's such the same way

853
00:54:07,160 --> 00:54:10,550
as human touch. It doesn't
really care what the surface

854
00:54:10,640 --> 00:54:14,150
properties are, whether it's
like, you know, glass metal, you

855
00:54:14,150 --> 00:54:16,670
know, you know, transparent,
translucent and we don't care

856
00:54:16,700 --> 00:54:21,500
reflective, you know, we you
know, we wire sensor with the

857
00:54:21,500 --> 00:54:23,540
foam to any material, it
doesn't, it doesn't really

858
00:54:23,540 --> 00:54:28,040
matter. So, this is where we
have to put the seen success and

859
00:54:28,040 --> 00:54:32,570
our in our initial commercial
efforts have been around

860
00:54:32,930 --> 00:54:36,980
providing measurement
capabilities to companies that

861
00:54:36,980 --> 00:54:42,410
are interested in understanding
specific features in their

862
00:54:42,410 --> 00:54:47,330
applications, like scratches and
dents in aerospace or, you know,

863
00:54:47,330 --> 00:54:50,510
measuring coatings in the paint
shop in automotive, I mean,

864
00:54:50,510 --> 00:54:56,360
it's, it's basically anytime
that you have I think human

865
00:54:56,360 --> 00:55:00,230
touch being used or where, where
basically using a cow A

866
00:55:00,260 --> 00:55:02,570
traditional camera system just
not going to work because of the

867
00:55:02,570 --> 00:55:04,460
type of material that that we're
dealing with.

868
00:55:05,090 --> 00:55:10,610
Audrow Nash: Yeah, shiny ones.
Exactly. Okay, yeah, that'll be

869
00:55:10,610 --> 00:55:15,140
cool if touch becomes digitized.
And then we have a way of

870
00:55:15,140 --> 00:55:17,540
communicating, and then it can
maybe enable all the haptic

871
00:55:17,780 --> 00:55:20,750
stuff that we were speaking
earlier. Correct. Really, really

872
00:55:20,750 --> 00:55:21,080
cool.

873
00:55:21,440 --> 00:55:24,170
Youssef Benmokhtar: Yes, I've
tried many of the current

874
00:55:24,170 --> 00:55:26,900
haptics technologies. And it's
just a very disappointing

875
00:55:26,900 --> 00:55:32,990
experience. It's basically, you
know, the vibrations you feel,

876
00:55:33,080 --> 00:55:36,620
regardless of what you're
supposed to be touching in a

877
00:55:36,620 --> 00:55:41,060
digital form. And that's,
that's, I think, past the first

878
00:55:41,060 --> 00:55:44,120
second of Oh, wow, I'm feeling
something, you actually just

879
00:55:44,120 --> 00:55:47,690
say, Yeah, but that's not how
it's supposed to feel. And they

880
00:55:47,690 --> 00:55:50,390
have really no other way. I
think today, you know, all I've

881
00:55:50,390 --> 00:55:56,660
seen is varying the varying the
frequency, or whatever technique

882
00:55:56,660 --> 00:55:56,810
they

883
00:55:56,870 --> 00:56:00,860
Audrow Nash: do with a pen or
something, and it will you drag

884
00:56:00,860 --> 00:56:04,490
it across a surface, and it kind
of spoofs by putting forces,

885
00:56:04,520 --> 00:56:08,540
Youssef Benmokhtar: for example,
for example, if it's, if it's

886
00:56:08,540 --> 00:56:11,060
haptic glove, you know,
sometimes they have, you know,

887
00:56:11,060 --> 00:56:14,030
kind of vibrating membranes on
your tip. So you basically

888
00:56:14,030 --> 00:56:16,940
change the vibration, you feel
that you're touching something.

889
00:56:17,840 --> 00:56:19,580
Audrow Nash: It's a similar
approach to like how sound

890
00:56:19,580 --> 00:56:23,120
works, right? Because I mean,
we, with the digital sound, you

891
00:56:23,120 --> 00:56:25,520
represent different frequencies,
and then you combine all those

892
00:56:25,520 --> 00:56:29,090
frequencies together at their
respective amplitudes. And then

893
00:56:29,090 --> 00:56:34,460
you get the appropriate sounds.
Kind of like that. They're

894
00:56:34,460 --> 00:56:37,310
emulating that but in a touch
space to try and you're saying

895
00:56:37,340 --> 00:56:40,070
at the current moment, it's not
very convincing. No,

896
00:56:40,130 --> 00:56:43,280
Youssef Benmokhtar: it's not the
resolution. And, and it's not

897
00:56:43,280 --> 00:56:44,930
actually matching what it's
supposed to be.

898
00:56:46,160 --> 00:56:49,400
Audrow Nash: Do, are there any
technologies that you know of in

899
00:56:49,400 --> 00:56:53,870
this space that are promising?
Or maybe we get the really good

900
00:56:53,870 --> 00:56:57,950
touch information? And then
that'll help us have that? I

901
00:56:57,950 --> 00:57:01,760
don't know, we'll use that good
information to build better

902
00:57:01,790 --> 00:57:04,040
emulations of what they look
like this kind of

903
00:57:04,040 --> 00:57:07,190
Youssef Benmokhtar: thing I'm
not aware of I mean, I'm aware

904
00:57:07,190 --> 00:57:10,640
of a lot of companies working on
it. So I'm sure that progress

905
00:57:10,640 --> 00:57:14,930
will be made. It is a difficult
problem. I haven't seen anybody

906
00:57:14,930 --> 00:57:20,930
who cracked it yet. But I do
hope that the digitization of

907
00:57:20,930 --> 00:57:23,450
tactile sensing will help
haptics companies because it

908
00:57:23,450 --> 00:57:26,450
will provide them with, you
know, a library of how things

909
00:57:26,450 --> 00:57:29,570
should feel. And I think that's,
that's an important part of it.

910
00:57:30,710 --> 00:57:33,320
Audrow Nash: Oh, yeah, that'd be
nice, though. It feels like so

911
00:57:33,320 --> 00:57:36,830
I'm not very aware of much
research in the haptic space.

912
00:57:37,310 --> 00:57:40,400
But a lot of it seems to be
like, can we emulate this

913
00:57:40,400 --> 00:57:44,060
texture? Or can we classify this
texture in a good way that we

914
00:57:44,060 --> 00:57:46,880
can possibly emulate later, and
this kind of thing, and if you

915
00:57:46,880 --> 00:57:49,640
have really good information
there than that, I mean,

916
00:57:49,640 --> 00:57:52,040
especially like, if I'm a
researcher that's trying to do

917
00:57:52,040 --> 00:57:56,000
haptics things. And I go use one
of your sensors and generate a

918
00:57:56,000 --> 00:57:58,850
whole library of what like, say,
a woodgrain looks like and then

919
00:57:58,850 --> 00:58:03,770
from there, I can randomly
sample or, I don't know, build a

920
00:58:03,770 --> 00:58:07,160
model based on all that data
that I just took myself, which

921
00:58:07,160 --> 00:58:07,940
is really awesome.

922
00:58:08,060 --> 00:58:09,830
Youssef Benmokhtar: Right? And
you know, what, one thing that I

923
00:58:09,830 --> 00:58:14,540
think also, you know, might help
to accelerate, you know, the

924
00:58:14,540 --> 00:58:17,930
adoption of digital touch, I
think, is also the the use of

925
00:58:19,370 --> 00:58:25,910
this digital understanding of a
surface. For applications like,

926
00:58:27,980 --> 00:58:31,730
you know, let's say, you know,
I'm a textile company, I've

927
00:58:31,730 --> 00:58:36,740
designed something. And in the
US, I'm having it made in

928
00:58:36,860 --> 00:58:43,010
Southeast Asia. And one way to
verify that what they've made is

929
00:58:43,010 --> 00:58:45,710
exactly what I want is actually
to compare the digital signature

930
00:58:45,800 --> 00:58:49,700
of it. Oh, that's super cool,
right? Which today, they don't

931
00:58:49,700 --> 00:58:51,890
really have I think the only way
they really do it is by

932
00:58:51,890 --> 00:58:52,940
exchanging samples.

933
00:58:54,140 --> 00:58:57,230
Audrow Nash: Hmm. Right. You're
saying like, if I want something

934
00:58:57,230 --> 00:58:59,390
from some company, and I say it
has to be made to my

935
00:58:59,390 --> 00:59:02,210
specifications, and they say,
Oh, I've done it, you can say,

936
00:59:02,240 --> 00:59:07,130
Oh, I've padded it everywhere.
And I see that the model is, I

937
00:59:07,130 --> 00:59:10,730
don't know, not within tolerance
in this one dimension or the

938
00:59:10,730 --> 00:59:13,040
wrong shape, or whatever, it
might be something like that. So

939
00:59:13,040 --> 00:59:14,060
you can verify

940
00:59:14,180 --> 00:59:15,500
Youssef Benmokhtar: it, you
would verify the texture.

941
00:59:15,560 --> 00:59:18,920
Exactly, you know, it does the
texture match what I designed,

942
00:59:19,250 --> 00:59:22,070
right, so I'm designing it here,
I want the texture to feel this

943
00:59:22,070 --> 00:59:25,340
way. Here's a digital picture of
what that texture should feel

944
00:59:25,340 --> 00:59:29,780
like you know, build it and then
measure the digital signature on

945
00:59:29,780 --> 00:59:31,160
your end and see if it matches

946
00:59:32,420 --> 00:59:36,980
Audrow Nash: be cool if this was
also used for like counterfeits

947
00:59:37,070 --> 00:59:41,030
and things for like say like a
high end clothing brand. They're

948
00:59:41,030 --> 00:59:44,750
like if you press your device on
it, you can see the quality of

949
00:59:44,750 --> 00:59:49,010
the fiber versus polyester
version that looks similar thing

950
00:59:49,010 --> 00:59:51,380
like this, cuz I imagine you
could look and see the

951
00:59:51,380 --> 00:59:52,040
differences.

952
00:59:52,190 --> 00:59:53,690
Youssef Benmokhtar: You're
absolutely right. We actually

953
00:59:53,690 --> 00:59:57,320
had inquiries around exactly
that front because we well,

954
00:59:57,320 --> 00:59:59,480
yeah, because the thread counts
you know is different.

955
01:00:00,770 --> 01:00:04,580
potentially counterfeit
material, you know, counterfeit.

956
01:00:05,570 --> 01:00:11,210
Shops are becoming extremely
good. It's basically becoming

957
01:00:11,210 --> 01:00:15,410
very, very hard to tell, you
know, to from fake. But one way

958
01:00:15,410 --> 01:00:17,720
actually, is to get a digital
signature, what it's supposed to

959
01:00:17,720 --> 01:00:20,810
be like, and look at it. Yeah.
So you know, it is part of our

960
01:00:20,810 --> 01:00:24,980
vision, you know, it, you know,
for us, if we could find a way

961
01:00:24,980 --> 01:00:28,670
to build a product and the
software behind it, to provide

962
01:00:28,670 --> 01:00:33,020
to all of the custom offices out
there that wants to verify, you

963
01:00:33,020 --> 01:00:38,000
know, is this real? Or is this
fake? And they basically could

964
01:00:38,000 --> 01:00:41,630
scan the materials and say,
compare it to their database and

965
01:00:41,630 --> 01:00:45,860
say, Well, this is how the real
one is that that is just a, you

966
01:00:45,860 --> 01:00:47,480
know, a much more efficient way
to do it.

967
01:00:48,290 --> 01:00:50,990
Audrow Nash: That's super cool.
Do you also, I'm imagining

968
01:00:50,990 --> 01:00:54,230
applications in healthcare, in
this kind of thing, like, Oh, I

969
01:00:54,230 --> 01:00:57,290
think I have a lump here for
something. And you could press

970
01:00:57,290 --> 01:01:03,200
it into it, and you could maybe
get good 3d information about

971
01:01:03,950 --> 01:01:08,000
what you're seeing, and then
what that means for this kind of

972
01:01:08,000 --> 01:01:08,270
thing.

973
01:01:08,360 --> 01:01:10,670
Youssef Benmokhtar: Absolutely.
And, you know, we, we've had,

974
01:01:10,670 --> 01:01:14,330
again, in his in the history of
GelSight, we've had inquiries

975
01:01:14,330 --> 01:01:19,700
for such applications. Yeah, we
haven't really pursued them at

976
01:01:19,700 --> 01:01:23,240
the time. You know, for a small
company, you have to choose

977
01:01:23,240 --> 01:01:25,160
where you want to spend your

978
01:01:26,240 --> 01:01:27,170
Audrow Nash: money for you guys.

979
01:01:27,740 --> 01:01:29,840
Youssef Benmokhtar: We're only,
you know, we're 20 People just

980
01:01:29,840 --> 01:01:32,120
about today,

981
01:01:32,150 --> 01:01:34,520
Audrow Nash: and we're How do
you do most of your money spent

982
01:01:34,700 --> 01:01:39,260
up until this point where you're
doing digit, which is, if I

983
01:01:39,260 --> 01:01:43,370
understand correctly, it's like
the first fairly low cost sensor

984
01:01:43,790 --> 01:01:48,920
that you guys are making. So
spend low volume high margins on

985
01:01:48,920 --> 01:01:51,500
how you've been operating. So
extremely, NEC, probably

986
01:01:51,500 --> 01:01:54,260
assemble in house, and this kind
of thing.

987
01:01:54,680 --> 01:01:57,800
Youssef Benmokhtar: So I would
say in our chemistry, type of

988
01:01:57,800 --> 01:02:01,100
works, I think around the gel is
done in house today. But we have

989
01:02:01,100 --> 01:02:04,850
started to outsource some part
of that process. And then the

990
01:02:04,880 --> 01:02:08,840
electronics assembly piece is
outsourced. So we don't we don't

991
01:02:08,840 --> 01:02:11,450
do that in house. So we you
know, we've been preparing

992
01:02:11,480 --> 01:02:15,110
ourselves for scale. And you
can't do that by, you know, just

993
01:02:15,590 --> 01:02:20,180
assembling that in our office in
Boston. So yeah, we definitely

994
01:02:20,180 --> 01:02:22,370
we've already started to build
that supply chain.

995
01:02:25,070 --> 01:02:30,020
Audrow Nash: Interesting. What
do you how do you imagine growth

996
01:02:30,080 --> 01:02:33,800
looking for you guys? Like what
do you? What do you think in the

997
01:02:33,800 --> 01:02:36,920
next like two years, five years,
this kind of thing? I know, it's

998
01:02:36,920 --> 01:02:39,770
a projection of something that
hasn't happened. But like, what

999
01:02:39,770 --> 01:02:40,190
do you think

1000
01:02:40,640 --> 01:02:43,730
Youssef Benmokhtar: our focus in
the next couple of years is, we

1001
01:02:43,730 --> 01:02:47,240
just launched our series two
metrology products. So we're

1002
01:02:47,330 --> 01:02:50,450
kind of putting out commercial
efforts on the deployment of

1003
01:02:50,450 --> 01:02:54,710
that solution, which we just
launched this October. And then

1004
01:02:54,710 --> 01:03:03,320
we basically planning to push
the commercialization of DIGIT

1005
01:03:03,440 --> 01:03:05,960
obviously, which is, you know,
something that is important to

1006
01:03:05,960 --> 01:03:09,380
us, and then this next
generation local sensor that

1007
01:03:09,380 --> 01:03:13,010
will hopefully have in the first
half of next year, but the thing

1008
01:03:13,220 --> 01:03:15,350
Audrow Nash: you were saying
that would be more accurate,

1009
01:03:15,440 --> 01:03:18,410
smaller, correct, then this kind
of thing, okay,

1010
01:03:18,440 --> 01:03:19,940
Youssef Benmokhtar: great,
because, you know, the thing is,

1011
01:03:20,420 --> 01:03:24,410
we need to, we need to create an
ecosystem around tactile

1012
01:03:24,410 --> 01:03:27,110
sensing. And that's, you know,
again, the shared vision with

1013
01:03:27,140 --> 01:03:33,500
with metta and, and to do that
we need to invest in bringing

1014
01:03:33,500 --> 01:03:37,100
products that are in that kind
of cost points and ease of use,

1015
01:03:37,580 --> 01:03:40,670
and form factor, and also invest
in marketing, you know, to make

1016
01:03:40,670 --> 01:03:44,930
it known. And that's what we
basically we're focusing the

1017
01:03:44,930 --> 01:03:48,800
next, you know, six months to a
year is let's, let's make

1018
01:03:48,800 --> 01:03:53,570
tactile sensing. available, that
everyone knows that everybody

1019
01:03:53,570 --> 01:03:57,530
knows about it. Everybody who
has any kind of curiosity about

1020
01:03:57,530 --> 01:04:01,430
what can I do with this? We want
to remove all the barriers, all

1021
01:04:01,430 --> 01:04:03,620
the obstacles and make it easy
for them to get it.

1022
01:04:04,520 --> 01:04:07,760
Audrow Nash: Yeah, I'm seeing so
I'm seeing DIGIT where you guys

1023
01:04:07,790 --> 01:04:14,090
similar to what was it? Is it
Leptin, the FLIR the thermal

1024
01:04:14,120 --> 01:04:16,970
camera, where it's like they
made the I think it was the FLIR

1025
01:04:16,970 --> 01:04:24,110
and it was the fairly low cost
thermal camera. Like I don't

1026
01:04:24,110 --> 01:04:27,830
know, it was a few $100 where
previously it was they were very

1027
01:04:27,830 --> 01:04:30,110
expensive. So are you are you
following kind of a similar

1028
01:04:30,110 --> 01:04:33,470
business model? You think at the
moment with digit

1029
01:04:35,300 --> 01:04:37,010
Youssef Benmokhtar: Yeah, I
think it's actually makes me

1030
01:04:37,010 --> 01:04:41,870
smile that you're mentioning the
laptop camera. I actually worked

1031
01:04:41,870 --> 01:04:46,880
on it in my past life. Yeah,

1032
01:04:46,880 --> 01:04:48,680
Audrow Nash: I worked with it
not on it.

1033
01:04:48,830 --> 01:04:54,050
Youssef Benmokhtar: Yeah. So
yeah, I think I think it is

1034
01:04:54,050 --> 01:04:56,840
about building that community.
You know, we we want to make it

1035
01:04:56,840 --> 01:05:00,590
available. We want to make it
affordable, but at the same time

1036
01:05:00,620 --> 01:05:04,790
we need tactile sensing to be,
you know, used in real

1037
01:05:04,790 --> 01:05:09,830
applications by customers that
give us that market credibility,

1038
01:05:09,830 --> 01:05:13,130
right when I, when I work with a
company in aerospace that is

1039
01:05:13,130 --> 01:05:16,340
actually saying, using your
technology saves me hundreds of

1040
01:05:16,340 --> 01:05:20,930
1000s of dollars a year in, you
know, reduced rework costs or

1041
01:05:20,930 --> 01:05:24,350
maintenance costs. That is very
important for Josiah, because he

1042
01:05:24,350 --> 01:05:28,160
basically said, tactile sensing
is not only about a long term

1043
01:05:28,160 --> 01:05:30,500
dream, a long term vision, it
actually actually has

1044
01:05:30,500 --> 01:05:37,790
applications today. So, we are
continuing to work hard at

1045
01:05:37,820 --> 01:05:42,800
having our sensors being used in
real applications. But at the

1046
01:05:42,800 --> 01:05:48,290
same time, we want it to be, you
know, we want to create that

1047
01:05:48,290 --> 01:05:51,050
that community, that hopefully
is going to be very, really

1048
01:05:51,050 --> 01:05:56,930
large, and in the years to come.
That will consider the use of

1049
01:05:56,930 --> 01:06:01,730
tactile sensing in their future
products. And to do that we need

1050
01:06:01,730 --> 01:06:04,550
to continue with what we started
with digit.

1051
01:06:05,750 --> 01:06:07,850
Audrow Nash: What kind of
software push are you guys

1052
01:06:07,850 --> 01:06:12,260
doing? So I know that meta AI is
contributing a lot in the

1053
01:06:12,260 --> 01:06:18,080
software space, it sounds like,
but are you guys maybe making

1054
01:06:18,080 --> 01:06:22,070
libraries that expose the data
type and make it useful for a

1055
01:06:22,070 --> 01:06:26,270
lot of common applications, a
lot of common hobbyists or

1056
01:06:26,270 --> 01:06:28,100
makers, this kind of thing.

1057
01:06:28,490 --> 01:06:30,920
Youssef Benmokhtar: So for the
for the, I would say, the low

1058
01:06:30,920 --> 01:06:35,780
cost part of our portfolio, we
we intend to follow the metal

1059
01:06:35,780 --> 01:06:39,920
example, and make our make
libraries open source make them

1060
01:06:39,950 --> 01:06:41,270
easy to access?

1061
01:06:42,260 --> 01:06:44,780
Audrow Nash: Does anything exist
yet? Or it sounds like it

1062
01:06:44,780 --> 01:06:45,380
doesn't yet

1063
01:06:45,410 --> 01:06:49,070
Youssef Benmokhtar: we have a
few we already have our you

1064
01:06:49,070 --> 01:06:55,880
know, our 3d reconstruction.
technique, you know, can be

1065
01:06:56,270 --> 01:07:00,860
available for people to leverage
on our sensors, our pose

1066
01:07:00,860 --> 01:07:07,160
estimation, you know, algorithms
also, we have, we're thinking

1067
01:07:07,160 --> 01:07:10,040
about other things, you know, we
have anti slip, for example, for

1068
01:07:10,040 --> 01:07:12,260
robotics, which could be
interesting, you know, detecting

1069
01:07:12,260 --> 01:07:15,590
than an anti slip, yeah, I was
gonna ask about that, right, you

1070
01:07:15,590 --> 01:07:18,500
know, detecting that something
is slipping from grasp, from

1071
01:07:18,500 --> 01:07:21,680
your grasp, you know, so these
are all the things that we, you

1072
01:07:21,680 --> 01:07:25,970
know, can put available for
community to use. So, we have a

1073
01:07:25,970 --> 01:07:30,230
few, but, you know, we, we need
to accelerate that and as part

1074
01:07:30,230 --> 01:07:34,160
of our plans. So on the low end
side, I would say, we're going

1075
01:07:34,160 --> 01:07:36,500
to follow the open source model,
we're going to try to make it

1076
01:07:36,800 --> 01:07:39,230
everything that we develop, make
it available for the community.

1077
01:07:40,190 --> 01:07:42,410
Audrow Nash: And part of that is
growing the community, correct

1078
01:07:42,470 --> 01:07:45,680
that gotcha, correct. So it's
interesting that that's a

1079
01:07:45,680 --> 01:07:49,460
pragmatic choice, which is quite
cool. To me, as someone who

1080
01:07:49,460 --> 01:07:51,920
really likes open source, that
it's kind of a pragmatic choice

1081
01:07:51,920 --> 01:07:53,600
well to do open, it's very

1082
01:07:53,600 --> 01:07:55,160
Youssef Benmokhtar: pragmatic in
the various, you know, in the

1083
01:07:55,160 --> 01:08:00,620
sense that, that that ecosystem
today does not exist, it's very

1084
01:08:00,620 --> 01:08:05,150
small. So, you know, for us to
grow it, it would be, I think,

1085
01:08:05,150 --> 01:08:08,210
it would not be smart on gel
site to make it difficult by

1086
01:08:08,210 --> 01:08:14,030
having a closed source system,
you know, or make it, you know,

1087
01:08:14,060 --> 01:08:17,660
Honorius, you know, for people.
So, open source is the way to go

1088
01:08:17,690 --> 01:08:20,270
to create a community, and we
are definitely embracing it.

1089
01:08:20,630 --> 01:08:24,410
Now, on the higher end, you
know, type of product, there we

1090
01:08:24,410 --> 01:08:28,250
are, you know, continuing to
develop applications. And those

1091
01:08:28,250 --> 01:08:31,010
are soft, you know, including
our software suites that

1092
01:08:31,010 --> 01:08:36,350
customers are, you know, paying
for, whether it's with the

1093
01:08:36,350 --> 01:08:41,240
purchase of a of some of our
systems, or as a just a, you

1094
01:08:41,240 --> 01:08:43,460
know, an applications we just
like you do with enterprise

1095
01:08:43,460 --> 01:08:47,360
software. But even then, you
know, even there, we are

1096
01:08:47,360 --> 01:08:52,670
planning to also invest in, you
know, machine learning, and AI

1097
01:08:52,700 --> 01:08:57,530
to bring in more services to our
customers in a future where,

1098
01:08:57,680 --> 01:09:01,400
instead of just offering a tool
that provides them with the

1099
01:09:01,400 --> 01:09:07,220
decision making capability at
the instant, is also the ability

1100
01:09:07,220 --> 01:09:12,290
to leverage the data, the data
that's coming out from the

1101
01:09:12,290 --> 01:09:15,950
sensors over time. So as you're
building a database of images,

1102
01:09:16,550 --> 01:09:20,150
in an enterprise environment, do
something with those images over

1103
01:09:20,150 --> 01:09:25,640
time. And we think that machine
learning and AI can can help us

1104
01:09:25,670 --> 01:09:27,980
bring more value to our
customers. And that's another

1105
01:09:27,980 --> 01:09:30,710
part that's going to be
important for Joseph going

1106
01:09:30,710 --> 01:09:31,010
forward.

1107
01:09:31,939 --> 01:09:35,659
Audrow Nash: Do you mean keeping
it for yourself or putting it

1108
01:09:35,689 --> 01:09:39,079
out into the community? And so
you get a bunch of data, and you

1109
01:09:39,079 --> 01:09:42,829
can train machine learning
models on it or whatever it

1110
01:09:42,829 --> 01:09:48,199
might be? Will it be like you'll
release a public data set? Or

1111
01:09:48,379 --> 01:09:49,189
you'll keep it in half?

1112
01:09:49,189 --> 01:09:52,099
Youssef Benmokhtar: They will do
both, I think on on the consumer

1113
01:09:52,099 --> 01:09:56,119
like, you know, market, you
know, we, you know, we will

1114
01:09:56,119 --> 01:09:59,389
likely publish some public
datasets, you know, to help how

1115
01:09:59,389 --> 01:10:03,019
the community leverage those
datasets. But in the enterprise

1116
01:10:03,019 --> 01:10:07,129
space, when you know the problem
to solve, you know, there, there

1117
01:10:07,129 --> 01:10:09,679
is a way to just monetize
directly that data set by

1118
01:10:09,679 --> 01:10:10,549
building services.

1119
01:10:11,990 --> 01:10:15,260
Audrow Nash: Do you think? Are
you guys do you think? I mean,

1120
01:10:15,260 --> 01:10:17,330
so many questions around all
these different things, because

1121
01:10:17,330 --> 01:10:20,660
the software and open source
that is really interesting. But

1122
01:10:20,660 --> 01:10:25,490
so one of the things that really
kicked off the all of the

1123
01:10:25,490 --> 01:10:28,370
advancements in computer vision,
as far as I understand is like

1124
01:10:28,370 --> 01:10:31,310
the release of image net. And I
think it was, I think it's image

1125
01:10:31,310 --> 01:10:35,240
net, and might be some others
thing, but it was a big data set

1126
01:10:35,930 --> 01:10:41,150
with benchmarks effectively, for
you can compare how good your

1127
01:10:41,150 --> 01:10:43,730
algorithm does. So you have a
bunch of images, those images

1128
01:10:43,730 --> 01:10:47,810
are labeled, and it asks you
what is this, and then you can

1129
01:10:47,810 --> 01:10:51,920
run your algorithm on it. And
your algorithm is right, say 60%

1130
01:10:51,920 --> 01:10:54,620
of the time and the current
state of the art is 70% of the

1131
01:10:54,620 --> 01:10:57,290
time and you've thought you know
how what you're doing compares,

1132
01:10:57,950 --> 01:11:02,660
do you think it's in your future
to create anything like this for

1133
01:11:02,660 --> 01:11:03,260
a touch?

1134
01:11:03,440 --> 01:11:07,220
Youssef Benmokhtar: I hope so, I
really hope so. Be awesome. It's

1135
01:11:07,250 --> 01:11:12,200
a it's a very ambitious goal for
EDA for a company of our size

1136
01:11:12,200 --> 01:11:15,530
today. But it is part of our
story. And it is part about how

1137
01:11:15,530 --> 01:11:20,750
we want the company to grow.
And, you know, we we believe

1138
01:11:20,750 --> 01:11:25,580
that that is something that
needs to happen. And we hope

1139
01:11:25,580 --> 01:11:27,710
that we'll be the ones to, to
build it.

1140
01:11:27,830 --> 01:11:31,610
Audrow Nash: Yeah, if I remember
correctly, ImageNet was done by

1141
01:11:31,610 --> 01:11:36,650
Fei Fei Li, and I think she was
at Stanford. And so they just

1142
01:11:36,650 --> 01:11:42,140
received a big grant, I think,
and then went and did it. So I

1143
01:11:42,140 --> 01:11:45,290
don't know, something like that.
I may, I may be wrong about the

1144
01:11:45,290 --> 01:11:48,740
story, or who were anything, but
it'd be quite cool to see you

1145
01:11:48,740 --> 01:11:51,440
guys do a touch library that
would really accelerate this

1146
01:11:51,440 --> 01:11:57,110
whole space. Are you doing
anything? So I mean, I met open

1147
01:11:57,110 --> 01:12:02,060
robotics. I'm wondering, do you
have ROS? Like, do you have any

1148
01:12:02,510 --> 01:12:03,800
way to interface yourself?

1149
01:12:04,160 --> 01:12:07,100
With Yeah, I should. I
should have mentioned that

1150
01:12:07,100 --> 01:12:11,540
before it or sorry? No,
actually, our sensors and, and

1151
01:12:11,540 --> 01:12:13,460
our software and firmware is ROS
compatible?

1152
01:12:14,840 --> 01:12:18,650
Audrow Nash: Suite? So which ROS
by the way? ROS 1 or ROS 2?

1153
01:12:19,730 --> 01:12:22,010
I don't know, that's a
good question. I'll ask my

1154
01:12:22,100 --> 01:12:26,810
robotics engineer. But but it is
absolutely our you know, that

1155
01:12:26,810 --> 01:12:31,820
we, we intend to support, you
know, anything that we need to,

1156
01:12:31,970 --> 01:12:35,780
to, to, again, to accelerate
adoption. So ROS is definitely

1157
01:12:35,780 --> 01:12:38,870
something that we keep keeping
an eye on and supporting.

1158
01:12:39,650 --> 01:12:46,280
Audrow Nash: If you one thing
that would be cool. If so as you

1159
01:12:46,280 --> 01:12:49,520
are working, because if robotics
is a big interest, and a lot of

1160
01:12:49,520 --> 01:12:54,320
the robotics community uses ROS,
one thing that's very nice to

1161
01:12:54,320 --> 01:12:59,000
have is something standardized
in the ROS community. And the

1162
01:12:59,000 --> 01:13:02,390
way to do this is through a ROS
enhancement proposal, it'd be

1163
01:13:02,390 --> 01:13:06,260
very cool to create one of these
for like a data structure that's

1164
01:13:06,260 --> 01:13:10,280
really good for touch. But
actually, maybe it's just an

1165
01:13:10,280 --> 01:13:13,940
image, which is kind of nuts, or
like a 3d point cloud or

1166
01:13:13,940 --> 01:13:17,570
something like this. But if if
it is a non standard datatype

1167
01:13:18,620 --> 01:13:21,020
creating one of these ROS
enhancement proposals would be

1168
01:13:21,020 --> 01:13:24,320
really cool. And then we have
this as like, this is the de

1169
01:13:24,320 --> 01:13:29,540
facto touch type that will be
used in the ROS ecosystem. So

1170
01:13:29,540 --> 01:13:34,820
other packages can also use it
and build off of your standards.

1171
01:13:35,990 --> 01:13:36,980
I'm making a note.

1172
01:13:40,460 --> 01:13:43,520
Audrow Nash: Awesome, that would
be super cool. And I'm, I'm

1173
01:13:43,520 --> 01:13:48,620
happy to see that you guys are
already supporting ROS even. I

1174
01:13:48,620 --> 01:13:51,440
bet. I wonder if it's ROS one. A
lot of people are moving ROS 2,

1175
01:13:51,740 --> 01:13:53,360
which is quite cool. It's
getting steam.

1176
01:13:53,390 --> 01:13:55,760
Youssef Benmokhtar: I can I can
ask right now. I don't know if I

1177
01:13:55,760 --> 01:13:57,200
get an answer right away. But

1178
01:13:58,370 --> 01:14:02,210
Audrow Nash: I mean, it doesn't
matter too much. Yeah. Let's

1179
01:14:02,210 --> 01:14:08,660
see. So now I want to see how
much time we have. So we'd like

1180
01:14:08,660 --> 01:14:13,940
another 15 minutes or so. I was
the one thing I was really

1181
01:14:13,940 --> 01:14:19,640
curious about your sensor was
vibration. And so a lot of time

1182
01:14:19,700 --> 01:14:23,870
or as far as I understand if you
have like a gripper and you have

1183
01:14:23,870 --> 01:14:27,020
an object in it, and the object
is starting to fall out of the

1184
01:14:27,020 --> 01:14:29,720
gripper, it'll create
vibrations, so you'll be able to

1185
01:14:29,720 --> 01:14:33,290
sense vibrations or something to
know if the object is slipping,

1186
01:14:33,290 --> 01:14:38,030
which you've mentioned. Yes. And
I was wondering with the gel,

1187
01:14:38,060 --> 01:14:43,340
how this would be like perhaps
if the gel deformed and then

1188
01:14:43,340 --> 01:14:46,970
slowly came back, it would be
very hard to get vibrations or

1189
01:14:46,970 --> 01:14:49,610
if it was very springy, it might
be easy, or you might get a

1190
01:14:49,610 --> 01:14:54,860
bunch of noise if it's to spring
back. I don't know. Can you talk

1191
01:14:54,860 --> 01:14:58,130
a bit about the slit of
different objects through your

1192
01:14:58,130 --> 01:14:58,700
sensors?

1193
01:14:59,060 --> 01:15:01,370
Youssef Benmokhtar: Yeah, I
think you know The really I

1194
01:15:01,370 --> 01:15:08,120
think what we do is we have come
up with a way to measure the

1195
01:15:08,120 --> 01:15:14,660
local forces at the sensor
surface. And, you know, based on

1196
01:15:14,660 --> 01:15:16,160
that you basically, you know,

1197
01:15:17,000 --> 01:15:19,640
Audrow Nash: you just assume
that it's normal to the

1198
01:15:19,760 --> 01:15:23,300
deformation. Yeah. So why don't
formation surface and the force?

1199
01:15:23,330 --> 01:15:23,750
Correct. So

1200
01:15:23,750 --> 01:15:25,670
Youssef Benmokhtar: what we do
actually, we imagine, like you

1201
01:15:25,670 --> 01:15:30,260
printing a dot matrix on the, on
the membrane of the sensor,

1202
01:15:30,620 --> 01:15:30,950
right?

1203
01:15:30,980 --> 01:15:32,450
Audrow Nash: I don't know what
you mean, dot matrix,

1204
01:15:32,480 --> 01:15:34,760
Youssef Benmokhtar: it's
basically a matrix of black

1205
01:15:34,760 --> 01:15:36,740
dots. Right? Okay. So

1206
01:15:36,980 --> 01:15:39,290
Audrow Nash: that's what you
mean. Right? Yeah. And thinking

1207
01:15:39,290 --> 01:15:41,810
like that product, like in math
or No, no, yeah.

1208
01:15:42,140 --> 01:15:45,200
Youssef Benmokhtar: It is very,
you know, yeah, just exactly

1209
01:15:45,200 --> 01:15:48,680
what what it sounds like, a
bunch of dots. Yeah. So now,

1210
01:15:48,680 --> 01:15:51,380
when you have a camera, right,
every time that you press on the

1211
01:15:51,380 --> 01:15:57,170
gel, those those dots, you know,
location basically get get

1212
01:15:57,170 --> 01:16:02,180
changed based on how the touch
the surface is being, you know,

1213
01:16:02,180 --> 01:16:05,240
being touched. And based on
that, I actually have now an

1214
01:16:05,240 --> 01:16:09,500
idea to, you know, to know, what
is the local force vectors

1215
01:16:09,500 --> 01:16:14,870
basically, on the entire matrix.
And as you're moving across the

1216
01:16:14,870 --> 01:16:18,320
surface, on also scan, detect,
basically, the changes in that

1217
01:16:18,320 --> 01:16:22,670
local, those local forces. So if
you're, if your object is

1218
01:16:22,670 --> 01:16:26,300
starting to slip a little bit,
you know, then you basically see

1219
01:16:26,330 --> 01:16:29,540
the vectors kind of all going
into one direction, with a

1220
01:16:29,540 --> 01:16:33,050
relative intensity also showed,
and you put all of that

1221
01:16:33,050 --> 01:16:36,890
together, you're able basically
to detect that, you know, the

1222
01:16:36,890 --> 01:16:42,740
object is, is actually starting
to just slip in some way. So

1223
01:16:42,740 --> 01:16:48,890
it's, it's, it's a pretty neat
way, actually, to provide this

1224
01:16:48,920 --> 01:16:51,830
additional information. And one
of the key things, you know,

1225
01:16:52,070 --> 01:16:55,820
you're a much better, you know,
much more expert than me in this

1226
01:16:55,820 --> 01:17:01,130
field. But, you know, one of the
difficulties I understand them,

1227
01:17:01,160 --> 01:17:04,070
and trying to get force
estimation, in robotics, and

1228
01:17:04,070 --> 01:17:06,980
robotics, arms and fingers, is
actually the sensors that

1229
01:17:06,980 --> 01:17:13,310
measure forces are not at the
tip of the of the drives, a lot

1230
01:17:13,310 --> 01:17:16,070
of times, right, so this is, you
know, so when you get forces

1231
01:17:16,070 --> 01:17:16,550
emissions,

1232
01:17:17,180 --> 01:17:19,430
Audrow Nash: this is
specifically a problem when you

1233
01:17:19,430 --> 01:17:23,480
have like a high gear gear
ratio, if you have low gear

1234
01:17:23,480 --> 01:17:26,720
ratios, a lot of times you can
infer the force at the tip

1235
01:17:26,870 --> 01:17:29,540
pretty accurately. But if you
have a high gear ratio, there's

1236
01:17:29,540 --> 01:17:32,030
all those gears in the way and I
don't know if this is correct,

1237
01:17:32,240 --> 01:17:34,010
whatever it makes it, so it's
hard to do.

1238
01:17:34,160 --> 01:17:36,770
Youssef Benmokhtar: Correct. But
in our case, here, whatever, you

1239
01:17:36,770 --> 01:17:40,460
know, in our case, we actually
can provide you with a local

1240
01:17:40,460 --> 01:17:43,730
force estimation at the tip,
which could be also very

1241
01:17:43,730 --> 01:17:45,500
interesting, depending on the
applications.

1242
01:17:46,220 --> 01:17:49,700
Audrow Nash: So for for the
local force estimation, at least

1243
01:17:49,700 --> 01:17:54,320
with the digit, it probably
can't, like if I I'm imagining,

1244
01:17:54,320 --> 01:17:57,080
like I had a robot that was like
going to pick up something with

1245
01:17:57,080 --> 01:18:00,170
a forklift. And I wanted to feel
what's on the end of the

1246
01:18:00,170 --> 01:18:05,090
forklift. I imagine you can't
put a lot of weight into these

1247
01:18:05,090 --> 01:18:10,250
sensors, he has this shake in
your head. But is there any way

1248
01:18:10,250 --> 01:18:14,270
to make them more robust,
because like, if I if I'm trying

1249
01:18:14,270 --> 01:18:18,410
to grab something that's heavy,
I probably can't use the sensors

1250
01:18:18,410 --> 01:18:20,960
on the end of grab them,

1251
01:18:21,350 --> 01:18:23,750
I would say, you know,
you saw you shaking my hand in

1252
01:18:23,750 --> 01:18:26,960
my head there. Because in the
case of DIGIT, right, if you

1253
01:18:26,960 --> 01:18:31,640
putting very heavy weights on on
a hand, you know, equipped with

1254
01:18:31,640 --> 01:18:34,730
DIGIT, I just think that I think
the mechanical housing would

1255
01:18:34,730 --> 01:18:38,600
just crack. That's was when I
was just not meant for that. I

1256
01:18:38,600 --> 01:18:42,350
don't think the issue is really
the gel as much. But the key

1257
01:18:42,350 --> 01:18:46,640
again, as I said very early in
our conversation, you could

1258
01:18:46,640 --> 01:18:51,140
design, you know, the sensor for
different applications, right.

1259
01:18:51,320 --> 01:18:55,340
So if you're basically looking
at an application where you need

1260
01:18:55,340 --> 01:19:00,590
to apply a lot of force on the
sensor, then you can design a

1261
01:19:00,590 --> 01:19:06,350
formulation that allows you to
enter to do that, you can also

1262
01:19:06,380 --> 01:19:10,070
design, you know, the thickness
of the gel to be, you know,

1263
01:19:10,070 --> 01:19:14,810
maybe thick enough to allow for,
you know, a lot of pressure to

1264
01:19:14,810 --> 01:19:18,320
be applied or thin enough to be
able to apply a lot of pressure.

1265
01:19:18,320 --> 01:19:22,550
So, we actually have done that.
We, we, you know, we have a

1266
01:19:22,550 --> 01:19:27,020
customer in forensics, who were
doing some role. Yeah, we were

1267
01:19:27,020 --> 01:19:30,230
doing some tests, like like
crime ski. Yeah, absolutely.

1268
01:19:30,290 --> 01:19:36,500
They, they basically use our
technology to measure bullet

1269
01:19:36,500 --> 01:19:41,180
casings, and compare them to do
to a central database to

1270
01:19:41,180 --> 01:19:45,770
basically be able to provide
like a biometric. You know,

1271
01:19:45,800 --> 01:19:51,800
confirmation that that case came
from this gun. You know it with

1272
01:19:51,800 --> 01:19:55,010
a with a 90 plus percent
confidence. It's actually used

1273
01:19:55,010 --> 01:19:59,390
in, in, in trials and in crime
labs and things like that. So

1274
01:19:59,390 --> 01:20:02,360
that's true, pretty Pretty wild,
but in that particular

1275
01:20:02,360 --> 01:20:06,020
application, they use more of a
benchtop type system that from

1276
01:20:06,020 --> 01:20:10,100
us, but, you know, they can
apply, you know, six to 10

1277
01:20:10,100 --> 01:20:14,600
kilograms of force. Very
locally, very, super localized

1278
01:20:14,600 --> 01:20:18,560
in a small area. We've done some
tests on some other things, you

1279
01:20:18,560 --> 01:20:24,530
know, where we we go to 1520
kilograms of force, again, a

1280
01:20:24,530 --> 01:20:29,570
very, very, very tiny area. So
I'm not, you know, I think our

1281
01:20:29,570 --> 01:20:35,270
team could design things to be,
you know, used in applications

1282
01:20:35,270 --> 01:20:40,250
where there's a lot of weight,
apply to them. It just needs to

1283
01:20:40,250 --> 01:20:42,500
make, you know, business sense,
to be honest, I think that's

1284
01:20:42,500 --> 01:20:44,180
really the main, the main
challenge main

1285
01:20:44,180 --> 01:20:48,350
Audrow Nash: limiter. Yeah.
Gotcha. What about, what about a

1286
01:20:48,350 --> 01:20:52,280
sensor without bevels? I'm
thinking about it. So you have

1287
01:20:52,280 --> 01:20:58,010
currently the edges around the
gel pad. I'm wondering, like I

1288
01:20:58,040 --> 01:21:01,070
imagined for robotics, it'd be
really nice to not have those

1289
01:21:01,070 --> 01:21:04,130
edges, because you're limited.
If I'm trying to touch into a

1290
01:21:04,130 --> 01:21:07,190
hard surface, does the gel
extrude? A little bit past?

1291
01:21:07,490 --> 01:21:11,240
bevels? It's not so you can?
Gotcha. Yeah.

1292
01:21:11,270 --> 01:21:14,210
Youssef Benmokhtar: Well, maybe
I should, yeah, it should not

1293
01:21:14,210 --> 01:21:17,030
interfere. But I understand your
point. I think if you really

1294
01:21:17,030 --> 01:21:20,840
want to mimic the human finger,
you should not have any bezel at

1295
01:21:20,840 --> 01:21:25,190
all, and you should actually
have a curved sensor. There is

1296
01:21:25,190 --> 01:21:29,480
hard probably, it is hard to
make. But it is not. Again,

1297
01:21:29,480 --> 01:21:33,710
conceptually, you know, are the
technology as I described it,

1298
01:21:33,710 --> 01:21:37,190
right of having some kind of a,
you know, polymer like material,

1299
01:21:37,340 --> 01:21:41,060
some illumination, a camera
behind it, as long as you can

1300
01:21:41,750 --> 01:21:46,760
image that curved area, and be
able to reconstruct that 3d

1301
01:21:46,970 --> 01:21:51,260
surface of it. It works. So I
don't think there is again,

1302
01:21:51,620 --> 01:21:54,410
Audrow Nash: a just you can
calibrate it pretty robustly,

1303
01:21:54,620 --> 01:21:58,520
regardless of its shape. I would
think so then

1304
01:21:58,550 --> 01:22:01,400
Youssef Benmokhtar: absolutely.
It is a complex design, a

1305
01:22:01,400 --> 01:22:03,800
probably will take, you know, a
lot of development to make

1306
01:22:03,800 --> 01:22:06,170
something like this. But
fundamentally, I don't see any

1307
01:22:06,410 --> 01:22:10,310
limitations from the technology,
it wouldn't actually be feasible

1308
01:22:10,310 --> 01:22:11,660
to do it with curved sensors.

1309
01:22:13,550 --> 01:22:17,660
Audrow Nash: That would be cool.
Yeah, I was just thinking, maybe

1310
01:22:17,660 --> 01:22:20,900
they'd be like edge effects. I'm
imagining like a soft mattress

1311
01:22:20,900 --> 01:22:23,750
or something where the edges are
easier to fall off than the

1312
01:22:23,750 --> 01:22:27,950
middle because it's kind of
gives more on the edges. And I

1313
01:22:27,950 --> 01:22:32,180
was wondering if that would make
it more difficult to sense

1314
01:22:32,180 --> 01:22:37,100
accurately on the edges. If you
had no edges, but perhaps it

1315
01:22:37,100 --> 01:22:40,850
wouldn't matter, because you
just calibrate what it looks

1316
01:22:40,850 --> 01:22:42,380
like for transformations?

1317
01:22:42,500 --> 01:22:44,210
Youssef Benmokhtar: Right, I
don't think would be an issue.

1318
01:22:45,200 --> 01:22:49,940
Audrow Nash: Gotcha. Okay, so I
would like to segue a little bit

1319
01:22:49,940 --> 01:22:55,070
to talking about you for this.
So you've mentioned that you've

1320
01:22:55,070 --> 01:22:58,760
been in tech for the last 25
years. And did you say you have

1321
01:22:58,760 --> 01:23:02,210
been leading in tech for 25
years? Or what did you say at

1322
01:23:02,210 --> 01:23:03,140
the beginning? Yeah,

1323
01:23:03,140 --> 01:23:05,750
Youssef Benmokhtar: I've been
kind of, uh, you know, in

1324
01:23:05,750 --> 01:23:12,110
leadership positions, you know,
for 20 plus years. I spent half

1325
01:23:12,110 --> 01:23:15,380
of my career in the
semiconductor world. So I I am

1326
01:23:15,410 --> 01:23:20,630
still biased to being a chip
guy. At St. microelectronics, I

1327
01:23:20,630 --> 01:23:25,400
worked. In the end, a fab that
is now closed in Phoenix,

1328
01:23:25,400 --> 01:23:29,660
Arizona is where I started my
career after grad school. In

1329
01:23:29,660 --> 01:23:34,400
operation management, at that
time, I'm an industrial and

1330
01:23:34,400 --> 01:23:35,900
system engineer by trade

1331
01:23:37,100 --> 01:23:39,230
Audrow Nash: was the first thing
what and

1332
01:23:39,410 --> 01:23:41,870
Youssef Benmokhtar: Industrial
and Systems Engineering. That's

1333
01:23:41,900 --> 01:23:48,200
what I studied in, in undergrad
and grad. And so worked in

1334
01:23:48,200 --> 01:23:52,970
Phoenix, I worked in France, in
semiconductors when I left the

1335
01:23:53,000 --> 01:23:55,610
semiconductor world, I was
leading the eight bit

1336
01:23:55,610 --> 01:24:03,770
microcontroller business unit at
St. Micro. Okay. And came back

1337
01:24:03,770 --> 01:24:06,170
to the US to join a company
called Digital optics

1338
01:24:06,170 --> 01:24:09,830
Corporation, which I moved from
like from electrons or photons

1339
01:24:09,830 --> 01:24:15,320
at the time. Yeah, it was a
company that was using wafer

1340
01:24:15,320 --> 01:24:18,530
level techniques. So still
leveraging my semiconductor

1341
01:24:18,530 --> 01:24:21,320
experience by actually build
micro optics, you know,

1342
01:24:21,320 --> 01:24:27,920
diffractive optics waveguides
and very tiny refract reflective

1343
01:24:28,430 --> 01:24:29,900
lenses refractive lenses.

1344
01:24:30,470 --> 01:24:32,330
Audrow Nash: I'm imagining just
tiny cameras,

1345
01:24:32,480 --> 01:24:35,720
Youssef Benmokhtar: very tiny
cameras, very tiny cameras,

1346
01:24:35,750 --> 01:24:37,250
Audrow Nash: because I don't
know what a lot of the words

1347
01:24:37,280 --> 01:24:38,870
you've just said mean. Yeah.

1348
01:24:39,740 --> 01:24:43,370
Youssef Benmokhtar: So, so I did
that for for a while. That's

1349
01:24:43,370 --> 01:24:47,750
actually where I, you know, met
the FLIR guys that were

1350
01:24:47,750 --> 01:24:50,930
developing Krypton at a time but
I can't I can't really say much

1351
01:24:50,930 --> 01:24:59,570
more than that. But I know a lot
about leptons. And we we sold

1352
01:24:59,570 --> 01:25:03,050
actually that that activity to
flare. That's public

1353
01:25:03,050 --> 01:25:07,910
information. And I decided to
move to California at the time

1354
01:25:07,910 --> 01:25:13,730
because as a technology geek
that I am, I've always felt that

1355
01:25:13,940 --> 01:25:18,260
where else can you be but in
Silicon Valley. So after we sold

1356
01:25:18,260 --> 01:25:21,440
the site in North Carolina, I
moved to the Silicon Valley, I

1357
01:25:21,440 --> 01:25:23,930
worked for OmniVision, for a
little bit, launched their

1358
01:25:24,770 --> 01:25:30,530
liquid crystalline silicon
business. And joined some

1359
01:25:30,530 --> 01:25:33,320
friends of mine that were in a
company called Photo nation,

1360
01:25:33,440 --> 01:25:38,690
which was a computer vision
company. core expertise in, in

1361
01:25:38,720 --> 01:25:41,750
face technologies. They've been
doing it since the mid 90s, I

1362
01:25:41,750 --> 01:25:45,710
think before many. So face
detection and tracking,

1363
01:25:45,890 --> 01:25:50,060
eventually recognition and eye
tracking, Iris, iris

1364
01:25:50,060 --> 01:25:54,080
recognition, things like that,
like that cool. And got an

1365
01:25:54,080 --> 01:25:58,610
opportunity to join, Magic Leap
do matter reality startup where

1366
01:25:58,610 --> 01:26:02,480
I spent almost five years as
their as VP of Business

1367
01:26:02,480 --> 01:26:09,650
Development, which helped me
really get access to incredibly

1368
01:26:09,710 --> 01:26:12,740
amazing technologies, because to
build the kind of AR headset

1369
01:26:12,740 --> 01:26:15,560
that we were building, you're
basically at the edge of

1370
01:26:15,560 --> 01:26:19,460
innovation on every front. Oh,
that's cool, which was amazing

1371
01:26:19,460 --> 01:26:25,370
for me. So amazing learning
experience, and decided to take

1372
01:26:25,370 --> 01:26:29,990
a break, spent a little bit of
time with the family. But I was

1373
01:26:30,020 --> 01:26:37,280
as I was doing that, I got
introduced to JL sites, and

1374
01:26:37,370 --> 01:26:40,310
really fell in love with the
technology, it kind of had that

1375
01:26:40,310 --> 01:26:44,270
similar wow effect when I saw it
the first time as I had when I

1376
01:26:44,330 --> 01:26:50,930
experienced Magic Leap in, in
late 2015. And I started digging

1377
01:26:50,930 --> 01:26:57,290
into it. And I basically noticed
that companies in every sector

1378
01:26:57,320 --> 01:27:02,990
showed interest in GelSight, and
I and I really, you know, it

1379
01:27:02,990 --> 01:27:06,710
really intrigued me like it
really piqued my curiosity, to

1380
01:27:06,710 --> 01:27:09,710
say, so what should we really be
able to do with this company,

1381
01:27:09,740 --> 01:27:16,460
you know, and, and after I met
the, the founders team, and, and

1382
01:27:16,490 --> 01:27:20,330
the staff, I basically decided
this was the right choice for me

1383
01:27:20,330 --> 01:27:24,140
is to join, joining the company,
it didn't help it grow towards

1384
01:27:24,140 --> 01:27:28,400
this vision of making digitized,
you know, their sensation of

1385
01:27:28,400 --> 01:27:33,410
tactile sensing. Reality. And
more importantly, I think just

1386
01:27:33,410 --> 01:27:35,900
bringing tactile intelligence to
the world, and you know, so

1387
01:27:35,900 --> 01:27:39,860
basically bringing these two
pieces of imaging based digital

1388
01:27:39,860 --> 01:27:45,200
tactile sensor, plus AI, as the
way forward, you know, for the

1389
01:27:45,230 --> 01:27:50,090
for the company. And that, to me
is super exciting. And, you

1390
01:27:50,090 --> 01:27:52,160
know, I've, I've enjoyed every,
every minute of it.

1391
01:27:54,080 --> 01:27:57,620
Audrow Nash: Now, one thing that
strikes me hearing about kind of

1392
01:27:57,620 --> 01:28:02,000
your path, is you kind of like,
pivoted and kept learning and

1393
01:28:02,000 --> 01:28:07,100
like, I imagine reinventing
yourself, like each stage. Can

1394
01:28:07,100 --> 01:28:09,770
you just tell me a bit about
that, like the experience that

1395
01:28:09,770 --> 01:28:13,160
kind of your heuristics? And I
don't know, how do you? Yeah,

1396
01:28:13,220 --> 01:28:17,360
Youssef Benmokhtar: that's a
great question. I think what

1397
01:28:17,360 --> 01:28:26,960
gets me excited, is learning new
things every day. And, you know,

1398
01:28:27,170 --> 01:28:32,960
it needs to have that component
in my life to motivate me, and

1399
01:28:32,960 --> 01:28:36,770
help me get up in the morning.
And, and that's what I've been

1400
01:28:36,770 --> 01:28:40,580
doing. You know, every time even
when I spent 13 years at St.

1401
01:28:40,580 --> 01:28:47,720
Micro, I basically had maybe
five or six different roles,

1402
01:28:47,990 --> 01:28:51,710
because I kept kept moving and
being promoted within the

1403
01:28:51,710 --> 01:28:56,060
company. Because as soon as I,
you know, I kind of figured it

1404
01:28:56,060 --> 01:28:58,730
out, I started getting bored on
I need a new challenge, I needed

1405
01:28:58,730 --> 01:29:01,760
a new challenge. And, you know,
the company had been really

1406
01:29:01,760 --> 01:29:06,680
great to me by offering many,
many ways for me to get to

1407
01:29:06,680 --> 01:29:12,470
advance but it made me to learn.
And I always take it as a person

1408
01:29:12,470 --> 01:29:16,520
who will challenge to, to learn
about new technology, and to

1409
01:29:16,520 --> 01:29:19,910
envision the best that can
happen with any technology that

1410
01:29:19,910 --> 01:29:24,440
I'm that I'm, you know, getting
the chance to work with. And

1411
01:29:24,440 --> 01:29:28,730
that's just who I am. I'm just
driven by, by this constant need

1412
01:29:28,820 --> 01:29:33,770
to, to learn. So yeah, that's
what drove me here.

1413
01:29:34,400 --> 01:29:38,270
Audrow Nash: How do you find
something that's exciting? Like

1414
01:29:38,270 --> 01:29:41,630
how does gels like get on your
radar? Or how does augmented ray

1415
01:29:41,660 --> 01:29:45,170
or the the headsets you were
working on? How do these get on

1416
01:29:45,170 --> 01:29:51,560
your radar for you to consider
switching your area to and keep

1417
01:29:51,560 --> 01:29:52,790
learning in that direction?

1418
01:29:53,690 --> 01:29:55,670
Youssef Benmokhtar: You know,
I've been blessed over the years

1419
01:29:55,670 --> 01:30:03,050
to, you know, build a network of
people. that, it first of all

1420
01:30:03,050 --> 01:30:06,950
know me, and they know what I'm
capable of doing. But it also

1421
01:30:06,950 --> 01:30:11,930
made me know that I need that, I
need that new challenge. So I've

1422
01:30:11,930 --> 01:30:15,440
had actually the opportunity to,
you know, like the Magic Leap

1423
01:30:15,440 --> 01:30:18,350
opportunities just to a friend
of mine at our work within the

1424
01:30:18,380 --> 01:30:20,750
optics company, he's just like
us, if this is for you, you need

1425
01:30:20,750 --> 01:30:23,810
to come and please take a look
at this. And that's what really

1426
01:30:23,810 --> 01:30:26,960
happened. And I think in gel
side, it was a bit of the same.

1427
01:30:28,370 --> 01:30:31,640
It just basically, by
surrounding yourself with people

1428
01:30:31,640 --> 01:30:35,480
that appreciate you for who you
are, and actually just know you,

1429
01:30:35,480 --> 01:30:39,410
and they know, you know, when
something really interesting is

1430
01:30:39,410 --> 01:30:43,010
out there. You're the guy they
think about, it's like, Hey, you

1431
01:30:43,010 --> 01:30:46,010
should take a look at this. You
might be interesting,

1432
01:30:46,100 --> 01:30:50,000
interesting to you. So that's
what I, that's what I've done.

1433
01:30:50,870 --> 01:30:53,060
Audrow Nash: Gotcha. That's
cool. It's interesting how the

1434
01:30:53,060 --> 01:30:56,750
network can kind of make you
aware of different

1435
01:30:56,750 --> 01:31:00,500
opportunities. And but you hear
about everything through your

1436
01:31:00,500 --> 01:31:03,230
connections, in a sense, they
kind of filter correct the

1437
01:31:03,230 --> 01:31:07,760
topics, and also can recommend,
like, Hey, this is super cool. I

1438
01:31:07,760 --> 01:31:08,690
think you'll love this.

1439
01:31:08,930 --> 01:31:10,310
Youssef Benmokhtar: And, you
know, the other thing I would

1440
01:31:10,310 --> 01:31:17,840
add is, like, my key motivation
is that curiosity. So it's not

1441
01:31:17,840 --> 01:31:23,990
about the, necessarily about the
the short term financial stuff.

1442
01:31:23,990 --> 01:31:26,600
So, you know, when I, when I
left Magic Leap, I had the

1443
01:31:26,600 --> 01:31:31,400
opportunity to join other
companies, and much bigger

1444
01:31:31,400 --> 01:31:34,910
companies that would offer me a
package also can never afford,

1445
01:31:34,940 --> 01:31:40,310
and even if we have a very nice,
yeah, so So even if we do really

1446
01:31:40,310 --> 01:31:42,350
good, you know, it might not
even match what I could have

1447
01:31:42,350 --> 01:31:45,590
done somewhere else. But it was
not interesting. You know, it

1448
01:31:45,590 --> 01:31:51,620
felt like, you know, to me, I
would be one person amongst many

1449
01:31:52,670 --> 01:31:55,640
not necessarily working on the
most exciting stuff, or they

1450
01:31:55,640 --> 01:32:00,320
being very limited in your
scope. You know, that that's

1451
01:32:01,820 --> 01:32:04,430
Audrow Nash: not interesting.
Yeah. And that's not a good use

1452
01:32:04,430 --> 01:32:05,060
of your time,

1453
01:32:05,120 --> 01:32:09,470
Youssef Benmokhtar: I can't see
myself being happy there. I

1454
01:32:09,470 --> 01:32:13,790
think to be happy, I just need
that, that I need that

1455
01:32:13,790 --> 01:32:17,450
challenge. I need to be learning
some things. And that's why I'm

1456
01:32:17,450 --> 01:32:18,470
here. That's great.

1457
01:32:20,810 --> 01:32:29,750
Audrow Nash: See, so. All right.
What advice do you have? For

1458
01:32:30,080 --> 01:32:36,320
someone, let's say, finishing
university? Given like, the

1459
01:32:36,320 --> 01:32:40,400
current climate of everything,
what advice do you have for

1460
01:32:40,400 --> 01:32:40,700
them?

1461
01:32:42,830 --> 01:32:49,160
Youssef Benmokhtar: I would say,
you know, really work at

1462
01:32:49,160 --> 01:32:52,940
identifying what really gets you
up in the morning and, and gets

1463
01:32:52,940 --> 01:32:57,680
you excited about contributing
to to our world in a positive

1464
01:32:57,680 --> 01:33:03,320
way. You know, at the end of the
day, it's, it's what's going to

1465
01:33:03,320 --> 01:33:06,830
matter in the long run. It's not
the material things, it's really

1466
01:33:06,830 --> 01:33:12,620
about, you know, Have you have
you had fun, you know, have you

1467
01:33:12,620 --> 01:33:15,590
learned things? Have you helped
others learn, have you out

1468
01:33:15,590 --> 01:33:22,460
helped others grow? Up, you
know, that, to me is really, I

1469
01:33:22,460 --> 01:33:25,730
think what young people should,
not young people everybody

1470
01:33:25,790 --> 01:33:28,100
should really think about,
that's the advice I would give,

1471
01:33:28,100 --> 01:33:31,520
that's the advice I give to my
own daughters. But that's what I

1472
01:33:31,520 --> 01:33:35,180
would say it's just, you know,
you have the foundations, you've

1473
01:33:35,180 --> 01:33:40,460
learned things. That's just the
beginning in life is going to be

1474
01:33:40,460 --> 01:33:46,940
about continuous learning. And,
you know, do something where you

1475
01:33:46,940 --> 01:33:50,330
can leverage what you've
learned, but also when you're

1476
01:33:50,360 --> 01:33:55,670
never stop learning, and where
you can actually then, you know,

1477
01:33:55,670 --> 01:33:58,040
share your experience, share,
share what you've learned with

1478
01:33:58,040 --> 01:34:03,440
others, you know, help help
others also get ahead. I find

1479
01:34:03,440 --> 01:34:08,120
that find out to be find that to
be very satisfying. You know,

1480
01:34:08,120 --> 01:34:11,330
for me, you know, that the best
thing that I once in a while

1481
01:34:11,330 --> 01:34:16,730
hear about is my, some old, you
know, colleagues of mine from

1482
01:34:16,760 --> 01:34:20,570
many jobs ago, you know, tell
me, you remember that advice you

1483
01:34:20,570 --> 01:34:24,020
gave me, you know, on such a
day? Well, I just wanted to let

1484
01:34:24,020 --> 01:34:28,040
you know, I did it five years
ago, and I feel that was the

1485
01:34:28,040 --> 01:34:32,000
best decision ever. That to me
is you know, when I hear things

1486
01:34:32,000 --> 01:34:34,910
like that, which I've been,
again, lucky to hear quite a few

1487
01:34:34,910 --> 01:34:38,630
times in my life. That that what
makes me happy and I want when I

1488
01:34:38,630 --> 01:34:44,180
hear that I was like, Okay, I've
done something. Good. So that's,

1489
01:34:44,240 --> 01:34:45,080
that's my advice.

1490
01:34:46,430 --> 01:34:52,070
Audrow Nash: Let's see. And then
one last question. Is there any

1491
01:34:52,880 --> 01:34:58,550
specific things you do or habits
or things like this that you

1492
01:34:58,550 --> 01:35:00,170
think have been very useful to
you?

1493
01:35:07,070 --> 01:35:08,690
Youssef Benmokhtar: I don't know
if I have good examples there

1494
01:35:08,690 --> 01:35:16,940
because I think I would be
scolded at. At home. I think

1495
01:35:18,050 --> 01:35:23,120
it's also spending time, you
know, by yourself, I think just,

1496
01:35:23,150 --> 01:35:28,250
you know, we've just taken time
for your own, you know, your own

1497
01:35:28,250 --> 01:35:33,830
being just well being just
reflecting on what matters, you

1498
01:35:33,830 --> 01:35:40,280
know, to you enjoying, you know,
this this earth that we live on,

1499
01:35:40,310 --> 01:35:43,640
you know, I do a lot of, you
know, I enjoy that very much.

1500
01:35:43,670 --> 01:35:48,890
I'm kind of a, sometimes too
much of a loner, but I enjoy

1501
01:35:48,890 --> 01:35:54,560
that. I mean, I enjoy taking the
time to listen to the wind

1502
01:35:54,560 --> 01:35:57,140
blowing on the leaves out there
in Boston is really nice right

1503
01:35:57,140 --> 01:36:00,230
now. And you know, things like
that. It just helps you to be

1504
01:36:00,230 --> 01:36:06,560
grounded, I think and just
enjoying the little things. I

1505
01:36:06,560 --> 01:36:10,280
like that, you know, very much
it has helped me. The other

1506
01:36:10,280 --> 01:36:13,880
thing is I don't sleep much. So
if you don't sleep much. You

1507
01:36:13,880 --> 01:36:15,230
have time to do work.

1508
01:36:17,750 --> 01:36:21,980
Audrow Nash: All right. Do you
have any links or website like

1509
01:36:21,980 --> 01:36:24,890
contact information, anything
you'd like to share with our

1510
01:36:24,890 --> 01:36:25,400
listeners?

1511
01:36:26,810 --> 01:36:29,300
Absolutely. I mean, I
would encourage everybody to

1512
01:36:29,300 --> 01:36:35,480
visit gelsight.com. We also have
our contact page there. If

1513
01:36:35,480 --> 01:36:38,930
you're interested in what we do,
or if you just want to give us

1514
01:36:38,930 --> 01:36:44,300
comments, please contact us. We
would love to hear from the

1515
01:36:44,300 --> 01:36:51,200
audience. You know, we you know,
we're here to basically help

1516
01:36:51,260 --> 01:36:54,740
digital touch happen. So if
you're interested in that topic,

1517
01:36:54,740 --> 01:36:55,580
we'd love to hear from you.

1518
01:36:57,080 --> 01:36:59,210
Audrow Nash: Awesome. Okay. It's
been a pleasure.

1519
01:36:59,930 --> 01:37:01,430
Youssef Benmokhtar: Thank you.
Same here. Absolutely.

1520
01:37:02,840 --> 01:37:04,610
Audrow Nash: Thanks for
listening to this conversation

1521
01:37:04,610 --> 01:37:07,700
with Youssef Benmokhtar. Thank
you again to our founding

1522
01:37:07,700 --> 01:37:10,520
sponsor, Open Robotics, and hope
to see you next time


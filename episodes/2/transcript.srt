1
00:00:03,120 --> 00:00:05,730
Audrow Nash: Hi, everyone,
welcome to the sense think act

2
00:00:05,760 --> 00:00:09,420
podcast. I'm Audrow Nash, your
host and a software engineer at

3
00:00:09,420 --> 00:00:12,990
Open Robotics. In today's
episode, I speak with Dave

4
00:00:12,990 --> 00:00:18,780
Coleman, CEO at PickNik, which
does engineering services and

5
00:00:18,810 --> 00:00:22,350
motion planning. Motion planning
is the problem of moving

6
00:00:22,350 --> 00:00:25,980
something from one place to
another, such as moving a robot

7
00:00:25,980 --> 00:00:32,340
from one location to another, or
picking up an object and placing

8
00:00:32,340 --> 00:00:35,790
it somewhere else. This can be
made more difficult if you try

9
00:00:35,790 --> 00:00:38,850
to avoid collisions. For
example, if you had something

10
00:00:38,850 --> 00:00:41,940
beneath a table and want to lift
it up over the table, you have

11
00:00:41,940 --> 00:00:45,930
to go around the table. And as
you can imagine, this is a

12
00:00:45,930 --> 00:00:51,510
fundamental problem in robotics.
And Dave has been involved in

13
00:00:51,570 --> 00:00:55,530
move it a motion planning
framework that has built on top

14
00:00:55,620 --> 00:01:00,630
of robot operating system or ROS
for a number of years, and has

15
00:01:01,920 --> 00:01:06,810
created picnic to do engineering
services around motion planning.

16
00:01:08,130 --> 00:01:11,790
We talked about his motion
planning or the motion planning

17
00:01:11,790 --> 00:01:17,100
framework, move it, how PickNik
came to be there work with NASA,

18
00:01:17,730 --> 00:01:23,220
and a paid service called
movement studio that hopes to

19
00:01:23,220 --> 00:01:27,900
help the problem of supervised
autonomy. And we teased the idea

20
00:01:28,290 --> 00:01:33,150
of move it three. I really
enjoyed talking to Dave, he is a

21
00:01:33,150 --> 00:01:36,960
fun person to interview. And I
find that he has a great

22
00:01:36,960 --> 00:01:41,070
perspective on robotics and open
source, probably in no small

23
00:01:41,070 --> 00:01:45,330
part because of the diverse
problems that they work on at

24
00:01:45,330 --> 00:01:50,190
picnic, and his time that he has
been in the robotics community.

25
00:01:50,790 --> 00:01:51,510
I hope you enjoy.

26
00:01:53,370 --> 00:01:57,000
So Dave, would you start off by
introducing yourself.

27
00:01:57,420 --> 00:02:03,240
Dave Coleman: Yeah. I'm Dave
Coleman, CEO of PickNik robotics

28
00:02:03,270 --> 00:02:07,710
and a longtime supporter of open
source robotics contributor to

29
00:02:07,710 --> 00:02:10,140
ROS and MoveIt. Glad to be here
today.

30
00:02:11,310 --> 00:02:15,030
Audrow Nash: Awesome. To start
off as a general overview, would

31
00:02:15,030 --> 00:02:18,690
you just tell us about move it?
What problems does it solve and

32
00:02:18,690 --> 00:02:19,680
how long it's been going?

33
00:02:20,430 --> 00:02:25,260
Dave Coleman: Sure. Move it is a
framework developed to do motion

34
00:02:25,260 --> 00:02:29,340
planning primarily for robotic
arms, but also for the full

35
00:02:29,340 --> 00:02:34,350
kinematics of your robot. It's
had some success and walking in

36
00:02:34,350 --> 00:02:40,050
mobile bases, even by esoteric
things like quite like flying

37
00:02:40,050 --> 00:02:44,160
robots and submersible so all
over the place move it's been

38
00:02:44,160 --> 00:02:48,420
applied. And it's the problem of
how to motion plan your, your

39
00:02:48,420 --> 00:02:50,760
joints through space, so you
don't hit things and that you

40
00:02:50,760 --> 00:02:54,390
can do useful things like
manipulation and grasping. And

41
00:02:54,420 --> 00:02:59,820
your second question, it's been
around since pic. 2010 was when

42
00:02:59,820 --> 00:03:04,770
development begun, I think 2011
was the beta release of move it

43
00:03:04,770 --> 00:03:08,520
and this was developed at Willow
Garage. Same place that ROS was

44
00:03:08,520 --> 00:03:11,910
developed, it was developed with
the PRT program. Sasha Cheetah

45
00:03:11,910 --> 00:03:16,680
was the program manager at the
time of that project. And yeah,

46
00:03:16,710 --> 00:03:20,460
Willow Garage eventually closed,
but it lives on.

47
00:03:22,080 --> 00:03:23,730
Audrow Nash: Let's see. And I
know we said we talked about

48
00:03:23,730 --> 00:03:26,700
kind of you're coming into this
a bit later in the interview,

49
00:03:26,700 --> 00:03:29,820
but might as well get into it
now. How did you get involved?

50
00:03:29,820 --> 00:03:33,870
So it started in 2010 ish? at
Willow Garage. When did you come

51
00:03:33,870 --> 00:03:34,200
along?

52
00:03:35,520 --> 00:03:38,490
Dave Coleman: I was an intern at
Willow Garage. Willow was very

53
00:03:38,520 --> 00:03:42,210
clever and having a lot of
interns huge program. So I guess

54
00:03:42,210 --> 00:03:48,030
I'm not that special. And that
the CEO at the time, Steve

55
00:03:48,030 --> 00:03:51,240
cousins said that the intern
program was a way of spreading

56
00:03:51,240 --> 00:03:54,060
ROS. I like like a virus, he
wanted us to go back to our

57
00:03:54,060 --> 00:03:57,690
research groups and get everyone
to use ROS and I think it was

58
00:03:57,690 --> 00:04:00,660
overall really effective
strategy. And so I was certainly

59
00:04:00,660 --> 00:04:03,720
part of that I brought ROS and
particularly move it back to our

60
00:04:03,720 --> 00:04:10,320
research group at CU Boulder,
Colorado. And and so I was

61
00:04:10,350 --> 00:04:12,660
developing some of the initial
parts of move it together with

62
00:04:12,660 --> 00:04:17,070
Johan sukan. And the team. And I
kind of decided to base the rest

63
00:04:17,070 --> 00:04:19,470
of my research during my
graduate program around move it

64
00:04:19,470 --> 00:04:22,020
and kind of did a lot of open
source contributions to

65
00:04:22,019 --> 00:04:26,909
Audrow Nash: it. Mm hmm. How did
that look like doing a PhD but

66
00:04:26,909 --> 00:04:30,539
also contributing largely to the
open source part of this head?

67
00:04:30,539 --> 00:04:33,179
Like, it seems like the
incentives are slightly

68
00:04:33,179 --> 00:04:36,959
different for what the PhD would
want and what an open source

69
00:04:36,989 --> 00:04:40,529
really useful tool with. One How
did that go? Do

70
00:04:40,530 --> 00:04:42,120
Dave Coleman: I think I think
you know the answer this

71
00:04:42,120 --> 00:04:48,240
question. leading question. I
think it worked well for me,

72
00:04:48,240 --> 00:04:51,630
because working at open source
robotics gives you so much hands

73
00:04:51,630 --> 00:04:54,540
on experience. It's like
relevant to industry relevant to

74
00:04:54,540 --> 00:04:59,970
getting jobs after the fact. So
I think it's a great way to do

75
00:05:00,000 --> 00:05:03,960
That kind of sharpen your role
or experience. However, if your

76
00:05:03,990 --> 00:05:08,340
main motive is to publish
papers, then it could be

77
00:05:08,340 --> 00:05:11,670
distracting. Maybe just I don't
have any experience about this

78
00:05:12,450 --> 00:05:17,940
possibly could distract you from
publishing enough. But on the

79
00:05:17,940 --> 00:05:22,350
flip side, if done well, there's
been a lot of examples where you

80
00:05:22,350 --> 00:05:25,080
do some pretty cool research and
you publish the open source code

81
00:05:25,080 --> 00:05:26,820
to it. I encourage everyone
listening to do that if you're

82
00:05:26,820 --> 00:05:29,400
in academia and and you can
actually increase your citations

83
00:05:29,400 --> 00:05:31,710
because people within convention
market and compare it against

84
00:05:31,710 --> 00:05:35,250
other methods. And so there's
there's definitely advantages to

85
00:05:35,250 --> 00:05:35,730
doing both.

86
00:05:36,090 --> 00:05:40,290
Audrow Nash: Yes, for sure. And
then how did you go from PhD

87
00:05:40,290 --> 00:05:44,760
student contributing to this to
now leading up to kind of taking

88
00:05:44,760 --> 00:05:46,020
on the initiative yourself.

89
00:05:49,529 --> 00:05:51,479
Dave Coleman: I just looked it
up. By the way, movie beta was

90
00:05:51,479 --> 00:05:54,689
officially released in 2013. And
that same year, that will close

91
00:05:54,689 --> 00:05:59,069
to actually and there was just
kind of a leadership void in the

92
00:05:59,069 --> 00:06:01,649
movement. I think the the
project was kind of floundering,

93
00:06:01,649 --> 00:06:04,079
and there are a lot of pull
requests piling up and not being

94
00:06:04,079 --> 00:06:07,919
merged in. There was a little
bit of support from SRI

95
00:06:07,919 --> 00:06:11,159
International after Willow
close, but it didn't last for

96
00:06:11,159 --> 00:06:14,819
very long. And so I was
encouraged by a number of people

97
00:06:14,819 --> 00:06:17,699
that Open Robotics and others
that were had been at Willow

98
00:06:17,699 --> 00:06:21,239
Garage who had been involved in
move it that I kind of like try

99
00:06:21,239 --> 00:06:24,539
revitalize it. So Michael
Ferguson was a big player and

100
00:06:24,539 --> 00:06:26,939
encouraging it to be
revitalized, I think he would

101
00:06:26,969 --> 00:06:31,829
the time was starting, but the
precursors to Fetch, and so that

102
00:06:31,829 --> 00:06:35,429
he was interested in using Uber
for that. So he and I plan will

103
00:06:35,429 --> 00:06:38,579
move a day, the first one ever
and so that was a big Kickstart

104
00:06:38,579 --> 00:06:42,239
to getting a community kind of
excited about moving again. And

105
00:06:42,239 --> 00:06:45,419
conveying that it is a thing and
a big part of that was getting

106
00:06:45,419 --> 00:06:49,859
the website updated, so that it
was just showing that the latest

107
00:06:49,859 --> 00:06:52,019
things happening and with
community. And there were two

108
00:06:52,019 --> 00:06:55,409
other maintainers at the time,
who were still involved, Robert

109
00:06:55,409 --> 00:06:59,669
hash and Michael corner. And and
so we had our first maintainer

110
00:06:59,669 --> 00:07:03,749
meeting, I think it was kind of
three or four of us. And we're

111
00:07:03,749 --> 00:07:05,909
like, yeah, let's, let's see if
we can get this thing flying.

112
00:07:05,909 --> 00:07:09,449
Again, I think that was a what
Michael said. And sure enough,

113
00:07:09,449 --> 00:07:12,509
what we did we you know, to keep
an open source project is just

114
00:07:12,509 --> 00:07:17,609
responding to pull requests fast
enough and reliably. And if you

115
00:07:17,669 --> 00:07:20,609
have enough people, so myself,
Michael and Robert, responding

116
00:07:20,609 --> 00:07:23,819
to pull requests, giving decent
reviews, keeping the codebase

117
00:07:23,819 --> 00:07:27,599
stable, you'll eventually build
a community assuming that the

118
00:07:27,599 --> 00:07:30,209
software does anything useful
for people. And that's exactly

119
00:07:30,209 --> 00:07:33,149
what we did. One of the big
issues I first took was to put

120
00:07:33,149 --> 00:07:36,269
our first continuous integration
in the place which nowadays

121
00:07:36,269 --> 00:07:40,439
various Bordeaux belaz. A, but
like back at Willow Garage, that

122
00:07:40,439 --> 00:07:43,139
was still kind of cutting edge.
And we didn't have ci yet. So

123
00:07:43,979 --> 00:07:48,659
Jonathan Bourne helped me get
Travis working. And then for the

124
00:07:48,659 --> 00:07:50,939
first time, we can merge things
more confidence not breaking

125
00:07:50,939 --> 00:07:51,269
down,

126
00:07:51,839 --> 00:07:55,949
Audrow Nash: just to be clear,
so ci is continuous integration,

127
00:07:55,949 --> 00:07:58,559
and that's running your tests
that test that the code is

128
00:07:58,559 --> 00:07:59,669
working correctly.

129
00:08:00,060 --> 00:08:02,610
Dave Coleman: Right? Yeah. And
he only went on your test that

130
00:08:02,610 --> 00:08:05,550
you have tests and and we've
over the years, gotten the test,

131
00:08:05,550 --> 00:08:07,620
better remove it, but there's
still not enough and at the

132
00:08:07,620 --> 00:08:10,560
time, there wasn't not much at
all. And so not only the test it

133
00:08:10,560 --> 00:08:13,410
just test the builds, and that
you can recreate the build, the

134
00:08:13,410 --> 00:08:16,920
dependencies are also correctly
and, and so one of the big goals

135
00:08:16,920 --> 00:08:21,210
of adding ci was reducing the
burden for the volunteer

136
00:08:21,330 --> 00:08:25,410
maintainers. And so you just
want to get as many as much

137
00:08:25,410 --> 00:08:29,400
automation and bots helping so
we, I implemented like a clang

138
00:08:29,400 --> 00:08:32,550
format style guide enforcer,
and, and those sorts of things

139
00:08:32,550 --> 00:08:37,260
so that the burden of code
reviews got easier for us. And

140
00:08:37,440 --> 00:08:39,510
you know, you don't have to
always download the pull request

141
00:08:39,510 --> 00:08:41,910
and test it locally. Maybe for
complex ones, you still want to

142
00:08:41,910 --> 00:08:46,410
do that. But you can just review
and say this looks right. The ci

143
00:08:46,410 --> 00:08:48,600
says it works. So let's merge
it. And that's a way of

144
00:08:48,600 --> 00:08:50,250
leveraging automation to

145
00:08:50,250 --> 00:08:54,570
Audrow Nash: reduce what we have
to do. Okay, so you did a lot of

146
00:08:54,570 --> 00:08:57,060
kind of this important
infrastructure that made it

147
00:08:57,060 --> 00:09:00,630
easier for you guys to go and
review pull requests quickly so

148
00:09:00,630 --> 00:09:03,000
that the community can kind of
build it up? Is that really the

149
00:09:03,000 --> 00:09:05,550
way to look at it with the
community contributing a lot,

150
00:09:05,550 --> 00:09:09,480
and you're kind of just like,
managing it so that it stays

151
00:09:09,510 --> 00:09:12,540
working? Or you guys do your own
feature development?

152
00:09:13,650 --> 00:09:17,970
Dave Coleman: Yeah, yeah. It is
the way I kind of look at it.

153
00:09:17,970 --> 00:09:20,550
There's different models. So
some open source projects,

154
00:09:20,550 --> 00:09:24,540
there's just one or two or maybe
a small lab group of people who

155
00:09:24,540 --> 00:09:27,090
are doing all the actual feature
development. And then everyone

156
00:09:27,090 --> 00:09:30,930
else is kind of just benefiting
and taking and maybe submitting

157
00:09:30,930 --> 00:09:33,990
a bug report but not knowing how
to fix it. Personally, I've

158
00:09:33,990 --> 00:09:37,950
always taken the approach of
this project has too many too or

159
00:09:37,950 --> 00:09:41,460
too much code. There's too many
features like I can't do all

160
00:09:41,460 --> 00:09:43,350
this myself. So we're going to
leverage the community and

161
00:09:43,350 --> 00:09:47,400
there's pluses and minuses to
putting your energy towards

162
00:09:47,580 --> 00:09:50,400
fixing the problems versus it
making easier for others to fix

163
00:09:50,400 --> 00:09:55,620
the problems. And you know, it's
not as simple as it sounds,

164
00:09:55,620 --> 00:09:58,650
adding people in because they
have to then spend the time

165
00:09:59,100 --> 00:10:04,260
understanding the codebase And
like, like dissecting it and

166
00:10:04,290 --> 00:10:07,590
having quality reviews. So
there's a there's a bit of both,

167
00:10:07,590 --> 00:10:10,290
I definitely added a lot of
features just as I was working

168
00:10:10,290 --> 00:10:12,360
on my PhD, I was like, Oh, I
need this feature, I'm going to

169
00:10:12,420 --> 00:10:13,530
get this merged in. So

170
00:10:15,480 --> 00:10:19,110
Audrow Nash: gotcha. Okay. So
that's, it's an interesting

171
00:10:19,110 --> 00:10:24,420
approach to focus mostly, are
focused largely on making it

172
00:10:24,420 --> 00:10:27,150
easier for people to contribute.
And it's a cool approach, I do

173
00:10:27,150 --> 00:10:30,120
see what you mean, when the code
base grows to be so large that

174
00:10:30,120 --> 00:10:35,580
you need to make sure that like,
basically, you just facilitate

175
00:10:35,580 --> 00:10:41,190
it. Rather than going deep into
adding additional users, you

176
00:10:41,190 --> 00:10:43,800
can't do it yourself, because
it's too large. So it seems like

177
00:10:43,800 --> 00:10:48,270
a good scalable approach to make
this kind of thing, especially

178
00:10:48,270 --> 00:10:49,920
when you guys have a few
reviewers

179
00:10:51,270 --> 00:10:54,360
Dave Coleman: have we been able
to grow the number of reviewers,

180
00:10:54,360 --> 00:10:58,470
we call them maintainers over
the years, and that that's an

181
00:10:58,470 --> 00:11:02,550
important aspect is encouraging
newcomers to get more involved

182
00:11:02,850 --> 00:11:07,020
and get eventually give them the
the access to have merge access,

183
00:11:07,020 --> 00:11:09,720
right access, and we actually
set up a program, I'd love to

184
00:11:09,750 --> 00:11:13,740
share real quick to help with
that, to bring in beginners

185
00:11:13,740 --> 00:11:17,460
more, we set up a core
contributor program. And the

186
00:11:17,460 --> 00:11:20,700
idea being that when we see
people who are getting really

187
00:11:20,700 --> 00:11:23,040
involved, and maybe they don't
have quite the in depth skills

188
00:11:23,040 --> 00:11:25,530
yet, then we don't fully trust
them. But we want to really

189
00:11:25,800 --> 00:11:28,350
appreciate what they're doing
and set them up to become a

190
00:11:28,350 --> 00:11:31,440
maintainer in the future, we'll
add them as a core contributor

191
00:11:31,440 --> 00:11:33,780
and put them on our website. So
they get some credit for that.

192
00:11:34,170 --> 00:11:36,870
And, you know, I'm not sure if
recently we've been using that

193
00:11:36,870 --> 00:11:40,110
enough, but it's been a plus,
you can see it on our website on

194
00:11:40,110 --> 00:11:41,130
the on the people.

195
00:11:41,880 --> 00:11:43,830
Audrow Nash: How does it compare
to like an internship or

196
00:11:43,830 --> 00:11:46,560
something, it's something
someone does on their own time,

197
00:11:47,100 --> 00:11:50,760
and you try to guide them or
mentor them a little bit more,

198
00:11:51,450 --> 00:11:52,530
or work.

199
00:11:52,559 --> 00:11:54,869
Dave Coleman: It's pretty
informal. It's not as nearly as

200
00:11:54,869 --> 00:11:57,599
structured as an internship, I
mean, one, there's no no pay,

201
00:11:57,599 --> 00:11:59,639
and most engineering
internships, you do get paid.

202
00:12:00,869 --> 00:12:04,049
But it's more like if you were a
grad student working on motion

203
00:12:04,049 --> 00:12:06,149
planning for your research, and
you know how to use move it and

204
00:12:06,149 --> 00:12:09,179
you're just a rising star, then
we'll start off saying, like,

205
00:12:09,299 --> 00:12:12,389
you're awesome, be a core
contributor. And then after a

206
00:12:12,389 --> 00:12:15,299
few months or a year, if they
continue to, like really

207
00:12:15,569 --> 00:12:17,609
demonstrate that they understand
the code base, and then they're

208
00:12:17,609 --> 00:12:20,219
capable of maintaining the
quality standards and so forth.

209
00:12:20,579 --> 00:12:23,309
We would invite them to become,
you know, a full ride access

210
00:12:23,309 --> 00:12:27,389
maintainer. So is there a
mentorship? Like, I think anyone

211
00:12:27,389 --> 00:12:31,229
who gets involved in that will
get mentorship via pull request

212
00:12:31,229 --> 00:12:36,389
reviews, I think this is often
undervalued, but the time that

213
00:12:36,389 --> 00:12:40,679
people put, so you say I want to
change this code. And if there

214
00:12:40,679 --> 00:12:44,039
are maintainers, who decide to
respond to it, they will spend

215
00:12:44,039 --> 00:12:49,169
their time showing you like, why
certain code patterns or bugs or

216
00:12:49,169 --> 00:12:51,839
memory leaks, like helping you
improve your code quality over

217
00:12:51,839 --> 00:12:55,469
time. So that's a great way to
get mentorship. It actually was

218
00:12:55,469 --> 00:12:58,979
one of the ways I learned was
just watching my recruiter get

219
00:12:58,979 --> 00:13:01,109
reviewed. And also I watched
other people's code get

220
00:13:01,109 --> 00:13:03,089
reviewed. And I learned a lot
that way. Because I'd be like,

221
00:13:03,119 --> 00:13:05,879
Oh, I didn't see that issue.
Next time. I'll know better to

222
00:13:05,879 --> 00:13:06,719
like, look out for that,

223
00:13:07,380 --> 00:13:09,720
Audrow Nash: huh, yeah, that's
been a lot of my experience to

224
00:13:09,750 --> 00:13:13,050
that code reviews are it because
it's, it's line by line through

225
00:13:13,050 --> 00:13:16,740
the thing through the code
change that you have. And then

226
00:13:16,740 --> 00:13:21,540
they can critique you on the
approach or anything. So it's a

227
00:13:21,540 --> 00:13:23,880
really good way to get feedback.
And it can be done

228
00:13:23,910 --> 00:13:27,510
asynchronously. So you can take
a while to like, understand the

229
00:13:27,510 --> 00:13:31,140
comments, and get lots of
different approaches. So I've

230
00:13:31,140 --> 00:13:35,010
personally found that very
valuable at Open Robotics, code

231
00:13:35,010 --> 00:13:37,380
reviews, and even community code
reviews, which are always

232
00:13:37,380 --> 00:13:39,480
amazing when someone steps in
from the community.

233
00:13:40,920 --> 00:13:43,290
Dave Coleman: Yeah, totally,
there's just got to be, yeah,

234
00:13:43,290 --> 00:13:45,570
sometimes have a thick skin
because there's a lot of code

235
00:13:45,570 --> 00:13:49,170
reviewed. And sometimes, I'm
sure I've been guilty of this,

236
00:13:49,170 --> 00:13:51,330
like you review it really
quickly, and you don't like

237
00:13:51,900 --> 00:13:54,030
cherry code it so much, you're
just like, not listening to me.

238
00:13:55,230 --> 00:13:57,750
And then I've encouraged people
at the movement maintainer group

239
00:13:57,750 --> 00:14:00,030
to still always say thank you
for this contribution. It's kind

240
00:14:00,030 --> 00:14:03,420
of a summary. Even if we've
like, totally red line and torn

241
00:14:03,420 --> 00:14:06,900
apart, you know, so you gotta
gotta just be aware that we're

242
00:14:06,900 --> 00:14:09,270
just trying to help you and keep
the code quality up so that

243
00:14:09,630 --> 00:14:11,130
future people can improve it

244
00:14:11,130 --> 00:14:15,210
Audrow Nash: as well. Yeah, at
Open Robotics, we talked about

245
00:14:15,210 --> 00:14:20,400
how a lot of times in text, it
seems to be a lot more harsh,

246
00:14:20,460 --> 00:14:24,990
whatever you say. So then kind
of being aware of that while

247
00:14:25,020 --> 00:14:28,350
giving feedback. But you're
right, when there's a lot of

248
00:14:28,350 --> 00:14:34,410
code to review. It's like, it's,
it's tough to have really, you

249
00:14:34,410 --> 00:14:36,390
have to get through it. And so
you might make a comment. That's

250
00:14:36,390 --> 00:14:42,000
a little rough. That's awesome,
though. Are you so you have this

251
00:14:42,000 --> 00:14:45,540
program to bring on people who
are contributing and give them a

252
00:14:45,540 --> 00:14:48,870
little more responsibility
within the organization. How has

253
00:14:48,870 --> 00:14:53,400
it been to grow from your core
group of three to now you guys

254
00:14:53,400 --> 00:14:55,980
around 30 employees if I'm
correct, or

255
00:14:56,730 --> 00:15:00,690
Dave Coleman: Yeah, I do want to
differentiate the new community

256
00:15:00,690 --> 00:15:04,740
project and my company picnic
are not they're not the same

257
00:15:04,740 --> 00:15:05,130
set.

258
00:15:06,240 --> 00:15:09,300
Audrow Nash: Okay, let's, let's
talk. So let's explain picnic, I

259
00:15:09,300 --> 00:15:09,690
guess.

260
00:15:10,410 --> 00:15:12,300
Dave Coleman: Yeah. But to
finish the finish that first

261
00:15:12,300 --> 00:15:16,470
thought. So Michael and Robert,
for example, they are a

262
00:15:16,470 --> 00:15:20,970
professor or a PhD student and
individ respectively, in

263
00:15:20,970 --> 00:15:24,810
Germany, on affiliated with
picnic, and yet they are major

264
00:15:24,810 --> 00:15:27,540
contributors to the project,
there's a number of other

265
00:15:27,540 --> 00:15:30,570
maintainers unaffiliated with
picnic like Felix, who does

266
00:15:30,570 --> 00:15:35,190
understand a lot of great stuff.
So maybe half at this point of

267
00:15:35,190 --> 00:15:38,280
the maintainers are from picnic
and I, I'm proud of that. And

268
00:15:38,310 --> 00:15:40,770
I'm glad that we've been able to
hire people and get them excited

269
00:15:40,770 --> 00:15:43,530
enough about open source that
they're like, major contributors

270
00:15:43,530 --> 00:15:48,390
to the project now. like hitting
Kaiser has been a big lead for

271
00:15:48,390 --> 00:15:52,680
the movie project Tyler. And so
yeah, there's, there's a mix,

272
00:15:52,680 --> 00:15:55,140
and we want to make sure that
the movie project remains

273
00:15:55,980 --> 00:15:59,100
something separate from picnic,
although there are just plenty

274
00:15:59,100 --> 00:15:59,910
of overlap as well.

275
00:16:00,030 --> 00:16:02,250
Audrow Nash: There's a lot of
overlap. So can you tell me a

276
00:16:02,250 --> 00:16:06,120
bit about the two? So move it is
the open source, motion planning

277
00:16:06,120 --> 00:16:10,680
framework? And picnic? is a
consulting and research company

278
00:16:10,710 --> 00:16:13,860
around this area? Or how would
you think of it?

279
00:16:14,220 --> 00:16:17,490
Dave Coleman: Yeah, we'd be
called reasonable consulting. In

280
00:16:17,490 --> 00:16:20,130
the early days, I've actually
tried to distance myself from

281
00:16:20,130 --> 00:16:23,640
that word, because I prefer the
word engineering services, it

282
00:16:23,640 --> 00:16:27,690
comes off more as like we want
to co develop or develop for you

283
00:16:27,810 --> 00:16:31,170
robotic software, using movement
using ROS using other

284
00:16:31,290 --> 00:16:36,210
perception navigation packages.
And so you're not just like

285
00:16:36,240 --> 00:16:39,270
advising you on how to do it. I
mean, that is a small part of

286
00:16:39,270 --> 00:16:44,310
what we do. But it's not our
main goal. By working with your

287
00:16:44,340 --> 00:16:48,990
with other companies and other
teams, we do kind of a consult

288
00:16:48,990 --> 00:16:51,780
with them, but we do it through
working side by side.

289
00:16:52,890 --> 00:16:55,470
Audrow Nash: Yeah, so it's
developing a lot rather than

290
00:16:55,470 --> 00:16:58,710
just advising. And that's why
you like this engineering

291
00:16:58,710 --> 00:17:02,070
services term better than
consulting. We're more hands on,

292
00:17:02,850 --> 00:17:07,320
hands on. And does it? So if you
use the two different terms,

293
00:17:07,320 --> 00:17:11,490
does it change the types of
clients that come to you? Or

294
00:17:11,520 --> 00:17:14,490
what's the or it's how you think
of yourself, or why

295
00:17:15,360 --> 00:17:18,360
Dave Coleman: it changes the
mean, words are important and

296
00:17:18,360 --> 00:17:21,450
changes the mindset when, when a
potential client comes to us.

297
00:17:21,630 --> 00:17:24,000
It's not that we're going to get
on a meeting with you once a

298
00:17:24,000 --> 00:17:28,080
week for an hour and discuss the
best way of using moving we do

299
00:17:28,080 --> 00:17:31,170
offer feasibility studies. And
those have been very popular

300
00:17:31,200 --> 00:17:34,710
with our customers. But we hope
that after the feasibility study

301
00:17:34,710 --> 00:17:38,580
that they would then hire us to
actually implement a lot or some

302
00:17:38,580 --> 00:17:41,220
of it all of it, you know, some
combination of that with their

303
00:17:41,220 --> 00:17:44,070
team. And so that's kind of our
consulting offering is the

304
00:17:44,070 --> 00:17:44,910
feasibility study.

305
00:17:45,450 --> 00:17:49,920
Audrow Nash: I see. And then so
now, a lot of this is it. The

306
00:17:49,920 --> 00:17:54,810
business model is something
like, if they allow you to open

307
00:17:54,810 --> 00:17:58,170
source, whatever you're
developing for move it, or for

308
00:17:58,170 --> 00:18:03,960
them for move it, then they
don't like it's incentivized

309
00:18:03,990 --> 00:18:07,470
kind of you charge them less if
what you are doing can be open

310
00:18:07,470 --> 00:18:10,500
source, or it's a feature you
want, or how does a How does it

311
00:18:10,500 --> 00:18:11,580
work? we don't we

312
00:18:11,580 --> 00:18:16,050
Dave Coleman: don't have a model
like that. We were pretty clear

313
00:18:16,050 --> 00:18:19,200
and contracts. And we have a lot
of discussions with with lawyers

314
00:18:19,200 --> 00:18:23,940
that when you hire a picnic,
some portion of it is going to

315
00:18:23,940 --> 00:18:27,240
be open source. And the only
question is how much and we've

316
00:18:27,240 --> 00:18:29,790
had some projects that
everything is open sourced, and

317
00:18:29,790 --> 00:18:33,150
we're delighted. But in reality,
we don't expect that that's not

318
00:18:33,150 --> 00:18:37,710
normal. It's it's typically that
like, we're helping them build

319
00:18:37,710 --> 00:18:42,090
out their application specific
IP, intellectual property. And

320
00:18:42,210 --> 00:18:46,110
it's building off of move it or
ROS or other components of the

321
00:18:46,110 --> 00:18:49,440
whole open source device
ecosystem. And we insist that

322
00:18:49,440 --> 00:18:53,130
bug fixes or small features,
hooks, just little things that

323
00:18:53,130 --> 00:18:55,950
like that really shouldn't be
anything different shitting

324
00:18:55,950 --> 00:19:01,170
them, those get open sourced.
And you know, we if it's like a

325
00:19:01,170 --> 00:19:03,690
thing that originated in, move
it or in ROS, and we're just

326
00:19:03,690 --> 00:19:07,080
like slightly improving, it will
likely open source that. But if

327
00:19:07,080 --> 00:19:09,780
it's like some fancy new
algorithm for a particular type

328
00:19:09,780 --> 00:19:12,750
of application, then absolutely
like, if our customer wants that

329
00:19:12,780 --> 00:19:17,610
proprietary, we're not, we're
not here to like, be be like do

330
00:19:17,610 --> 00:19:23,010
to zealot about it. Huh. Okay.
The key is that we don't want to

331
00:19:23,010 --> 00:19:24,120
fix the same bug over and over

332
00:19:24,120 --> 00:19:27,120
Audrow Nash: again. That would
be ridiculous. Yeah, for sure.

333
00:19:27,120 --> 00:19:29,760
And also, it's nice for the
whole community to just benefit

334
00:19:29,760 --> 00:19:31,680
from any work you do with these
things.

335
00:19:32,130 --> 00:19:35,610
Dave Coleman: Yeah, it's kind of
like giving it back paying it

336
00:19:35,610 --> 00:19:38,910
forward type of thing of like,
you're benefiting from all this

337
00:19:38,940 --> 00:19:43,320
prior work that's saved you tons
of r&d hours and like bootstrap,

338
00:19:43,680 --> 00:19:47,820
or program you have and and now
we just ask that some of that be

339
00:19:47,820 --> 00:19:51,480
contributed back to the next
person or, you know, like one of

340
00:19:51,480 --> 00:19:53,850
the big moments we have about
the question of like open

341
00:19:53,850 --> 00:19:57,570
sourcing versus like forking
open source project, is that you

342
00:19:57,570 --> 00:20:00,210
don't want to take on
maintenance and ownership. That

343
00:20:00,210 --> 00:20:02,700
project in the future, but if
you stay with the mainland

344
00:20:02,700 --> 00:20:06,660
project, then companies like
picnic and Open Robotics and,

345
00:20:06,840 --> 00:20:10,260
and other contributors will take
care of that for you maintaining

346
00:20:10,290 --> 00:20:13,500
the basics of bug fixes and new
opera operating systems and

347
00:20:13,500 --> 00:20:14,970
patches. Yeah.

348
00:20:15,330 --> 00:20:18,240
Audrow Nash: And just to be
clear with the terminology, so

349
00:20:18,240 --> 00:20:20,280
when you're forking a project,
you're taking it and you're

350
00:20:20,280 --> 00:20:22,830
saying, This is unlike I'm
taking it in its current state,

351
00:20:22,830 --> 00:20:25,470
and I'm gonna go move it
somewhere else. And then I'm

352
00:20:25,470 --> 00:20:28,290
going to work on it and maintain
so you can hide it, what you

353
00:20:28,290 --> 00:20:33,090
actually contribute to, if
you're some company, I'm sure

354
00:20:33,090 --> 00:20:35,430
that they diverged. Oh, totally
sure.

355
00:20:35,940 --> 00:20:38,190
Dave Coleman: You really can't
see it typically? Nope.

356
00:20:39,060 --> 00:20:41,670
Audrow Nash: Yeah. So it's nice
having it all in the open, so

357
00:20:41,670 --> 00:20:45,510
they can just grab the main
movement branch or main movement

358
00:20:45,510 --> 00:20:49,290
repository and then apply fixes
directly to that and benefit

359
00:20:49,290 --> 00:20:52,320
everyone. That's it seems like
the big argument for open source

360
00:20:52,710 --> 00:20:53,130
to me.

361
00:20:54,120 --> 00:20:56,340
Dave Coleman: Yeah, and it's
like, it's not just moving

362
00:20:56,340 --> 00:20:58,530
everyone, but it's benefiting
the individual companies making

363
00:20:58,530 --> 00:21:01,830
these decisions, because they're
not taking on the ownership.

364
00:21:01,830 --> 00:21:05,430
They say that like, once you
like writing a line of code,

365
00:21:05,580 --> 00:21:08,670
that the cost of that for like
an engineer to do that is only a

366
00:21:08,670 --> 00:21:11,910
fraction of the overall cost of
that code over its lifetime.

367
00:21:12,180 --> 00:21:14,790
Because for every like hour
spent coding, you're gonna spend

368
00:21:14,790 --> 00:21:18,000
several more hours maintaining
it bug fixing in over the

369
00:21:18,000 --> 00:21:20,580
lifetime of your product, or
your robotics project, or what

370
00:21:20,580 --> 00:21:24,030
have you. So it's really
reducing your maintenance cost

371
00:21:24,030 --> 00:21:24,780
over the long term.

372
00:21:25,320 --> 00:21:31,200
Audrow Nash: Yep. Yeah. And time
and I don't know, energy and

373
00:21:31,200 --> 00:21:35,340
everything. There's just so many
things, even like running up

374
00:21:35,340 --> 00:21:38,010
your continuous integration
time, because you have to test

375
00:21:38,010 --> 00:21:41,520
more things which make it more
difficult, as well as just

376
00:21:41,550 --> 00:21:43,380
engineering hours to fix bugs.

377
00:21:43,680 --> 00:21:45,750
Dave Coleman: It's a good point.
And we're talking a lot about

378
00:21:45,750 --> 00:21:49,350
like industry users of open
source software. But you know,

379
00:21:49,350 --> 00:21:52,800
there's a lot of other reasons
and motivations why students

380
00:21:52,800 --> 00:21:56,130
graduate students would but
choose to contribute to open

381
00:21:56,130 --> 00:21:59,760
source as well. So there's,
there's both worlds, I just want

382
00:21:59,760 --> 00:21:59,880
to

383
00:22:00,240 --> 00:22:02,760
Audrow Nash: want to say, what
is what are some of the

384
00:22:02,790 --> 00:22:07,260
motivators for people in
academia, students to contribute

385
00:22:07,260 --> 00:22:08,160
to open source,

386
00:22:08,610 --> 00:22:11,910
Dave Coleman: it's building up
your portfolio, your experience,

387
00:22:12,090 --> 00:22:16,830
getting that mentorship, we were
talking about, kind of being a

388
00:22:16,830 --> 00:22:18,660
part of something bigger,
there's, there's this just a

389
00:22:18,660 --> 00:22:21,780
sense of like, seeing that you
contribute to code that's being

390
00:22:21,780 --> 00:22:24,930
used all over the world, and
being able to brag about that.

391
00:22:24,930 --> 00:22:28,560
And like for many people, maybe
they haven't ever contributed to

392
00:22:28,590 --> 00:22:31,650
real software before. And so
this is like, kind of a good

393
00:22:31,650 --> 00:22:34,020
first step in their career. So
there's those sorts of things,

394
00:22:34,020 --> 00:22:35,910
but really, there's a chance to
still learn a lot.

395
00:22:36,360 --> 00:22:39,150
Audrow Nash: Hmm, totally agree.
Yeah, my experience at open

396
00:22:39,150 --> 00:22:44,820
robotics. Really, I get a lot of
satisfaction from contributing

397
00:22:44,820 --> 00:22:47,730
to things that I know that other
people are using. So I agree

398
00:22:47,730 --> 00:22:54,510
with that. So okay, going back a
little bit. picnic, when did

399
00:22:54,510 --> 00:22:58,560
picnic come along? in the scheme
of things, so you were

400
00:22:58,560 --> 00:23:02,370
contributing and your PhD to
this? And it was you in a small

401
00:23:02,370 --> 00:23:05,820
group of other maintainers? How,
where did picnic come from?

402
00:23:06,900 --> 00:23:11,550
Dave Coleman: It was 2015. And I
like yourself. But recently, I

403
00:23:11,550 --> 00:23:16,350
was an intern. And I was
interning at Google. So pretty

404
00:23:16,350 --> 00:23:21,030
lucky place to be at Google
robotics to be exact. And after

405
00:23:21,030 --> 00:23:25,920
the internship ended, there was
a group there who wanted I'd

406
00:23:25,920 --> 00:23:30,090
help them use move it for some
projects. may actually say too

407
00:23:30,090 --> 00:23:32,940
much here. But they wanted more
of that they wanted more

408
00:23:32,940 --> 00:23:37,350
support. And they asked for
another internship. I said, No,

409
00:23:37,710 --> 00:23:40,680
I'm not going to. I've had a lot
of internships. And so they

410
00:23:40,680 --> 00:23:43,140
said, Do you want to consult for
Google? And I said, Of course I

411
00:23:43,140 --> 00:23:51,270
do. And so that is what bogen
picnic. And technically, like we

412
00:23:51,270 --> 00:23:54,480
had been so picnic, the term
originated from a team at the

413
00:23:54,480 --> 00:23:57,120
University that I was attending
for the Amazon picking

414
00:23:57,120 --> 00:24:01,500
challenge. And so it can
challenge picnic. A friend just

415
00:24:01,500 --> 00:24:05,220
helped me coined this term. So I
asked the team, I was the team

416
00:24:05,220 --> 00:24:08,100
lead. I was like, Hey, can I use
this term for doing some

417
00:24:08,100 --> 00:24:10,950
consulting? And everyone's like,
no problem. So that's kind of

418
00:24:11,610 --> 00:24:12,600
the origin story.

419
00:24:13,770 --> 00:24:17,100
Audrow Nash: Gotcha. And so it
was just you at the beginning

420
00:24:17,100 --> 00:24:22,410
consulting for Google for some
project that use move it. And

421
00:24:22,410 --> 00:24:26,460
you grew from there to now 30
people or so. Yep, kind of

422
00:24:26,460 --> 00:24:30,480
thing. Yeah. That's exciting. So
2015 it started and we're in

423
00:24:30,480 --> 00:24:31,980
2021. Yeah,

424
00:24:32,009 --> 00:24:34,319
Dave Coleman: that's also I had
to finish my PhD. So I

425
00:24:34,319 --> 00:24:38,579
graduated, took a little time
off to travel. And when I came

426
00:24:38,579 --> 00:24:41,219
back, I just kept getting
requests from different

427
00:24:41,219 --> 00:24:45,509
companies that were using move
it for support. And so I'd fly

428
00:24:45,509 --> 00:24:48,869
out to different companies and
do more consulting but also a

429
00:24:48,869 --> 00:24:55,049
lot of coding. And I realized I
had too much work and I made the

430
00:24:55,259 --> 00:24:59,189
pivotal decision to bring on
some co founders and that

431
00:24:59,189 --> 00:25:02,309
certainly changed things. Spent
a lot of work since then an

432
00:25:02,309 --> 00:25:06,299
energy company. But it's been
really fun and exciting also.

433
00:25:06,840 --> 00:25:11,190
Audrow Nash: Hmm. Let's see. So
what have been some of the

434
00:25:11,190 --> 00:25:16,620
projects that you've worked on
with picnic? Like just the

435
00:25:16,620 --> 00:25:19,080
nature of it. So the kinds of
things you can solve with move

436
00:25:19,080 --> 00:25:21,300
it in less abstract form?

437
00:25:22,140 --> 00:25:24,510
Dave Coleman: Sure, yeah, I will
avoid company names because

438
00:25:24,510 --> 00:25:30,210
India is get tricky. And we're
on a public forum here. But one

439
00:25:30,210 --> 00:25:36,540
of so like, logistics was our
second project, like warehouse

440
00:25:36,570 --> 00:25:42,780
bin picking type of stuff. The
next one was robot cooking. And

441
00:25:42,780 --> 00:25:47,250
then a really big one for us was
cooking. Yeah, you know, like,

442
00:25:47,520 --> 00:25:51,270
during things cutting things
like home chef.

443
00:25:51,840 --> 00:25:53,040
Audrow Nash: That's cool. Oh,
yeah, there's

444
00:25:53,039 --> 00:25:54,509
Dave Coleman: like, there's a
couple a couple companies out

445
00:25:54,509 --> 00:25:56,309
there doing this. Yeah, we've
actually worked with a lot of

446
00:25:56,309 --> 00:26:02,639
them. But that was one of our
early projects. And, yeah, we

447
00:26:02,669 --> 00:26:07,079
know, all of our bigger projects
has been surgical, robotics,

448
00:26:07,409 --> 00:26:10,679
and, you know, move. It's been
used to do surgery. But, of

449
00:26:10,679 --> 00:26:14,789
course, they had to do a lot of
rewriting of certain segments to

450
00:26:14,789 --> 00:26:19,619
make it FDA certifiable. And,
like, move, it's a really great

451
00:26:19,619 --> 00:26:21,899
starting point for some
applications. But sometimes you

452
00:26:21,899 --> 00:26:25,739
have to, like, do a lot of
shaping it to be something

453
00:26:25,739 --> 00:26:28,499
that's safe enough for human
use. So I don't recommend you

454
00:26:28,499 --> 00:26:32,789
use move it out of the box to do
surgery. Don't mistake me here.

455
00:26:32,879 --> 00:26:35,039
But yeah, we work with this
company for a long time. It was

456
00:26:35,069 --> 00:26:37,889
a really fun project. And and
since then, like the application

457
00:26:37,949 --> 00:26:40,679
we use it for, it just
astonishes me how diverse it's

458
00:26:40,679 --> 00:26:44,699
been since then. I mean, we're,
it's we've worked for several

459
00:26:44,699 --> 00:26:48,569
space applications, several
underwater robotics, like doing

460
00:26:48,569 --> 00:26:55,829
manipulation with oil and gas.
telehealth because all over the

461
00:26:55,829 --> 00:26:59,669
place we're doing one of our big
projects now is robot farming.

462
00:26:59,789 --> 00:27:03,869
So harvesting of fruits and
vegetables, you name it, like

463
00:27:03,869 --> 00:27:05,129
we've probably been involved.

464
00:27:06,810 --> 00:27:09,540
Audrow Nash: That's so cool. And
it's because motion planning is

465
00:27:09,540 --> 00:27:12,270
just such a fundamental robotics
problem. And you guys have a

466
00:27:12,270 --> 00:27:15,300
bunch of really great tools
around there.

467
00:27:15,450 --> 00:27:17,820
Dave Coleman: Yeah, it turns
out, like, even though you don't

468
00:27:17,820 --> 00:27:22,080
see robot arms used a lot
outside of the factory, I think

469
00:27:22,080 --> 00:27:24,210
you're gonna see a lot more of
that very soon, because we're

470
00:27:24,210 --> 00:27:27,930
working with a lot of early
stage r&d groups, whether

471
00:27:28,080 --> 00:27:31,920
corporate or startup, to use
robots for new applications. But

472
00:27:31,950 --> 00:27:34,950
it turns out that robot arms are
extremely useful because the

473
00:27:34,950 --> 00:27:37,680
whole world is designed for
human arms. And that's what

474
00:27:37,680 --> 00:27:39,390
we're trying to mimic.

475
00:27:40,470 --> 00:27:45,810
Audrow Nash: Hmm. Okay, that's
really cool. And I actually

476
00:27:45,810 --> 00:27:47,640
towards the end of the
interview, I want to ask about

477
00:27:47,640 --> 00:27:49,980
where you think things are
going. Because I assume from all

478
00:27:49,980 --> 00:27:54,270
the consulting, that you have an
incredible idea about kind of

479
00:27:54,300 --> 00:27:56,580
where things are headed, because
you're seeing these early

480
00:27:56,580 --> 00:28:05,460
applications, which is so cool.
But the Okay, so you started

481
00:28:05,460 --> 00:28:10,410
this now? Congratulations,
you're having larger customers,

482
00:28:10,410 --> 00:28:13,740
you mentioned that you have a
collaboration with NASA. Would

483
00:28:13,740 --> 00:28:15,630
you talk a little bit about
this? Sure.

484
00:28:15,660 --> 00:28:18,480
Dave Coleman: Yeah, thank you
for for bringing that up. I just

485
00:28:18,480 --> 00:28:22,380
think space is really cool. This
is really cool. It seems like

486
00:28:22,380 --> 00:28:24,930
there's this big movement, at
least in the US. But I think

487
00:28:24,930 --> 00:28:28,560
it's pretty international of
commercializing space, it's

488
00:28:28,770 --> 00:28:31,590
becoming more privatized,
there's a lot of startups there

489
00:28:31,590 --> 00:28:35,250
was the X PRIZE a few years ago.
And some companies came out of

490
00:28:35,250 --> 00:28:38,250
that, like that Virgin Galactic
flight just recently came out of

491
00:28:38,250 --> 00:28:42,480
that. And just in general, now
that SpaceX has made flights,

492
00:28:42,510 --> 00:28:45,180
getting stuff to space, so much
cheaper and more regular, we're

493
00:28:45,180 --> 00:28:47,340
seeing a lot of other
applications. And so a lot of

494
00:28:47,340 --> 00:28:50,940
companies are working on
satellite assembly is a big one.

495
00:28:50,970 --> 00:28:54,390
And using robot arms for that
doing more experiments in the

496
00:28:54,390 --> 00:28:58,320
space station or in the future
gateway station being worked on.

497
00:29:00,180 --> 00:29:01,890
Audrow Nash: I don't I don't
know very much about space

498
00:29:01,890 --> 00:29:07,230
applications, or the different
ways that companies are trying

499
00:29:07,230 --> 00:29:10,680
to make a profit out of space.
So you said satellite assembly

500
00:29:10,680 --> 00:29:15,150
that's on Earth, or is that in
space? Oh, wow. So you send up

501
00:29:15,150 --> 00:29:19,080
the components and then build it
out up there? Yeah. Okay.

502
00:29:19,380 --> 00:29:21,870
Dave Coleman: Yeah, I think one
of the big motivations is that

503
00:29:22,230 --> 00:29:25,290
things have to currently
compress into these little

504
00:29:25,290 --> 00:29:28,620
rocket modules. But sometimes
you want to build things bigger

505
00:29:28,620 --> 00:29:30,660
than that. And so you need to
assemble in space.

506
00:29:31,230 --> 00:29:34,950
Audrow Nash: Hmm. Okay. And that
would be used for a bunch of

507
00:29:34,950 --> 00:29:39,750
applications. Like taking photos
of the earth or maybe sending

508
00:29:39,780 --> 00:29:43,770
internet places like starlink or
whatever it might be this kind

509
00:29:43,770 --> 00:29:44,190
of thing.

510
00:29:44,340 --> 00:29:48,660
Dave Coleman: Yeah. It I guess I
don't know. a ton about like,

511
00:29:48,660 --> 00:29:52,320
What? What I mean, yeah,
assembling satellites for all

512
00:29:52,320 --> 00:29:54,090
the normal cases what you just
said,

513
00:29:54,450 --> 00:29:57,390
Audrow Nash: Yep. Okay, and then
what other applications were you

514
00:29:57,390 --> 00:29:58,770
saying? first base.

515
00:30:00,000 --> 00:30:04,170
Dave Coleman: So the doing more
things without astronauts in

516
00:30:04,170 --> 00:30:07,140
space like on the space station
so NASA has had this long

517
00:30:07,140 --> 00:30:10,920
standing program to have robots
augment the astronauts time

518
00:30:10,920 --> 00:30:15,300
astronauts are wildly expensive
to send up like every hour of

519
00:30:15,300 --> 00:30:18,540
their work day their their
billable rate is very very high

520
00:30:19,980 --> 00:30:24,000
now because because of just all
the training all the fuel Yeah,

521
00:30:24,299 --> 00:30:26,759
Audrow Nash: infrastructure
would you I mean, I bet it's

522
00:30:26,759 --> 00:30:30,389
like comically large how
expensive they are per hour what

523
00:30:30,389 --> 00:30:34,829
would you do about what it was
but it's like $10,000 an hour or

524
00:30:34,829 --> 00:30:36,329
is it way more than that?

525
00:30:36,569 --> 00:30:38,429
Dave Coleman: I wish I had that
on my head

526
00:30:39,750 --> 00:30:43,710
Audrow Nash: okay so what are
what is it that you guys are

527
00:30:43,710 --> 00:30:45,840
doing? Are you looking for a
number

528
00:30:46,410 --> 00:30:49,260
Dave Coleman: Yeah, I am looking
for a number but i don't i don't

529
00:30:49,260 --> 00:30:53,550
see it so they're using move it
right now on the this program

530
00:30:53,550 --> 00:30:57,150
called the Robonaut which is in
the space station. And to like

531
00:30:57,150 --> 00:31:00,240
help do some more than
maintenance tasks of the

532
00:31:00,240 --> 00:31:04,770
station. Like cleaning surfaces
or like just flipping switches

533
00:31:04,770 --> 00:31:07,680
just like things that like maybe
aren't worth the astronauts time

534
00:31:07,710 --> 00:31:10,410
Audrow Nash: would you describe
Bravo not because it's a pretty

535
00:31:10,410 --> 00:31:11,430
wild looking thing.

536
00:31:11,820 --> 00:31:16,320
Dave Coleman: Yeah, it's it's
very anthropomorphic, it like to

537
00:31:16,320 --> 00:31:19,260
look like a human, for the most
part. So it's got fully

538
00:31:19,260 --> 00:31:23,400
dexterous fingers. It's got a
head that can rotate. Look

539
00:31:23,400 --> 00:31:26,460
around, it's got like a chest
just like a human. The legs

540
00:31:26,460 --> 00:31:29,130
however, are a bit creepier.
They're think more like yes,

541
00:31:29,130 --> 00:31:33,300
spider legs, there's less. But
because you're in zero G, you

542
00:31:33,300 --> 00:31:35,790
don't need legs that can walk
like on Earth, you just need

543
00:31:35,790 --> 00:31:39,360
something to grab on to
handrails. And so that part's a

544
00:31:39,360 --> 00:31:43,890
little creepier. And I am not
the definitive source of the

545
00:31:43,890 --> 00:31:47,610
status of this program. But
it's, I think it's a little bit

546
00:31:47,850 --> 00:31:51,420
winding down. And they're like,
revisiting what kind of robots

547
00:31:51,420 --> 00:31:55,110
best for space. And, and so for
the gateway, which is a new

548
00:31:55,110 --> 00:31:59,580
station being launched soon, to
orbit the moon, one of the big

549
00:31:59,580 --> 00:32:02,820
needs, there is a inner vehicle
robot that can take care of the

550
00:32:02,820 --> 00:32:05,430
station when it's unmanned,
because they aren't planning on

551
00:32:05,430 --> 00:32:09,390
having a human there. All times
of the year, I think closer to

552
00:32:09,390 --> 00:32:12,000
like four months of the year,
it'll be manned. Eight months a

553
00:32:12,000 --> 00:32:15,450
year, the robots got to take
care of the place. And so we're

554
00:32:15,450 --> 00:32:17,220
currently on a grant involved
with that.

555
00:32:18,030 --> 00:32:23,430
Audrow Nash: Hmm, so it'll be
the robo Robo robot on this down

556
00:32:23,430 --> 00:32:27,780
the gateway, which is orbiting
the moon. And it will be taking

557
00:32:27,780 --> 00:32:31,500
care of a lot of operations by
doing what a human might do if

558
00:32:31,500 --> 00:32:35,910
they were on it. Is it going to
be tele operated? Or is it going

559
00:32:35,910 --> 00:32:37,530
to be largely autonomous or?

560
00:32:38,670 --> 00:32:44,340
Dave Coleman: Yeah, I love this
topic. I think teleoperated to

561
00:32:44,340 --> 00:32:48,300
me, the definition of that is
really drive by wire, you've got

562
00:32:48,330 --> 00:32:53,550
a joystick, or a mouse, or these
days, a VR headset with two hand

563
00:32:53,550 --> 00:32:56,730
controllers. And you're telling
the robot what to do like

564
00:32:56,730 --> 00:33:00,000
basically one to one. And you
know, it's not exactly one to

565
00:33:00,000 --> 00:33:02,970
one because oftentimes, the
robot arm may have a different

566
00:33:02,970 --> 00:33:06,030
kinematic morphology than a
human. And so the way it maps

567
00:33:06,030 --> 00:33:08,190
out your command might be
slightly different. But for the

568
00:33:08,190 --> 00:33:10,890
most part, you know, I'm talking
about like Cartesian control,

569
00:33:11,130 --> 00:33:14,010
which is like effector control.
But for the most part, you're

570
00:33:14,010 --> 00:33:17,640
just you tell what to do. That's
totally up to me. Yeah, so

571
00:33:17,640 --> 00:33:20,130
Audrow Nash: you move like it
would be like moving joysticks

572
00:33:20,130 --> 00:33:24,330
around, like the VR things. And
the robot would do pretty much

573
00:33:24,330 --> 00:33:26,940
the same motion, but it might do
slightly different things.

574
00:33:26,940 --> 00:33:29,820
Because its joints might be
different than humans. Exactly.

575
00:33:30,510 --> 00:33:30,960
Okay.

576
00:33:31,290 --> 00:33:34,560
Dave Coleman: Yeah. And so that
breaks down when you're on the

577
00:33:34,560 --> 00:33:38,040
moon. And particularly if you're
going to Mars, which is the next

578
00:33:38,040 --> 00:33:40,770
stepping stone for the space
program, as Ilan, lets us all

579
00:33:40,770 --> 00:33:47,460
know. Because latency and
bandwidth issues, delays in

580
00:33:47,460 --> 00:33:50,880
time. So I think to the moon
it's like three or four seconds,

581
00:33:51,060 --> 00:33:54,810
and to the Mars to Mars, it's
like several minutes. Don't

582
00:33:54,810 --> 00:33:57,030
quote me on this, I don't
memorize numbers, as you can

583
00:33:57,030 --> 00:34:02,010
tell. So that becomes really
annoying and frustrating to

584
00:34:02,010 --> 00:34:05,220
control something with that
amount of lag because you send a

585
00:34:05,220 --> 00:34:07,530
command and then you have to
wait round trip for it to come

586
00:34:07,530 --> 00:34:12,030
back. So we're very interested
technic, we're developing some

587
00:34:12,030 --> 00:34:17,070
technology that is a mix of
fully autonomous and tele

588
00:34:17,070 --> 00:34:21,870
operated. So what's between
those two extremes? And that's,

589
00:34:22,290 --> 00:34:22,680
yeah,

590
00:34:22,709 --> 00:34:25,199
Audrow Nash: that's what you're
trying to figure out, or that's

591
00:34:25,199 --> 00:34:28,799
what we're proposing is what
we're working on right now. So

592
00:34:28,799 --> 00:34:32,939
is it like a higher level thing
where you can delegate tasks

593
00:34:32,969 --> 00:34:36,179
like at a task level, you say,
Go select this, go do your thing

594
00:34:36,179 --> 00:34:39,719
here and it will kind of get
over so if it's flip a switch

595
00:34:39,749 --> 00:34:43,469
will, the robot will go over
there and position itself and

596
00:34:43,469 --> 00:34:46,769
perhaps flick it, but you've
directed that it should do that?

597
00:34:46,799 --> 00:34:50,639
So it's like a higher level
command and I think we're, Ah,

598
00:34:51,569 --> 00:34:54,359
Dave Coleman: that's, this goes
under a number of names. But

599
00:34:54,419 --> 00:35:00,269
supervisor autonomy is maybe the
most common one where you You

600
00:35:00,269 --> 00:35:00,689
are in such

601
00:35:00,690 --> 00:35:03,930
Audrow Nash: an oxymoron. But I
get it. Yeah,

602
00:35:03,930 --> 00:35:06,420
Dave Coleman: it does. So you
tell the robot, hey, here's a

603
00:35:06,420 --> 00:35:10,260
high level task. And then you're
kind of observing the robot as

604
00:35:10,260 --> 00:35:13,140
it goes about doing it with the
understanding that maybe the

605
00:35:13,140 --> 00:35:18,030
robots not quite smart enough to
fully do the task. Because these

606
00:35:18,030 --> 00:35:20,340
are just hard problems. They're
kind of unsolved so far,

607
00:35:20,550 --> 00:35:24,270
especially when you're in
unstructured environments. I've

608
00:35:24,270 --> 00:35:27,540
had arguments about whether a
space station like the ISS is

609
00:35:27,540 --> 00:35:31,170
unstructured or not, it's kind
of an academic argument. Because

610
00:35:31,170 --> 00:35:33,690
I know my mind, these things are
highly engineered things where

611
00:35:33,690 --> 00:35:37,530
they have exact computer models
before they get launched. You

612
00:35:37,530 --> 00:35:41,370
look at videos on like YouTube
of astronauts, giving you a tour

613
00:35:41,370 --> 00:35:45,450
of the Space Station. It's
really striking how many bags

614
00:35:45,450 --> 00:35:49,470
and wires and new experiments
are just floating in the middle

615
00:35:49,470 --> 00:35:52,620
of the way. And so actually,
it's an extremely complex

616
00:35:52,620 --> 00:35:56,880
environment. So for a robot to
be able to fully autonomously

617
00:35:56,880 --> 00:36:00,600
navigate this ever changing
environment to do useful things.

618
00:36:00,960 --> 00:36:04,920
It Yeah, it's hard for today's
algorithms. And so the AI going

619
00:36:04,920 --> 00:36:07,860
back to supervise autonomy,
there's a human there to help it

620
00:36:07,860 --> 00:36:11,130
along when needed, but really
minimizing how much intervention

621
00:36:11,190 --> 00:36:12,480
is needed from that from the
human.

622
00:36:14,130 --> 00:36:18,060
Audrow Nash: Okay, that's really
cool. Do you think that this

623
00:36:18,060 --> 00:36:21,060
will be a larger thing in
robotics? Like the supervise

624
00:36:21,060 --> 00:36:25,680
autonomy? Do you think before, I
mean, we see it with like, like,

625
00:36:25,680 --> 00:36:28,920
you can think of like Tesla and
its self driving as being

626
00:36:28,920 --> 00:36:31,560
somewhat supervised autonomy,
you sit there in the seat, and

627
00:36:31,560 --> 00:36:36,210
it drives for you until it
cannot handle whatever's going

628
00:36:36,210 --> 00:36:39,240
on. And then it gives you back
control. Do you think that this

629
00:36:39,240 --> 00:36:42,360
is going to be a larger trend
before robots are like actually

630
00:36:42,360 --> 00:36:45,120
capable of exactly those things
entirely?

631
00:36:45,360 --> 00:36:50,280
Dave Coleman: It's exactly what
I think. So to Tesla versus

632
00:36:50,280 --> 00:36:53,550
whammo versus the other crews,
self driving car companies, they

633
00:36:53,550 --> 00:36:56,130
all have slightly different
approaches to how they're doing

634
00:36:56,190 --> 00:36:59,880
autonomous vehicles. But I think
it's really interesting that

635
00:36:59,880 --> 00:37:03,420
Weibo and a number of the other
ones, they've all kind of

636
00:37:03,450 --> 00:37:07,320
realized that in order to get to
L five, autonomy, actually, you

637
00:37:07,320 --> 00:37:12,000
need a remote operator that
occasionally can help this, like

638
00:37:12,000 --> 00:37:16,200
the robo taxi, get unstuck. So
you know, a lot of the prototype

639
00:37:16,230 --> 00:37:19,170
or concept vehicles that I think
are going to be out soon, they

640
00:37:19,170 --> 00:37:21,570
may or may not have a student
steering wheel. And so if you

641
00:37:21,570 --> 00:37:24,330
think about a taxi, and maybe
the seats are facing inward,

642
00:37:25,020 --> 00:37:29,010
there's no one there to take
over. If the robot just the car

643
00:37:29,010 --> 00:37:31,620
really gets stuck. A Tesla has a
steering wheel still, and

644
00:37:31,620 --> 00:37:34,770
they're not. They're a different
player. So I would, they're a

645
00:37:34,770 --> 00:37:38,340
different category of autonomy
in my opinion. But the idea with

646
00:37:38,340 --> 00:37:41,160
like way, Mo is that there's
someone in a call center who

647
00:37:41,250 --> 00:37:45,270
maybe isn't watching every turn
every step of the way. But when

648
00:37:45,270 --> 00:37:48,690
it's needed, they can be, you
know, called in to give the

649
00:37:48,690 --> 00:37:50,190
robot a little more
understanding, like, Hey, this

650
00:37:50,190 --> 00:37:52,830
is a construction site. We
haven't quite seen this problem

651
00:37:52,830 --> 00:37:55,140
before. But this is what I want
you to do. And the robot can

652
00:37:55,140 --> 00:37:59,220
then go, Okay, I'm going to
maneuver around this. So that's

653
00:37:59,220 --> 00:38:02,370
proving out to be a necessary
need in self driving cars. And I

654
00:38:02,370 --> 00:38:06,240
think it's also going to be more
and more in need as we get robot

655
00:38:06,240 --> 00:38:07,980
arms outside of factories,

656
00:38:08,400 --> 00:38:12,210
Audrow Nash: huh? Yeah, I bet
you're right. It's a very

657
00:38:12,210 --> 00:38:16,830
interesting thing. Because you
can kind of augment where, like

658
00:38:16,830 --> 00:38:21,630
robots can do maybe 80% of it,
or 70% of it. But then there's

659
00:38:21,630 --> 00:38:24,510
some part of it that people just
need to be there for their

660
00:38:24,510 --> 00:38:28,080
judgment. And so we can buffer.

661
00:38:29,160 --> 00:38:31,380
Dave Coleman: I think you kind
of hinted at it a second ago,

662
00:38:31,380 --> 00:38:34,980
like, eventually, we won't need
this again, like we're gonna get

663
00:38:34,980 --> 00:38:37,950
the machine learning algorithms
and the software and all of it

664
00:38:37,950 --> 00:38:42,660
so intelligent that the human
will be then removed completely.

665
00:38:42,930 --> 00:38:45,060
But there's been some
interesting research about like,

666
00:38:45,090 --> 00:38:49,830
how AI is harder than we think.
And we've hit some critical

667
00:38:49,830 --> 00:38:52,320
limits of current machine
learning techniques. And this is

668
00:38:52,320 --> 00:38:54,750
why the self driving car
industry has been so delayed.

669
00:38:55,110 --> 00:38:58,530
And so I think it's going to be
longer than we think like, you

670
00:38:58,530 --> 00:39:01,890
kind of have to get general
intelligence, General AI in

671
00:39:01,890 --> 00:39:06,570
order to completely eliminate
the human from it. And I'm not

672
00:39:06,570 --> 00:39:08,880
super stoked personally about
even achieving that, because

673
00:39:08,880 --> 00:39:11,130
then you have the whole super
intelligence thing. And what if

674
00:39:11,130 --> 00:39:12,270
it gets smarter than us? And

675
00:39:13,410 --> 00:39:16,920
Audrow Nash: Terminator? Yeah,
yeah. All that stuff. Yeah, I

676
00:39:16,920 --> 00:39:21,420
don't know. It is all very
interesting. And I do from my

677
00:39:21,420 --> 00:39:26,940
own, like, foray into machine
learning and things I have

678
00:39:26,940 --> 00:39:30,540
trouble understanding how the
metaphors can get to a more

679
00:39:30,540 --> 00:39:32,460
general intelligence at the
moment,

680
00:39:33,060 --> 00:39:36,420
Dave Coleman: which is probably
good for humanity. Maybe Yeah.

681
00:39:37,530 --> 00:39:42,870
Audrow Nash: But Alright, so
then your, how long have you

682
00:39:42,870 --> 00:39:44,400
guys been on this NASA project?

683
00:39:45,600 --> 00:39:49,530
Dave Coleman: It's actually just
the past year so not not even a

684
00:39:49,530 --> 00:39:53,790
year, just under a year. We've
been involved in this. But we

685
00:39:53,790 --> 00:39:56,400
recently got our next phase of
grant money with them and

686
00:39:57,420 --> 00:40:02,880
Exactly. So So that's we're
doing this for NASA. But we're

687
00:40:02,880 --> 00:40:05,400
also starting to do this more
and more with our other

688
00:40:05,430 --> 00:40:09,630
customers, using open source,
move it, but also developing

689
00:40:09,630 --> 00:40:14,280
some higher level task planning
proprietary aspects of it that

690
00:40:15,090 --> 00:40:18,150
we, because we've had some
compasses customers asked us to

691
00:40:18,150 --> 00:40:20,970
build this kind of one off. And
now we're making kind of a

692
00:40:20,970 --> 00:40:24,120
general solution for this
overall supervisor autonomy

693
00:40:24,150 --> 00:40:27,990
problem. So I think that's going
to really unlock a lot of

694
00:40:27,990 --> 00:40:29,970
applications in the next decade

695
00:40:29,970 --> 00:40:33,300
Audrow Nash: or two. Yeah, I've
been I don't know, I've been

696
00:40:33,300 --> 00:40:36,750
thinking that this is one of the
big problems on the front of

697
00:40:36,750 --> 00:40:40,050
robotics like, and I think
you're hitting on the head and

698
00:40:40,050 --> 00:40:46,440
actually doing it, which is very
cool. Okay, yeah, making it so

699
00:40:46,440 --> 00:40:49,920
that you can delegate at a
higher level for robots what to

700
00:40:49,920 --> 00:40:54,810
do, and then have some sort of
thing come in and help babies.

701
00:40:55,560 --> 00:40:57,390
It just it seems so unnecessary.

702
00:40:58,980 --> 00:41:01,230
Dave Coleman: I think there's an
interesting, interesting pattern

703
00:41:01,290 --> 00:41:05,250
about past robot companies and
how they've gotten around this

704
00:41:05,250 --> 00:41:08,820
and why maybe there isn't a
solution out there for this

705
00:41:08,850 --> 00:41:14,460
exactly, is that typically, you
choose an application, I'm going

706
00:41:14,460 --> 00:41:20,640
to solve like a robot, that was
a good example here that picks

707
00:41:20,670 --> 00:41:24,210
widgets from a bin, that's just
right, this is a big one, right

708
00:41:24,210 --> 00:41:29,160
now, a lot of companies going
after like, a mixed parcel box.

709
00:41:29,430 --> 00:41:32,880
And you can make a bunch of
assumptions and fixture stuff,

710
00:41:33,210 --> 00:41:38,070
and do just enough autonomy and
AI and like computer vision to

711
00:41:38,070 --> 00:41:42,060
solve that problem really well
and reliably. And those those

712
00:41:42,060 --> 00:41:44,940
solutions that keep coming to
market. So like in the 70s,

713
00:41:44,940 --> 00:41:47,880
maybe the problem was, how do we
spray paint a car really

714
00:41:47,880 --> 00:41:52,380
reliably? And they came up with
exactly the tools for that. And

715
00:41:52,380 --> 00:41:56,280
so we keep pushing slowly, the
envelope of a robot doing a very

716
00:41:56,280 --> 00:42:00,930
fixed thing for harder problems.
But and there's there's a lot of

717
00:42:00,930 --> 00:42:03,240
benefits, like fully autonomous
has a better return on

718
00:42:03,240 --> 00:42:05,550
investment in terms of like,
you're totally eliminating the

719
00:42:05,550 --> 00:42:08,760
job versus like still requiring
a human to be kind of assisting

720
00:42:08,760 --> 00:42:12,570
and sometimes, yep, I just think
that's not going to go all the

721
00:42:12,570 --> 00:42:16,410
way to like a robot that can
navigate through your your

722
00:42:16,410 --> 00:42:20,430
office, your home, like outside,
in a wreck and just like assist

723
00:42:20,550 --> 00:42:25,020
or space, in particular, for any
arbitrary problem you throw at

724
00:42:25,020 --> 00:42:27,390
it and have it be able to
achieve it. So that's, I think

725
00:42:27,390 --> 00:42:28,470
this was me next?

726
00:42:29,040 --> 00:42:31,440
Audrow Nash: Yes, yeah, even the
modern ones, it's like, they're

727
00:42:31,440 --> 00:42:34,560
somewhat like the picking the
widgets out of the bin. The

728
00:42:34,560 --> 00:42:38,250
approaches seem to be somewhat
flexible to variation. But it's

729
00:42:38,250 --> 00:42:42,660
like you throw a different bin
or a new widget in, and then you

730
00:42:42,660 --> 00:42:47,580
have to reprogram everything and
add new, like hacks or less

731
00:42:47,580 --> 00:42:49,950
general solutions to get it to
work again.

732
00:42:50,220 --> 00:42:52,380
Dave Coleman: And maybe yet,
maybe machine learning

733
00:42:52,380 --> 00:42:55,020
techniques, the difficulty of
adding a new widget is gone way

734
00:42:55,020 --> 00:42:57,480
down. Maybe I think it's
probably really easy to

735
00:42:57,780 --> 00:43:00,600
arbitrary object, train it
really quickly. Yeah, but he

736
00:43:00,600 --> 00:43:05,310
still if you ask him to then,
like, paint a car or do a

737
00:43:05,310 --> 00:43:07,620
different, totally different
type. It's just not going to be

738
00:43:07,980 --> 00:43:08,220
Yeah.

739
00:43:09,480 --> 00:43:11,610
Audrow Nash: Yep. Yeah, that's a
better way to phrase it. It's

740
00:43:11,610 --> 00:43:16,620
just if you choose a different
task, it is unable to cope with

741
00:43:16,620 --> 00:43:19,770
the same system, you can run
another program, and have that

742
00:43:19,770 --> 00:43:23,970
actually work, perhaps, but it
has to be a specialized program

743
00:43:23,970 --> 00:43:26,670
in itself to do the different
tasks. Yeah, I

744
00:43:26,670 --> 00:43:28,320
Dave Coleman: think the key
there is you said you have to

745
00:43:28,320 --> 00:43:33,720
run another program. And so who
isn't you the US? Yep. So so

746
00:43:33,720 --> 00:43:37,470
like really giving the operator
a slew of a library of programs

747
00:43:37,470 --> 00:43:41,400
that are more general and not
the robot do a lot of autonomy.

748
00:43:41,400 --> 00:43:44,160
But when the robot like gets
stumped, there's a human there

749
00:43:44,160 --> 00:43:47,490
to like, push it along, like,
Hey, here's a little hint. And

750
00:43:47,490 --> 00:43:52,530
then one really cool idea that
we are not, you know, pursuing

751
00:43:52,590 --> 00:43:57,300
exactly yet. But like, you have
all this human interfering or

752
00:43:57,300 --> 00:43:59,850
intervening helping the robot,
and then that actually creates

753
00:43:59,850 --> 00:44:03,390
more training data to generate.
So then you have this life cycle

754
00:44:03,390 --> 00:44:07,200
of labelled semantic data that
you can use for future machine

755
00:44:07,200 --> 00:44:07,950
learning models. It's

756
00:44:07,950 --> 00:44:11,670
Audrow Nash: a virtuous cycle,
it is totally more data more to

757
00:44:11,670 --> 00:44:14,520
train on, you can get more
sophisticated and you get closer

758
00:44:14,520 --> 00:44:15,750
to actually solving your
problem.

759
00:44:16,320 --> 00:44:17,850
Dave Coleman: I'm not a machine
learning expert, though, so I

760
00:44:17,850 --> 00:44:19,710
won't I won't claim any of them

761
00:44:19,710 --> 00:44:24,060
Audrow Nash: either. Sure. Let's
see. So that's really exciting.

762
00:44:24,060 --> 00:44:28,770
How do you so witness and I
don't know if you can say, how

763
00:44:28,770 --> 00:44:33,150
are you doing? Like, do you have
a simulation of what it's like

764
00:44:33,150 --> 00:44:39,840
to be on the on the gateway that
space? The What do they call

765
00:44:39,840 --> 00:44:43,260
them? space stations? Yeah, the
space station that's going

766
00:44:43,260 --> 00:44:45,180
around the moon, do you have a
simulation of that? Are you

767
00:44:45,180 --> 00:44:49,140
working on like, don't like
really specific problems for

768
00:44:49,140 --> 00:44:51,480
them? Are you working on general
technologies that they're going

769
00:44:51,480 --> 00:44:55,140
to apply to that situation or I
assume it's a mix

770
00:44:55,710 --> 00:44:57,960
Dave Coleman: more general
technologies at this point, we

771
00:44:57,960 --> 00:45:01,740
hope to move towards more
specific problems in the future.

772
00:45:02,370 --> 00:45:06,600
But move it in has been used a
lot with the space station. And

773
00:45:06,600 --> 00:45:10,170
so in gazebo, another open
source common library and ROS,

774
00:45:10,380 --> 00:45:15,990
they groups at NASA have created
not full simulation space

775
00:45:15,990 --> 00:45:18,810
station, but a full simulation
of a particular module, they

776
00:45:18,810 --> 00:45:21,630
included the railing that you
can grab on to, and maybe some

777
00:45:21,630 --> 00:45:24,750
problems and so they're dead
there hasn't worked that the

778
00:45:24,960 --> 00:45:28,950
Robonaut using the open motion
planning library would move

779
00:45:28,980 --> 00:45:32,370
through this environment using
its creepy spider legs and arms

780
00:45:33,660 --> 00:45:38,640
to like, pull a cargo bag and
like open the Velcro, like some

781
00:45:38,640 --> 00:45:44,010
pretty cool tasks. That that's
been worked on. And so some of

782
00:45:44,010 --> 00:45:46,230
the guys that are at our company
have been involved in that

783
00:45:46,230 --> 00:45:46,710
program.

784
00:45:47,519 --> 00:45:51,809
Audrow Nash: So cool. Is there
any heart? So I guess, does this

785
00:45:51,809 --> 00:45:54,749
already? Does the gateway
already exist? Or is it already

786
00:45:54,749 --> 00:45:56,759
up there? That's a thing in the
future.

787
00:45:57,090 --> 00:45:59,010
Dave Coleman: I believe it's not
launched yet.

788
00:46:00,330 --> 00:46:03,120
Audrow Nash: So are there? I
mean, I'm just wondering if

789
00:46:03,120 --> 00:46:07,920
you're like doing the sinusoidal
flight in an airplane with Robo

790
00:46:07,920 --> 00:46:10,290
not that's floating for a few
seconds and trying to do

791
00:46:10,290 --> 00:46:11,340
something or

792
00:46:11,550 --> 00:46:14,400
Dave Coleman: no, no, I mean,
like it we're not, we're not

793
00:46:14,400 --> 00:46:18,030
that involved in this yet.
Because that would be so cool.

794
00:46:18,660 --> 00:46:19,500
That would be

795
00:46:21,330 --> 00:46:23,640
Audrow Nash: so you could fight
against gravity by doing that.

796
00:46:24,960 --> 00:46:25,800
It's so cool.

797
00:46:27,450 --> 00:46:29,790
Dave Coleman: I mean, we don't
have gravity, it just makes all

798
00:46:29,790 --> 00:46:33,330
the manipulation problems, I
think easier, because if they

799
00:46:33,330 --> 00:46:35,490
don't have any momentum, they
just stay.

800
00:46:36,330 --> 00:46:40,050
Audrow Nash: It's true. Unless
if they would be floating, it

801
00:46:40,050 --> 00:46:42,540
would probably be very
difficult. And there's no forced

802
00:46:43,230 --> 00:46:45,840
precedent like they just move
away from you if you put any

803
00:46:45,840 --> 00:46:50,040
force that they symmetric into
good point. But easier if

804
00:46:50,040 --> 00:46:56,940
they're stationary, because you
just but Hmm. So I think one

805
00:46:56,940 --> 00:47:01,920
thing that seems really exciting
about this, to me is open source

806
00:47:02,730 --> 00:47:06,930
being used at NASA is amazing.
Like that. I feel like that's a

807
00:47:06,930 --> 00:47:09,540
huge win for the open source
community. Can you talk a bit

808
00:47:09,540 --> 00:47:10,140
about that?

809
00:47:11,190 --> 00:47:15,030
Dave Coleman: Yeah, they've
they've been involved with ROS

810
00:47:15,030 --> 00:47:18,240
and funding Open Robotics for a
while, I believe is my

811
00:47:18,240 --> 00:47:22,680
understanding. And I think that
they see that this is a great

812
00:47:22,680 --> 00:47:26,910
way of tech transfer from what's
the latest in academia. And they

813
00:47:26,910 --> 00:47:31,170
see it as a way to kind of
standardize and hire people who

814
00:47:31,170 --> 00:47:35,670
already know, the technology and
I ROS just kind of become a

815
00:47:35,670 --> 00:47:40,590
standard. And so NASA organizes
that on various teams at NASA

816
00:47:40,590 --> 00:47:41,100
recognize it.

817
00:47:42,300 --> 00:47:45,450
Audrow Nash: The really
interesting thing to me is when

818
00:47:45,450 --> 00:47:51,570
I think NASA I think of like
incredibly robot, like they're

819
00:47:51,570 --> 00:47:54,840
really concerned about
reliability. And it's

820
00:47:54,840 --> 00:47:58,350
interesting to me that they're
going to open source for things

821
00:47:58,350 --> 00:48:01,980
that are important in their
application, like controlling a

822
00:48:01,980 --> 00:48:06,300
robo not. Yeah, station, like
that's really interesting to me.

823
00:48:06,660 --> 00:48:08,520
Dave Coleman: Yeah, good
question. May is not a question.

824
00:48:08,520 --> 00:48:13,380
But I have a thought on that is
the robot, their strategy, the

825
00:48:13,380 --> 00:48:16,860
group at Johnson Space Center,
was to make the low level

826
00:48:16,860 --> 00:48:21,030
controls really heartened, and
like, I'm not sure if I'd call

827
00:48:21,030 --> 00:48:25,770
it like flight certified but
certified quality and rigorous

828
00:48:25,770 --> 00:48:30,630
such that it was guaranteed not
to extract to exert the force to

829
00:48:30,630 --> 00:48:33,930
like punch into a space station,
for example, like, they can't

830
00:48:33,930 --> 00:48:37,350
break the station, because
that's extremely dangerous. And

831
00:48:37,350 --> 00:48:40,680
so if you aren't like if the
underlying controllers and like

832
00:48:40,680 --> 00:48:44,160
the hardware interface, it like
reaches the right certification

833
00:48:44,160 --> 00:48:46,560
level of safety and that it
can't go beyond a certain

834
00:48:46,560 --> 00:48:49,890
velocity and sort of torque,
then you can then think about

835
00:48:49,890 --> 00:48:53,460
the layer above that kind of the
application layer with a more

836
00:48:53,610 --> 00:48:56,760
modern like rapid iteration
software development techniques,

837
00:48:56,970 --> 00:49:00,780
that allows for more powerful
compute and more like advanced

838
00:49:00,810 --> 00:49:04,530
methodologies. But sometimes it
does, maybe sacrifice the rigor

839
00:49:04,530 --> 00:49:08,190
of a very simple system that is
flight ready.

840
00:49:10,020 --> 00:49:13,560
Audrow Nash: I see what you
mean. So it's nice to so we, you

841
00:49:13,560 --> 00:49:16,770
can have that base layer that
NASA writes that make sure that

842
00:49:16,770 --> 00:49:20,190
the robots got not going to
break anything. And then after

843
00:49:20,190 --> 00:49:23,370
that, you can put your more
sophisticated layer on your

844
00:49:23,370 --> 00:49:26,610
layer that does higher level
control. To do this,

845
00:49:26,820 --> 00:49:28,950
Dave Coleman: there's often a
trade off of like, if you want

846
00:49:28,950 --> 00:49:31,950
to have these, like high
resolution meshes that in like

847
00:49:31,980 --> 00:49:36,240
sensor data, where you're like,
able to plan at higher level

848
00:49:36,240 --> 00:49:39,510
thinking and that task levels,
the software gets very complex.

849
00:49:39,660 --> 00:49:43,170
And there's just like a lot of
possibilities where sensor noise

850
00:49:43,200 --> 00:49:47,100
could cause errors, or just all
the interacting interacting

851
00:49:47,100 --> 00:49:50,310
systems on different threads and
cores, just can cause a little

852
00:49:50,310 --> 00:49:53,070
bit more unexpected timing. And
so you definitely need to have

853
00:49:53,070 --> 00:49:56,730
like, an underlying like, super
safe layer on top of all these

854
00:49:56,730 --> 00:49:57,780
advanced capabilities.

855
00:49:57,810 --> 00:50:03,810
Audrow Nash: Yep. So Now I see
that we are, like run where I

856
00:50:03,810 --> 00:50:05,970
see that we're running out of
time. And I know there's a few

857
00:50:05,970 --> 00:50:09,870
things that we want to talk
about. So could you tell me a

858
00:50:09,870 --> 00:50:14,040
bit about premium? So move it
premium? And how like, what is

859
00:50:14,040 --> 00:50:15,540
that? And what's the model?

860
00:50:15,840 --> 00:50:20,760
Dave Coleman: No, I just did. So
we're calling into the studio.

861
00:50:21,360 --> 00:50:24,960
And that studio. Yeah. So I'm
glad you made time for this. I'm

862
00:50:24,960 --> 00:50:27,720
surprised that we're running out
of time this is flown by, but

863
00:50:27,720 --> 00:50:32,250
yeah, do it. So we've, we have
been doing engineering services

864
00:50:32,250 --> 00:50:35,640
for the past four or five years.
And it's been a lot of fun. But

865
00:50:35,640 --> 00:50:39,150
we think that the next stage of
growth at picnic is going to

866
00:50:39,150 --> 00:50:42,840
evolve, and not only the next
stage of growth, but the way

867
00:50:42,840 --> 00:50:46,080
that we can have a bigger impact
towards growing the move at open

868
00:50:46,080 --> 00:50:50,550
source project is by also
offering a premium version that

869
00:50:50,730 --> 00:50:54,540
that like larger companies would
be really excited to pay for,

870
00:50:54,540 --> 00:50:57,750
because they get all these
additional features. And, and so

871
00:50:57,750 --> 00:51:01,680
we tried to make sure not to
come up with a premium feature

872
00:51:01,680 --> 00:51:05,250
that conflicts with the core
feature set of move it because

873
00:51:05,250 --> 00:51:08,310
we don't want to be trying to
make a better version of move it

874
00:51:08,310 --> 00:51:12,780
but instead, move it studio is
the operator human loop

875
00:51:12,780 --> 00:51:18,210
supervisors autonomy aspect.
That's right. Oh, that's Yeah,

876
00:51:18,210 --> 00:51:21,330
so. So like, we're gonna keep
improving the underlying

877
00:51:21,330 --> 00:51:24,450
grasping library and planning
libraries and kinematics and

878
00:51:24,450 --> 00:51:28,740
like, the handy calibration
tools, improving all that for

879
00:51:28,740 --> 00:51:31,380
the overall community. But also,
like we've we've made this

880
00:51:31,380 --> 00:51:35,220
dividing line. Some might say
it's controversial, but there's

881
00:51:35,220 --> 00:51:38,340
been, I've studied a lot of
like, open source business

882
00:51:38,340 --> 00:51:42,660
models of past successes. And
it's like, very common, either

883
00:51:42,660 --> 00:51:44,730
you come up with a SAS play,
where you're selling an internet

884
00:51:44,730 --> 00:51:48,120
service on top of your open
source library, think WordPress,

885
00:51:48,330 --> 00:51:52,560
or you're coming up with a
premium version of the software

886
00:51:53,040 --> 00:51:55,920
that says Software as a Service
software as a service. Thank

887
00:51:55,920 --> 00:51:58,740
you. Yeah. Or you have this just
like this license offer on top

888
00:51:58,740 --> 00:52:01,620
of it. So WordPress actually did
that. Also, they have jetpack,

889
00:52:01,920 --> 00:52:05,160
like premium plugins, if you
know WordPress at all. Or

890
00:52:05,160 --> 00:52:09,540
another example is like Apache
Spark is a really popular open

891
00:52:09,540 --> 00:52:13,710
source library for I think, data
analysis. I don't use it. But

892
00:52:14,160 --> 00:52:18,000
this company data bricks, made a
product on top of it that has

893
00:52:18,000 --> 00:52:21,660
allowed Apache Spark to continue
to grow also. So that's the the

894
00:52:21,660 --> 00:52:24,990
new one of our new strategies on
top of our engineering services.

895
00:52:25,290 --> 00:52:29,160
Audrow Nash: Seems smart. The AI
reminds me like another example.

896
00:52:29,280 --> 00:52:32,940
There's tailwind, which is a CSS
framework, if I understand

897
00:52:32,940 --> 00:52:36,150
correctly. And they have
tailwind UI, which is kind of

898
00:52:36,180 --> 00:52:38,190
it's the same breakdown that
you're doing. So they have the

899
00:52:38,190 --> 00:52:41,400
open source one that gives you
all the functionality. But then

900
00:52:41,400 --> 00:52:45,150
they have components. So if you
want to make it more useful, and

901
00:52:45,360 --> 00:52:50,220
that I guess not exactly the
same, but the like the

902
00:52:50,250 --> 00:52:54,420
supervised autonomy, like more
structured interactions with

903
00:52:54,420 --> 00:52:57,210
what you're doing that kind of
fit a template, they have

904
00:52:57,210 --> 00:53:02,160
literal templates for making
HTML and CSS components. That's

905
00:53:02,160 --> 00:53:03,570
their point that they charge
for.

906
00:53:05,040 --> 00:53:06,930
Dave Coleman: a pretty good
example. I mean, for us, it's

907
00:53:06,930 --> 00:53:10,500
like, one way to think about it
is that there's like a front end

908
00:53:10,530 --> 00:53:14,790
for moving now. But there is a
lot more under the hood besides

909
00:53:14,790 --> 00:53:15,660
just a front end.

910
00:53:16,470 --> 00:53:20,280
Audrow Nash: Yep. Awesome. Very
interesting. So what's the

911
00:53:20,280 --> 00:53:25,500
timeline on that? Like, where
are we now in this?

912
00:53:26,250 --> 00:53:28,800
Dave Coleman: Great question. We
have to reference customers

913
00:53:28,830 --> 00:53:32,700
currently that are that we've
released an alpha two. And we're

914
00:53:32,700 --> 00:53:38,370
in talks a number of other early
early customers. And so we plan

915
00:53:38,370 --> 00:53:42,390
to have the beta operating at
ROS con, we should have it

916
00:53:42,690 --> 00:53:45,600
should be running at our booth,
if I assume our viewers are

917
00:53:45,600 --> 00:53:48,060
familiar with the ROS
conference in New Orleans this

918
00:53:48,060 --> 00:53:53,280
year. So that'll be October
2021. So hopefully, we'll have a

919
00:53:53,310 --> 00:53:54,210
pretty cool demo to show.

920
00:53:54,570 --> 00:53:58,350
Audrow Nash: I can't wait to see
Will you guys be we have move at

921
00:53:58,350 --> 00:54:03,000
con or anything nearby at around
the same time, like yeah, or

922
00:54:03,000 --> 00:54:03,240
whatever

923
00:54:03,240 --> 00:54:04,950
Dave Coleman: it might be. This
year, we're not doing a

924
00:54:04,950 --> 00:54:08,040
standalone Lubich con event. I
think our main motivation was we

925
00:54:08,040 --> 00:54:11,850
weren't 100% sure about COVID.
And so we thought we would just

926
00:54:12,240 --> 00:54:16,860
focus our resources on the main
ROS con event. So we are having

927
00:54:17,670 --> 00:54:20,610
we are having a workshop the day
before the official ROS con

928
00:54:20,610 --> 00:54:24,240
event starts, but it's part of
the ROS con workshops we're

929
00:54:24,240 --> 00:54:28,200
having. And that one is actually
totally unrelated to supervise

930
00:54:28,200 --> 00:54:33,120
autonomy, we have been adding to
open source move it some better

931
00:54:33,120 --> 00:54:35,670
features around mobile
manipulation, which is the idea

932
00:54:35,670 --> 00:54:38,850
that you can synchronize the
mobile base of your robot with

933
00:54:38,850 --> 00:54:42,240
the arms so that you can expand
your workspace for for doing

934
00:54:42,240 --> 00:54:44,970
tasks. So like when you think
about a human, you're trying to

935
00:54:44,970 --> 00:54:48,360
reach something across the
table, you could I don't know

936
00:54:48,390 --> 00:54:50,910
get up and walk around the table
or you could like reach across

937
00:54:50,910 --> 00:54:53,850
it but both of those modalities
require using more than just

938
00:54:53,850 --> 00:54:57,540
your arm. So that that kind of
functionality it's always kind

939
00:54:57,540 --> 00:55:01,050
of been a move it but we've
greatly proved it. And so the

940
00:55:01,050 --> 00:55:03,990
workshop will be about how to
use that on a Hello robot

941
00:55:03,990 --> 00:55:08,100
stretch platform, which is a
startup in the Bay Area, making

942
00:55:08,100 --> 00:55:11,010
some pretty cool mobile
manipulators. And by cool, I

943
00:55:11,010 --> 00:55:14,760
mean low cost. It looks like a
stick figure, but it's also

944
00:55:14,850 --> 00:55:17,730
Audrow Nash: really, I'm pretty
happy with it. Yeah, yeah, that

945
00:55:17,730 --> 00:55:18,300
is awesome.

946
00:55:18,510 --> 00:55:21,180
Dave Coleman: So they will be
there with us. picnic will be

947
00:55:21,210 --> 00:55:24,300
kind of doing tutorials on how
to use, move it for that

948
00:55:24,300 --> 00:55:24,960
application.

949
00:55:26,970 --> 00:55:31,140
Audrow Nash: Now I know we've
said a lot about, like talking

950
00:55:31,140 --> 00:55:35,370
about the studio version, and
you guys are working with NASA.

951
00:55:35,370 --> 00:55:39,360
But what's, what's next for
picnic and move it outside of

952
00:55:39,360 --> 00:55:41,400
those, like where you guys had?
would you think?

953
00:55:42,300 --> 00:55:45,270
Dave Coleman: Yeah, so mobile
innovation is mobile

954
00:55:45,270 --> 00:55:50,370
manipulation is one of our big
focus. Big like guiding winds is

955
00:55:50,370 --> 00:55:54,480
like, we need arms to be able to
synchronize better with basis.

956
00:55:54,510 --> 00:55:58,890
And so continuing that thread.
Another big thread for us is

957
00:55:58,890 --> 00:56:01,860
hybrid planning, which is the
combination of global planners

958
00:56:01,860 --> 00:56:06,480
and local planners, the best of
real time planning and global,

959
00:56:06,480 --> 00:56:09,180
really smart planning. They both
have pros and cons. If you

960
00:56:09,180 --> 00:56:13,200
combine them, you get the best
of both worlds. And so we've

961
00:56:13,200 --> 00:56:15,600
been adding more features on
that the past year, we're

962
00:56:15,600 --> 00:56:18,930
working with Fraunhofer over in
Europe on a demo of this

963
00:56:18,930 --> 00:56:25,620
technology. That's that's one of
our big threads. I'm trying to

964
00:56:25,620 --> 00:56:27,810
think what else is on our
roadmap, I can check real quick.

965
00:56:28,350 --> 00:56:34,050
Sure. We're still like I guess
getting the last finishing

966
00:56:34,050 --> 00:56:38,280
touches on move it to I mean
Move Move it to is basically a

967
00:56:38,280 --> 00:56:41,280
feature complete, we have a blog
post recently just talking about

968
00:56:41,640 --> 00:56:44,520
Audrow Nash: what feature
complete you mean up to move it

969
00:56:44,550 --> 00:56:46,320
one in the correct abilities,

970
00:56:46,560 --> 00:56:49,290
Dave Coleman: and move it to his
reminder is just move it

971
00:56:49,290 --> 00:56:52,770
migrated to ROS 2. Except
it's not just that because we've

972
00:56:52,770 --> 00:56:55,470
been adding, like all of our new
features are not going to move

973
00:56:55,470 --> 00:56:57,780
it to so if you're on the move
at one, we encourage you to

974
00:56:57,780 --> 00:57:01,440
upgrade, it has a lot of hassle,
because you have to upgrade your

975
00:57:01,440 --> 00:57:04,470
ROS version as well. But I
think more and more of the

976
00:57:04,470 --> 00:57:07,980
community's making the jump. And
so when I said about feature

977
00:57:07,980 --> 00:57:12,390
complete parameters and launch
files are still a little bit

978
00:57:12,390 --> 00:57:15,780
rough in like ROS 2 Foxy I
think a lot of ethics and

979
00:57:15,780 --> 00:57:19,320
galactic. But now that it's
fixed and galactic, we're having

980
00:57:19,320 --> 00:57:22,860
to finish up the moobot Setup
Assistant, which is simply a

981
00:57:22,860 --> 00:57:26,010
user interface that lets you
easily set up an arbitrary robot

982
00:57:26,100 --> 00:57:28,590
with movement. And we have to
just make it work with a new

983
00:57:28,590 --> 00:57:33,300
style of launch files and
configuration files. So you can

984
00:57:33,300 --> 00:57:35,340
do it without the Setup
Assistant, it's just more work,

985
00:57:35,340 --> 00:57:36,660
we're trying to make it easier
to do it.

986
00:57:37,110 --> 00:57:39,600
Audrow Nash: For sure. Yeah,
hopefully that will get even

987
00:57:39,600 --> 00:57:43,230
easier with humble. The next
one, which will be released, I

988
00:57:43,230 --> 00:57:47,760
don't know may of next year
2018. to hopefully, hopefully,

989
00:57:48,060 --> 00:57:50,940
Dave Coleman: another big one
that I think we've momentum on

990
00:57:50,940 --> 00:57:53,880
is being able to remove into
factors and different into

991
00:57:53,880 --> 00:57:58,860
factors, swap them out, live in
move. And so this is a deep

992
00:57:58,860 --> 00:58:01,470
structural change. But there's a
number of people at picnic

993
00:58:01,590 --> 00:58:04,440
working on this right now
talking about the architecture,

994
00:58:04,680 --> 00:58:06,750
we'll see if we get merged in
and the company doesn't balk at

995
00:58:06,750 --> 00:58:11,340
the changes. But when you're you
already have changes it really

996
00:58:11,580 --> 00:58:14,520
like it breaks a lot of
underlying data structures of

997
00:58:14,520 --> 00:58:16,740
how movement thinks about your
robot. And so we're trying to

998
00:58:16,740 --> 00:58:19,260
restructure that. And that's
been a common request from

999
00:58:19,260 --> 00:58:23,580
customers for years. So imagine,
yeah, I'm excited about if that

1000
00:58:23,580 --> 00:58:28,590
actually lands in the next
version. And that actually, just

1001
00:58:28,590 --> 00:58:31,230
to change topics Audrow that
might end up being what we call

1002
00:58:31,230 --> 00:58:35,070
move three is about API change
of that magnitude we'd probably

1003
00:58:35,070 --> 00:58:35,640
wrap up

1004
00:58:35,760 --> 00:58:38,670
Audrow Nash: Oh, it's that
significant of a change it's a

1005
00:58:38,670 --> 00:58:39,510
huge change.

1006
00:58:39,660 --> 00:58:43,200
Dave Coleman: And in general
move it three is like we it's

1007
00:58:43,200 --> 00:58:45,960
when we stopped thinking move it
one to move it to so right now

1008
00:58:45,960 --> 00:58:50,280
we're actually using get able to
sync the code changes back forth

1009
00:58:50,280 --> 00:58:54,240
them for import, and we're gonna
draw a line in the sand and say,

1010
00:58:54,600 --> 00:58:57,180
we're not gonna make a lot of
huge breaking changes that

1011
00:58:57,360 --> 00:59:00,300
sinkings over and that's to me
kind of what movie three

1012
00:59:00,300 --> 00:59:01,110
represents.

1013
00:59:01,800 --> 00:59:07,710
Audrow Nash: Gotcha. Any, that's
a it's an exciting reveal. Any

1014
00:59:07,710 --> 00:59:10,890
idea when move it three will be
a thing when you actually do

1015
00:59:10,890 --> 00:59:16,290
that. Will it be like when this
when this urdf? Or that the way

1016
00:59:16,290 --> 00:59:21,240
of switching the robot to use a
different gripper? Well that

1017
00:59:21,630 --> 00:59:25,530
kind of be the catalyst to
switch it or I honestly don't

1018
00:59:25,530 --> 00:59:25,770
know

1019
00:59:25,770 --> 00:59:29,850
Dave Coleman: the date. I'm not
sure if the the main move it

1020
00:59:29,850 --> 00:59:34,470
team at picnic knows the date
yet. But it's just gonna be one

1021
00:59:34,470 --> 00:59:37,020
day that we're like, okay, we're
making huge breaking changes.

1022
00:59:37,290 --> 00:59:38,520
We're now drawing a line here.

1023
00:59:39,060 --> 00:59:40,710
Audrow Nash: Boom, move it
three. Yeah, that'll be

1024
00:59:40,710 --> 00:59:42,870
exciting. Do you think it'll be
in the next year?

1025
00:59:43,649 --> 00:59:47,339
Dave Coleman: I hope so. I
really Yeah, definitely. I think

1026
00:59:47,339 --> 00:59:49,199
so. Awesome.

1027
00:59:49,860 --> 00:59:51,270
Audrow Nash: I exciting. I'm
hesitant

1028
00:59:51,270 --> 00:59:54,030
Dave Coleman: to make
commitments because this is

1029
00:59:54,030 --> 00:59:58,560
still open source software and
funding major feature changes is

1030
00:59:58,560 --> 01:00:00,570
always difficult. We don't have
anyone fun. Doing this right

1031
01:00:00,570 --> 01:00:04,950
now. So Nick uses a small, like
a portion of our profit and like

1032
01:00:04,950 --> 01:00:09,420
our extra revenue, to go towards
these things. But if you know,

1033
01:00:09,450 --> 01:00:12,630
let's say, changing and
effectors live is something that

1034
01:00:12,630 --> 01:00:15,810
you really want, and you're a
company with funding, you know,

1035
01:00:15,810 --> 01:00:19,710
you can just hire us, we will do
it way faster and your timeline.

1036
01:00:19,710 --> 01:00:23,910
So that's my thought like, we're
here to do open source changes

1037
01:00:23,970 --> 01:00:24,690
for hire.

1038
01:00:26,070 --> 01:00:30,360
Audrow Nash: Now, so wrapping
up, how does someone get

1039
01:00:30,360 --> 01:00:35,190
involved with move it if they
want to? Like how do they become

1040
01:00:35,190 --> 01:00:37,410
a contributor? How should they
get started,

1041
01:00:37,980 --> 01:00:40,320
Dave Coleman: you use the word
involved. I like that. So the

1042
01:00:40,320 --> 01:00:43,950
big call to action button on the
movement website says get

1043
01:00:43,950 --> 01:00:47,190
involved. So you click that big
blue button at the top right.

1044
01:00:47,520 --> 01:00:51,750
And we recently revamped these
pages to be really pretty and

1045
01:00:52,710 --> 01:00:56,010
hopefully easy to follow to like
guide beginners into the

1046
01:00:56,010 --> 01:00:59,880
project. It used to be just a
bunch of plain text on a web

1047
01:00:59,880 --> 01:01:02,970
page. And so let's move on
to @ROS.org Click the Get

1048
01:01:02,970 --> 01:01:05,700
involved button. And I'm looking
at right now the first two

1049
01:01:05,700 --> 01:01:08,850
things it says is, you know, get
in touch, like saying taps by

1050
01:01:08,880 --> 01:01:13,260
vamos and discourse and discord,
which is unfortunately, similar

1051
01:01:13,260 --> 01:01:14,010
names. similar

1052
01:01:14,010 --> 01:01:16,710
Audrow Nash: name. Yeah, yeah,
that's me up to Yeah,

1053
01:01:16,890 --> 01:01:19,050
Dave Coleman: we decided not to
use slack. We thought discord

1054
01:01:19,050 --> 01:01:20,460
was a better open source,

1055
01:01:20,730 --> 01:01:23,280
Audrow Nash: like discord much
more than slack. Yeah, totally

1056
01:01:23,280 --> 01:01:24,900
agree with that decision? Yeah,

1057
01:01:24,960 --> 01:01:27,000
Dave Coleman: we use slack at
our company. But I think discord

1058
01:01:27,000 --> 01:01:29,550
is great for open source. And
then on the other side, it says,

1059
01:01:29,550 --> 01:01:32,190
you know, start contributing
day, you can click on that,

1060
01:01:32,190 --> 01:01:35,730
it'll tell you how to, like, get
involved with fixing issues,

1061
01:01:35,790 --> 01:01:39,480
improving documentation and
contributing good. Awesome,

1062
01:01:40,140 --> 01:01:45,150
Audrow Nash: and how can how can
people like any social media or

1063
01:01:45,150 --> 01:01:48,660
anything that you want to? So if
anyone wants to follow up and

1064
01:01:48,660 --> 01:01:49,800
learn more, how can they?

1065
01:01:50,129 --> 01:01:53,729
Dave Coleman: Yeah, we post
every week on LinkedIn and

1066
01:01:53,729 --> 01:01:57,629
Twitter under picnic robotics
handle. So a lot of good content

1067
01:01:57,659 --> 01:02:00,809
about the latest things and move
it and a lot of like white

1068
01:02:00,809 --> 01:02:04,109
papers, kind of the latest
research on how we're thinking

1069
01:02:04,109 --> 01:02:08,009
about doing hybrid planning or
grasping or what have you. So we

1070
01:02:08,009 --> 01:02:11,549
have a lot of our PhDs published
on a frequent basis there. So I

1071
01:02:11,549 --> 01:02:15,509
encourage you to follow us on
either those platforms. That's

1072
01:02:15,509 --> 01:02:18,779
been Nick robotics, and I have a
Twitter account and waffle just

1073
01:02:18,779 --> 01:02:23,339
panel. I don't post often
though, but I always mean to I

1074
01:02:23,339 --> 01:02:23,819
just don't.

1075
01:02:26,070 --> 01:02:30,120
Audrow Nash: All right. Awesome.
Thank you. I really enjoyed

1076
01:02:30,120 --> 01:02:37,620
this. And Bye, everyone. Thanks.
That's all we have for you

1077
01:02:37,620 --> 01:02:41,580
today. If you liked this, feel
free to subscribe, head over to

1078
01:02:41,580 --> 01:02:45,090
the ROS discourse if you want
to comment on the episode. Thank

1079
01:02:45,090 --> 01:02:48,090
you to our founding sponsor,
Open Robotics, and I'll see you

1080
01:02:48,090 --> 01:02:49,740
in two weeks. Bye, everyone.

